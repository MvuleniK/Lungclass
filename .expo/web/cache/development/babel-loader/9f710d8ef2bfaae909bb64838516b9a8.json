{"ast":null,"code":"import _toConsumableArray from \"@babel/runtime/helpers/toConsumableArray\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport _get from \"@babel/runtime/helpers/get\";\nimport _inherits from \"@babel/runtime/helpers/inherits\";\nimport _possibleConstructorReturn from \"@babel/runtime/helpers/possibleConstructorReturn\";\nimport _getPrototypeOf from \"@babel/runtime/helpers/getPrototypeOf\";\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from \"../backend/tfjs_backend\";\nimport { nameScope } from \"../common\";\nimport { NotImplementedError, RuntimeError, ValueError } from \"../errors\";\nimport { deserialize } from \"../layers/serialization\";\nimport * as losses from \"../losses\";\nimport * as Metrics from \"../metrics\";\nimport * as optimizers from \"../optimizers\";\nimport { checkUserDefinedMetadata } from \"../user_defined_metadata\";\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from \"../utils/generic_utils\";\nimport { printSummary } from \"../utils/layer_utils\";\nimport { range } from \"../utils/math_utils\";\nimport { convertPythonicToTs } from \"../utils/serialization_utils\";\nimport { version } from \"../version\";\nimport { Container } from \"./container\";\nimport { execute as _execute, FeedDict } from \"./executor\";\nimport { evaluateDataset as _evaluateDataset, fitDataset as _fitDataset } from \"./training_dataset\";\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from \"./training_tensors\";\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from \"./training_utils\";\nexport function isDataTensor(x) {\n  return x instanceof Tensor;\n}\nexport function isDataArray(x) {\n  return Array.isArray(x);\n}\nexport function isDataDict(x) {\n  return !isDataTensor(x) && !isDataArray(x);\n}\nexport function standardizeInputData(data, names, shapes) {\n  var checkBatchAxis = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : true;\n  var exceptionPrefix = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : '';\n\n  if (names == null || names.length === 0) {\n    if (data != null) {\n      var gotUnexpectedData = false;\n\n      if (isDataArray(data) && data.length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (var key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        gotUnexpectedData = true;\n      }\n\n      if (gotUnexpectedData) {\n        throw new ValueError(\"Error when checking model \" + exceptionPrefix + \" expected no data, \" + (\"but got \" + data));\n      }\n    }\n\n    return [];\n  }\n\n  if (data == null) {\n    return names.map(function (name) {\n      return null;\n    });\n  }\n\n  var arrays;\n\n  if (isDataDict(data)) {\n    data = data;\n    arrays = [];\n\n    for (var _iterator = _createForOfIteratorHelperLoose(names), _step; !(_step = _iterator()).done;) {\n      var name = _step.value;\n\n      if (data[name] == null) {\n        throw new ValueError(\"No data provided for \\\"\" + name + \"\\\". Need data for each key in: \" + (\"\" + names));\n      }\n\n      arrays.push(data[name]);\n    }\n  } else if (isDataArray(data)) {\n    data = data;\n\n    if (data.length !== names.length) {\n      throw new ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" + \"Tensors that you are passing to your model is not the size the \" + (\"model expected. Expected to see \" + names.length + \" Tensor(s), but \") + (\"instead got the following list of Tensor(s): \" + data));\n    }\n\n    arrays = data;\n  } else {\n    data = data;\n\n    if (names.length > 1) {\n      throw new ValueError(\"The model \" + exceptionPrefix + \" expects \" + names.length + \" Tensor(s), \" + (\"but only received one Tensor. Found: Tensor with shape \" + data.shape));\n    }\n\n    arrays = [data];\n  }\n\n  arrays = ensureTensorsRank2OrHigher(arrays);\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have \" + shapes[i].length + \" dimension(s). but got array with \") + (\"shape \" + array.shape));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have shape [\" + shapes[i] + \"], but got array with shape \") + (\"[\" + array.shape + \"].\"));\n        }\n      }\n    }\n  }\n\n  return arrays;\n}\nexport function checkArrayLengths(inputs, targets, weights) {\n  var setX = unique(inputs.map(function (input) {\n    return input.shape[0];\n  }));\n  setX.sort();\n  var setY = unique(targets.map(function (target) {\n    return target.shape[0];\n  }));\n  setY.sort();\n\n  if (setX.length > 1) {\n    throw new ValueError(\"All input Tensors (x) should have the same number of samples. \" + \"Got array shapes: \" + (\"\" + JSON.stringify(inputs.map(function (input) {\n      return input.shape;\n    }))));\n  }\n\n  if (setY.length > 1) {\n    throw new ValueError(\"All target Tensors (y) should have the same number of samples. \" + \"Got array shapes: \" + (\"\" + JSON.stringify(targets.map(function (target) {\n      return target.shape;\n    }))));\n  }\n\n  if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n    throw new ValueError(\"Input Tensors should have the same number of samples as target \" + (\"Tensors. Found \" + setX[0] + \" input sample(s) and \" + setY[0] + \" target \") + \"sample(s).\");\n  }\n}\n\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n  var keyLosses = [losses.meanSquaredError, losses.binaryCrossentropy, losses.categoricalCrossentropy];\n\n  for (var i = 0; i < targets.length; ++i) {\n    var y = targets[i];\n    var loss = lossFns[i];\n    var shape = outputShapes[i];\n\n    if (loss == null) {\n      continue;\n    }\n\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new ValueError(\"You are passing a target array of shape \" + y.shape + \" while using \" + \"a loss 'categorical_crossentropy'. 'categorical_crossentropy'\" + \"expects targets to be binary matrices (1s and 0s) of shape \" + \"[samples, classes].\");\n      }\n    }\n\n    if (keyLosses.indexOf(loss) !== -1) {\n      var slicedYShape = y.shape.slice(1);\n      var slicedShape = shape.slice(1);\n\n      for (var j = 0; j < slicedYShape.length; ++j) {\n        var targetDim = slicedYShape[j];\n        var outDim = slicedShape[j];\n\n        if (outDim != null && targetDim !== outDim) {\n          throw new ValueError(\"A target Tensor with shape \" + y.shape + \" was passed for an \" + (\"output of shape \" + shape + \", while using a loss function that \") + \"expects targets to have the same shape as the output.\");\n        }\n      }\n    }\n  }\n}\n\nfunction checkInputData(data, names, shapes) {\n  var checkBatchAxis = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : true;\n  var exceptionPrefix = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : '';\n  var arrays;\n\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" + \"Tensors that you are passing to your model is not the size the \" + (\"the model expected. Expected to see \" + names.length + \" Tensor(s),\") + (\" but instead got \" + data.length + \" Tensors(s).\"));\n    }\n\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new ValueError(\"The model expects \" + names.length + \" \" + exceptionPrefix + \" Tensors, \" + \"but only received one Tensor. Found: array with shape \" + (JSON.stringify(data.shape) + \".\"));\n    }\n\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have \" + shapes[i].length + \" dimension(s), but got array with \") + (\"shape \" + JSON.stringify(array.shape)));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + (names[i] + \" to have shape \" + JSON.stringify(shapes[i]) + \" but \") + (\"got array with shape \" + JSON.stringify(array.shape) + \".\"));\n          }\n        }\n      }\n    }\n  }\n}\n\nexport function collectMetrics(metrics, outputNames) {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(function (name) {\n      return [];\n    });\n  }\n\n  var wrappedMetrics;\n\n  if (typeof metrics === 'string' || typeof metrics === 'function') {\n    wrappedMetrics = [metrics];\n  } else if (Array.isArray(metrics) || typeof metrics === 'object') {\n    wrappedMetrics = metrics;\n  } else {\n    throw new TypeError('Type of metrics argument not understood. Expected an string,' + (\"function, Array, or Object, found: \" + metrics));\n  }\n\n  if (Array.isArray(wrappedMetrics)) {\n    return outputNames.map(function (name) {\n      return wrappedMetrics;\n    });\n  } else {\n    var nestedMetrics = [];\n\n    for (var _iterator2 = _createForOfIteratorHelperLoose(outputNames), _step2; !(_step2 = _iterator2()).done;) {\n      var name = _step2.value;\n      var outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n\n      if (!Array.isArray(outputMetrics)) {\n        outputMetrics = [outputMetrics];\n      }\n\n      nestedMetrics.push(outputMetrics);\n    }\n\n    return nestedMetrics;\n  }\n}\nvar LAYERS_MODEL_FORMAT_NAME = 'layers-model';\nexport var LayersModel = function (_Container) {\n  _inherits(LayersModel, _Container);\n\n  var _super = _createSuper(LayersModel);\n\n  function LayersModel(args) {\n    var _this;\n\n    _classCallCheck(this, LayersModel);\n\n    _this = _super.call(this, args);\n    _this.isTraining = false;\n    return _this;\n  }\n\n  _createClass(LayersModel, [{\n    key: \"summary\",\n    value: function summary(lineLength, positions) {\n      var printFn = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n\n      if (!this.built) {\n        throw new ValueError(\"This model has never been called, thus its weights have not been \" + \"created yet. So no summary can be displayed. Build the model \" + \"first (e.g., by calling it on some test data).\");\n      }\n\n      printSummary(this, lineLength, positions, printFn);\n    }\n  }, {\n    key: \"compile\",\n    value: function compile(args) {\n      var _this2 = this;\n\n      if (args.loss == null) {\n        args.loss = [];\n      }\n\n      this.loss = args.loss;\n\n      if (typeof args.optimizer === 'string') {\n        this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n        this.isOptimizerOwned = true;\n      } else {\n        if (!(args.optimizer instanceof Optimizer)) {\n          throw new ValueError(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n        }\n\n        this.optimizer_ = args.optimizer;\n        this.isOptimizerOwned = false;\n      }\n\n      var lossFunctions = [];\n\n      if (!Array.isArray(args.loss) && typeof args.loss !== 'string' && typeof args.loss !== 'function') {\n        args.loss = args.loss;\n\n        for (var name in args.loss) {\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new ValueError(\"Unknown entry in loss dictionary: \\\"\" + name + \"\\\". \" + (\"Only expected the following keys: \" + this.outputNames));\n          }\n        }\n\n        for (var _iterator3 = _createForOfIteratorHelperLoose(this.outputNames), _step3; !(_step3 = _iterator3()).done;) {\n          var _name = _step3.value;\n\n          if (args.loss[_name] == null) {\n            console.warn(\"Output \\\"\" + _name + \"\\\" is missing from loss dictionary. We assume \" + \"this was done on purpose, and we will not be expecting data \" + (\"to be passed to \" + _name + \" during training\"));\n          }\n\n          lossFunctions.push(losses.get(args.loss[_name]));\n        }\n      } else if (Array.isArray(args.loss)) {\n        if (args.loss.length !== this.outputs.length) {\n          throw new ValueError(\"When passing an Array as loss, it should have one entry per \" + (\"model output. The model has \" + this.outputs.length + \" output(s), \") + (\"but you passed loss=\" + args.loss + \".\"));\n        }\n\n        var theLosses = args.loss;\n        lossFunctions = theLosses.map(function (l) {\n          return losses.get(l);\n        });\n      } else {\n        var lossFunction = losses.get(args.loss);\n        this.outputs.forEach(function (_) {\n          lossFunctions.push(lossFunction);\n        });\n      }\n\n      this.lossFunctions = lossFunctions;\n      this.feedOutputNames = [];\n      this.feedOutputShapes = [];\n      this.feedLossFns = [];\n\n      for (var i = 0; i < this.outputs.length; ++i) {\n        var shape = this.internalOutputShapes[i];\n        var _name2 = this.outputNames[i];\n        this.feedOutputNames.push(_name2);\n        this.feedOutputShapes.push(shape);\n        this.feedLossFns.push(this.lossFunctions[i]);\n      }\n\n      var skipTargetIndices = [];\n      this.metrics = args.metrics;\n      this.metricsNames = ['loss'];\n      this.metricsTensors = [];\n      nameScope('loss', function () {\n        for (var _i = 0; _i < _this2.outputs.length; ++_i) {\n          if (skipTargetIndices.indexOf(_i) !== -1) {\n            continue;\n          }\n\n          var weightedLoss = _this2.lossFunctions[_i];\n\n          if (_this2.outputs.length > 1) {\n            _this2.metricsTensors.push([weightedLoss, _i]);\n\n            _this2.metricsNames.push(_this2.outputNames[_i] + '_loss');\n          }\n        }\n      });\n      var nestedMetrics = collectMetrics(args.metrics, this.outputNames);\n\n      var appendMetric = function appendMetric(outputIndex, metricName, metricTensor) {\n        if (_this2.outputNames.length > 1) {\n          metricName = _this2.outputNames[outputIndex] + '_' + metricName;\n        }\n\n        _this2.metricsNames.push(metricName);\n\n        _this2.metricsTensors.push([metricTensor, outputIndex]);\n      };\n\n      nameScope('metric', function () {\n        var _loop = function _loop(_i2) {\n          if (skipTargetIndices.indexOf(_i2) !== -1) {\n            return \"continue\";\n          }\n\n          var outputMetrics = nestedMetrics[_i2];\n\n          var handleMetrics = function handleMetrics(metrics) {\n            var metricNamePrefix = '';\n            var metricName;\n            var accFn;\n            var weightedMetricFn;\n\n            for (var _iterator4 = _createForOfIteratorHelperLoose(metrics), _step4; !(_step4 = _iterator4()).done;) {\n              var metric = _step4.value;\n\n              if (typeof metric === 'string' && ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !== -1) {\n                var outputShape = _this2.internalOutputShapes[_i2];\n\n                if (outputShape[outputShape.length - 1] === 1 || _this2.lossFunctions[_i2] === losses.binaryCrossentropy) {\n                  if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                    accFn = Metrics.binaryAccuracy;\n                  } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                    accFn = Metrics.binaryCrossentropy;\n                  }\n                } else if (_this2.lossFunctions[_i2] === losses.sparseCategoricalCrossentropy) {\n                  if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                    accFn = Metrics.sparseCategoricalAccuracy;\n                  } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                    accFn = Metrics.sparseCategoricalCrossentropy;\n                  }\n                } else {\n                  if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                    accFn = Metrics.categoricalAccuracy;\n                  } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                    accFn = Metrics.categoricalCrossentropy;\n                  }\n                }\n\n                var suffix = void 0;\n\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  suffix = 'acc';\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  suffix = 'ce';\n                }\n\n                weightedMetricFn = accFn;\n                metricName = metricNamePrefix + suffix;\n              } else {\n                var metricFn = Metrics.get(metric);\n                weightedMetricFn = metricFn;\n                metricName = metricNamePrefix + Metrics.getLossOrMetricName(metric);\n              }\n\n              var metricResult = void 0;\n              nameScope(metricName, function () {\n                metricResult = weightedMetricFn;\n              });\n              appendMetric(_i2, metricName, metricResult);\n            }\n          };\n\n          handleMetrics(outputMetrics);\n        };\n\n        for (var _i2 = 0; _i2 < _this2.outputs.length; ++_i2) {\n          var _ret = _loop(_i2);\n\n          if (_ret === \"continue\") continue;\n        }\n      });\n      this.collectedTrainableWeights = this.trainableWeights;\n    }\n  }, {\n    key: \"checkTrainableWeightsConsistency\",\n    value: function checkTrainableWeightsConsistency() {\n      if (this.collectedTrainableWeights == null) {\n        return;\n      }\n\n      if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {\n        console.warn('Discrepancy between trainableweights and collected trainable ' + 'weights. Did you set `model.trainable` without calling ' + '`model.compile()` afterwards?');\n      }\n    }\n  }, {\n    key: \"evaluate\",\n    value: function evaluate(x, y) {\n      var args = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n      var batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize);\n      var checkBatchAxis = true;\n      var standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n\n      try {\n        var ins = standardizedOuts[0].concat(standardizedOuts[1]);\n        this.makeTestFunction();\n        var f = this.testFunction;\n        var testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n        return singletonOrArray(testOuts);\n      } finally {\n        disposeNewTensors(standardizedOuts[0], x);\n        disposeNewTensors(standardizedOuts[1], y);\n      }\n    }\n  }, {\n    key: \"evaluateDataset\",\n    value: function evaluateDataset(dataset, args) {\n      return _regeneratorRuntime.async(function evaluateDataset$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              this.makeTestFunction();\n              return _context.abrupt(\"return\", _evaluateDataset(this, dataset, args));\n\n            case 2:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"checkNumSamples\",\n    value: function checkNumSamples(ins, batchSize, steps) {\n      var stepsName = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'steps';\n      var numSamples;\n\n      if (steps != null) {\n        numSamples = null;\n\n        if (batchSize != null) {\n          throw new ValueError(\"If \" + stepsName + \" is set, batchSize must be null or undefined.\" + (\"Got batchSize = \" + batchSize));\n        }\n      } else if (ins != null) {\n        if (Array.isArray(ins)) {\n          numSamples = ins[0].shape[0];\n        } else {\n          numSamples = ins.shape[0];\n        }\n      } else {\n        throw new ValueError(\"Either the input data should have a defined shape, or \" + (stepsName + \" shoud be specified.\"));\n      }\n\n      return numSamples;\n    }\n  }, {\n    key: \"execute\",\n    value: function execute(inputs, outputs) {\n      if (Array.isArray(outputs) && outputs.length === 0) {\n        throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n      }\n\n      var outputsIsArray = Array.isArray(outputs);\n      var outputNames = outputsIsArray ? outputs : [outputs];\n      var outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);\n      var feedDict = new FeedDict();\n\n      if (inputs instanceof Tensor) {\n        inputs = [inputs];\n      }\n\n      if (Array.isArray(inputs)) {\n        if (inputs.length !== this.inputs.length) {\n          throw new ValueError(\"The number of inputs provided (\" + inputs.length + \") \" + \"does not match the number of inputs of this model \" + (\"(\" + this.inputs.length + \").\"));\n        }\n\n        for (var i = 0; i < this.inputs.length; ++i) {\n          feedDict.add(this.inputs[i], inputs[i]);\n        }\n      } else {\n        for (var _iterator5 = _createForOfIteratorHelperLoose(this.inputs), _step5; !(_step5 = _iterator5()).done;) {\n          var input = _step5.value;\n          var tensorValue = inputs[input.name];\n\n          if (tensorValue == null) {\n            throw new ValueError(\"No value is provided for the model's input \" + input.name);\n          }\n\n          feedDict.add(input, tensorValue);\n        }\n      }\n\n      var executeOutputs = _execute(outputSymbolicTensors, feedDict);\n\n      return outputsIsArray ? executeOutputs : executeOutputs[0];\n    }\n  }, {\n    key: \"retrieveSymbolicTensors\",\n    value: function retrieveSymbolicTensors(symbolicTensorNames) {\n      var outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n      var outputsRemaining = symbolicTensorNames.length;\n\n      for (var _iterator6 = _createForOfIteratorHelperLoose(this.layers), _step6; !(_step6 = _iterator6()).done;) {\n        var layer = _step6.value;\n        var layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n        var layerOutputNames = layerOutputs.map(function (output) {\n          return output.name;\n        });\n\n        for (var i = 0; i < symbolicTensorNames.length; ++i) {\n          var index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n\n          if (index !== -1) {\n            outputSymbolicTensors[i] = layerOutputs[index];\n            outputsRemaining--;\n          }\n\n          if (outputsRemaining === 0) {\n            break;\n          }\n        }\n\n        if (outputsRemaining === 0) {\n          break;\n        }\n      }\n\n      if (outputsRemaining > 0) {\n        var remainingNames = [];\n        outputSymbolicTensors.forEach(function (tensor, i) {\n          if (tensor == null) {\n            remainingNames.push(symbolicTensorNames[i]);\n          }\n        });\n        throw new ValueError(\"Cannot find SymbolicTensors for output name(s): \" + (\"\" + JSON.stringify(remainingNames)));\n      }\n\n      return outputSymbolicTensors;\n    }\n  }, {\n    key: \"predictLoop\",\n    value: function predictLoop(ins) {\n      var _this3 = this;\n\n      var batchSize = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;\n      var verbose = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      return tfc.tidy(function () {\n        var numSamples = _this3.checkNumSamples(ins);\n\n        if (verbose) {\n          throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n        }\n\n        var batches = makeBatches(numSamples, batchSize);\n\n        var outsBatches = _this3.outputs.map(function (output) {\n          return [];\n        });\n\n        var _loop2 = function _loop2(batchIndex) {\n          var batchOuts = tfc.tidy(function () {\n            var batchStart = batches[batchIndex][0];\n            var batchEnd = batches[batchIndex][1];\n            var insBatch = sliceArrays(ins, batchStart, batchEnd);\n            var feeds = [];\n\n            if (Array.isArray(insBatch)) {\n              for (var i = 0; i < insBatch.length; ++i) {\n                feeds.push({\n                  key: _this3.inputs[i],\n                  value: insBatch[i]\n                });\n              }\n            } else {\n              feeds.push({\n                key: _this3.inputs[0],\n                value: insBatch\n              });\n            }\n\n            var feedDict = new FeedDict(feeds);\n            return _execute(_this3.outputs, feedDict);\n          });\n          batchOuts.forEach(function (batchOut, i) {\n            return outsBatches[i].push(batchOut);\n          });\n        };\n\n        for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          _loop2(batchIndex);\n        }\n\n        return singletonOrArray(outsBatches.map(function (batches) {\n          return tfc.concat(batches, 0);\n        }));\n      });\n    }\n  }, {\n    key: \"predict\",\n    value: function predict(x) {\n      var args = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n      var xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n      checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n\n      try {\n        var batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        return this.predictLoop(xsRank2OrHigher, batchSize);\n      } finally {\n        disposeNewTensors(xsRank2OrHigher, x);\n      }\n    }\n  }, {\n    key: \"predictOnBatch\",\n    value: function predictOnBatch(x) {\n      checkInputData(x, this.inputNames, this.feedInputShapes, true);\n      var batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n      return this.predictLoop(x, batchSize);\n    }\n  }, {\n    key: \"standardizeUserDataXY\",\n    value: function standardizeUserDataXY(x, y) {\n      var checkBatchAxis = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n      var batchSize = arguments.length > 3 ? arguments[3] : undefined;\n\n      if (this.optimizer_ == null) {\n        throw new RuntimeError('You must compile a model before training/testing. Use ' + 'LayersModel.compile(modelCompileArgs).');\n      }\n\n      var outputShapes = [];\n\n      for (var i = 0; i < this.feedOutputShapes.length; ++i) {\n        var outputShape = this.feedOutputShapes[i];\n        var lossFn = this.feedLossFns[i];\n\n        if (lossFn === losses.sparseCategoricalCrossentropy) {\n          outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n        } else {\n          outputShapes.push(outputShape);\n        }\n      }\n\n      x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n      y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target');\n      checkArrayLengths(x, y, null);\n      checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n\n      if (this.stateful && batchSize != null && batchSize > 0) {\n        if (x[0].shape[0] % batchSize !== 0) {\n          throw new ValueError(\"In a stateful network, you should only pass inputs with a \" + \"number of samples that is divisible by the batch size \" + (batchSize + \". Found: \" + x[0].shape[0] + \" sample(s).\"));\n        }\n      }\n\n      return [x, y];\n    }\n  }, {\n    key: \"standardizeUserData\",\n    value: function standardizeUserData(x, y, sampleWeight, classWeight) {\n      var checkBatchAxis,\n          batchSize,\n          _this$standardizeUser,\n          _this$standardizeUser2,\n          standardXs,\n          standardYs,\n          standardSampleWeights,\n          classWeights,\n          i,\n          _args2 = arguments;\n\n      return _regeneratorRuntime.async(function standardizeUserData$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              checkBatchAxis = _args2.length > 4 && _args2[4] !== undefined ? _args2[4] : true;\n              batchSize = _args2.length > 5 ? _args2[5] : undefined;\n              _this$standardizeUser = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize), _this$standardizeUser2 = _slicedToArray(_this$standardizeUser, 2), standardXs = _this$standardizeUser2[0], standardYs = _this$standardizeUser2[1];\n\n              if (!(sampleWeight != null)) {\n                _context2.next = 5;\n                break;\n              }\n\n              throw new Error('sample weight is not supported yet.');\n\n            case 5:\n              standardSampleWeights = null;\n\n              if (!(classWeight != null)) {\n                _context2.next = 19;\n                break;\n              }\n\n              classWeights = standardizeClassWeights(classWeight, this.outputNames);\n              standardSampleWeights = [];\n              i = 0;\n\n            case 10:\n              if (!(i < classWeights.length)) {\n                _context2.next = 19;\n                break;\n              }\n\n              _context2.t0 = standardSampleWeights;\n              _context2.next = 14;\n              return _regeneratorRuntime.awrap(standardizeWeights(standardYs[i], null, classWeights[i]));\n\n            case 14:\n              _context2.t1 = _context2.sent;\n\n              _context2.t0.push.call(_context2.t0, _context2.t1);\n\n            case 16:\n              ++i;\n              _context2.next = 10;\n              break;\n\n            case 19:\n              return _context2.abrupt(\"return\", [standardXs, standardYs, standardSampleWeights]);\n\n            case 20:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"testLoop\",\n    value: function testLoop(f, ins, batchSize) {\n      var _this4 = this;\n\n      var verbose = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n      var steps = arguments.length > 4 ? arguments[4] : undefined;\n      return tfc.tidy(function () {\n        var numSamples = _this4.checkNumSamples(ins, batchSize, steps, 'steps');\n\n        var outs = [];\n\n        if (verbose > 0) {\n          throw new NotImplementedError('Verbose mode is not implemented yet.');\n        }\n\n        if (steps != null) {\n          throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n        } else {\n          var batches = makeBatches(numSamples, batchSize);\n          var indexArray = tensor1d(range(0, numSamples));\n\n          for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n            var batchStart = batches[batchIndex][0];\n            var batchEnd = batches[batchIndex][1];\n            var batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);\n            var insBatch = sliceArraysByIndices(ins, batchIds);\n            var batchOuts = f(insBatch);\n\n            if (batchIndex === 0) {\n              for (var i = 0; i < batchOuts.length; ++i) {\n                outs.push(scalar(0));\n              }\n            }\n\n            for (var _i3 = 0; _i3 < batchOuts.length; ++_i3) {\n              var batchOut = batchOuts[_i3];\n              outs[_i3] = tfc.add(outs[_i3], tfc.mul(batchEnd - batchStart, batchOut));\n            }\n          }\n\n          for (var _i4 = 0; _i4 < outs.length; ++_i4) {\n            outs[_i4] = tfc.div(outs[_i4], numSamples);\n          }\n        }\n\n        return outs;\n      });\n    }\n  }, {\n    key: \"getDedupedMetricsNames\",\n    value: function getDedupedMetricsNames() {\n      var outLabels = this.metricsNames;\n      var dedupedOutLabels = [];\n\n      for (var i = 0; i < outLabels.length; ++i) {\n        var label = outLabels[i];\n        var newLabel = label;\n\n        if (count(outLabels, label) > 1) {\n          var dupIndex = count(outLabels.slice(0, i), label);\n          newLabel += \"_\" + dupIndex;\n        }\n\n        dedupedOutLabels.push(newLabel);\n      }\n\n      return dedupedOutLabels;\n    }\n  }, {\n    key: \"makeTrainFunction\",\n    value: function makeTrainFunction() {\n      var _this5 = this;\n\n      return function (data) {\n        var lossValues = [];\n        var inputs = data.slice(0, _this5.inputs.length);\n        var targets = data.slice(_this5.inputs.length, _this5.inputs.length + _this5.outputs.length);\n        var sampleWeights = data.slice(_this5.inputs.length + _this5.outputs.length, _this5.inputs.length + _this5.outputs.length * 2);\n        var metricsValues = [];\n\n        var totalLossFunction = function totalLossFunction() {\n          var feeds = [];\n\n          for (var i = 0; i < _this5.inputs.length; ++i) {\n            feeds.push({\n              key: _this5.inputs[i],\n              value: inputs[i]\n            });\n          }\n\n          var feedDict = new FeedDict(feeds);\n\n          var outputs = _execute(_this5.outputs, feedDict, {\n            'training': true\n          });\n\n          var totalLoss;\n\n          for (var _i5 = 0; _i5 < _this5.lossFunctions.length; ++_i5) {\n            var lossFunction = _this5.lossFunctions[_i5];\n            var loss = lossFunction(targets[_i5], outputs[_i5]);\n\n            if (sampleWeights[_i5] != null) {\n              loss = computeWeightedLoss(loss, sampleWeights[_i5]);\n            }\n\n            var meanLoss = tfc.mean(loss);\n            lossValues.push(meanLoss);\n\n            if (_i5 === 0) {\n              totalLoss = loss;\n            } else {\n              totalLoss = tfc.add(totalLoss, loss);\n            }\n          }\n\n          for (var _i6 = 0; _i6 < _this5.metricsTensors.length; ++_i6) {\n            var weightedMetric = void 0;\n\n            if (_this5.outputs.length > 1 && _i6 < _this5.outputs.length) {\n              weightedMetric = lossValues[_i6];\n            } else {\n              var metric = _this5.metricsTensors[_i6][0];\n              var outputIndex = _this5.metricsTensors[_i6][1];\n              weightedMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n            }\n\n            tfc.keep(weightedMetric);\n            metricsValues.push(weightedMetric);\n          }\n\n          totalLoss = tfc.mean(totalLoss);\n\n          _this5.calculateLosses().forEach(function (regularizerLoss) {\n            totalLoss = tfc.add(totalLoss, regularizerLoss);\n          });\n\n          return totalLoss;\n        };\n\n        var variables = _this5.collectedTrainableWeights.map(function (param) {\n          return param.read();\n        });\n\n        var returnCost = true;\n\n        var totalLossValue = _this5.optimizer_.minimize(totalLossFunction, returnCost, variables);\n\n        return [totalLossValue].concat(metricsValues);\n      };\n    }\n  }, {\n    key: \"makeTestFunction\",\n    value: function makeTestFunction() {\n      var _this6 = this;\n\n      this.testFunction = function (data) {\n        return tfc.tidy(function () {\n          var valOutputs = [];\n          var totalLoss;\n          var inputs = data.slice(0, _this6.inputs.length);\n          var targets = data.slice(_this6.inputs.length, _this6.inputs.length + _this6.outputs.length);\n          var feeds = [];\n\n          for (var i = 0; i < _this6.inputs.length; ++i) {\n            feeds.push({\n              key: _this6.inputs[i],\n              value: inputs[i]\n            });\n          }\n\n          var feedDict = new FeedDict(feeds);\n\n          var outputs = _execute(_this6.outputs, feedDict);\n\n          for (var _i7 = 0; _i7 < _this6.lossFunctions.length; ++_i7) {\n            var lossFunction = _this6.lossFunctions[_i7];\n            var loss = tfc.mean(lossFunction(targets[_i7], outputs[_i7]));\n\n            if (_i7 === 0) {\n              totalLoss = loss;\n            } else {\n              totalLoss = tfc.add(totalLoss, loss);\n            }\n\n            valOutputs.push(totalLoss);\n          }\n\n          for (var _i8 = 0; _i8 < _this6.metricsTensors.length; ++_i8) {\n            var metric = _this6.metricsTensors[_i8][0];\n            var outputIndex = _this6.metricsTensors[_i8][1];\n            var meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n            valOutputs.push(meanMetric);\n          }\n\n          return valOutputs;\n        });\n      };\n    }\n  }, {\n    key: \"fit\",\n    value: function fit(x, y) {\n      var args,\n          _args3 = arguments;\n      return _regeneratorRuntime.async(function fit$(_context3) {\n        while (1) {\n          switch (_context3.prev = _context3.next) {\n            case 0:\n              args = _args3.length > 2 && _args3[2] !== undefined ? _args3[2] : {};\n              return _context3.abrupt(\"return\", fitTensors(this, x, y, args));\n\n            case 2:\n            case \"end\":\n              return _context3.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"fitDataset\",\n    value: function fitDataset(dataset, args) {\n      return _regeneratorRuntime.async(function fitDataset$(_context4) {\n        while (1) {\n          switch (_context4.prev = _context4.next) {\n            case 0:\n              return _context4.abrupt(\"return\", _fitDataset(this, dataset, args));\n\n            case 1:\n            case \"end\":\n              return _context4.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"trainOnBatch\",\n    value: function trainOnBatch(x, y) {\n      var standardizeOut, inputs, targets, trainFunction, losses, lossValues, _iterator7, _step7, loss, v;\n\n      return _regeneratorRuntime.async(function trainOnBatch$(_context5) {\n        while (1) {\n          switch (_context5.prev = _context5.next) {\n            case 0:\n              _context5.next = 2;\n              return _regeneratorRuntime.awrap(this.standardizeUserData(x, y));\n\n            case 2:\n              standardizeOut = _context5.sent;\n              inputs = standardizeOut[0];\n              targets = standardizeOut[1];\n              trainFunction = this.makeTrainFunction();\n              losses = trainFunction(inputs.concat(targets));\n              lossValues = [];\n              _iterator7 = _createForOfIteratorHelperLoose(losses);\n\n            case 9:\n              if ((_step7 = _iterator7()).done) {\n                _context5.next = 17;\n                break;\n              }\n\n              loss = _step7.value;\n              _context5.next = 13;\n              return _regeneratorRuntime.awrap(loss.data());\n\n            case 13:\n              v = _context5.sent;\n              lossValues.push(v[0]);\n\n            case 15:\n              _context5.next = 9;\n              break;\n\n            case 17:\n              tfc.dispose(losses);\n              return _context5.abrupt(\"return\", singletonOrArray(lossValues));\n\n            case 19:\n            case \"end\":\n              return _context5.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"getNamedWeights\",\n    value: function getNamedWeights(config) {\n      var namedWeights = [];\n      var trainableOnly = config != null && config.trainableOnly;\n      var weights = trainableOnly ? this.trainableWeights : this.weights;\n      var weightValues = this.getWeights(trainableOnly);\n\n      for (var i = 0; i < weights.length; ++i) {\n        if (trainableOnly && !weights[i].trainable) {\n          continue;\n        }\n\n        namedWeights.push({\n          name: weights[i].originalName,\n          tensor: weightValues[i]\n        });\n      }\n\n      return namedWeights;\n    }\n  }, {\n    key: \"stopTraining\",\n    get: function get() {\n      return this.stopTraining_;\n    },\n    set: function set(stop) {\n      this.stopTraining_ = stop;\n    }\n  }, {\n    key: \"optimizer\",\n    get: function get() {\n      return this.optimizer_;\n    },\n    set: function set(optimizer) {\n      if (this.optimizer_ !== optimizer) {\n        this.optimizer_ = optimizer;\n        this.isOptimizerOwned = false;\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var result = _get(_getPrototypeOf(LayersModel.prototype), \"dispose\", this).call(this);\n\n      if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {\n        var numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n        this.optimizer_.dispose();\n        result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n      }\n\n      return result;\n    }\n  }, {\n    key: \"getLossIdentifiers\",\n    value: function getLossIdentifiers() {\n      var lossNames;\n\n      if (typeof this.loss === 'string') {\n        lossNames = toSnakeCase(this.loss);\n      } else if (Array.isArray(this.loss)) {\n        for (var _iterator8 = _createForOfIteratorHelperLoose(this.loss), _step8; !(_step8 = _iterator8()).done;) {\n          var loss = _step8.value;\n\n          if (typeof loss !== 'string') {\n            throw new Error('Serialization of non-string loss is not supported.');\n          }\n        }\n\n        lossNames = this.loss.map(function (name) {\n          return toSnakeCase(name);\n        });\n      } else {\n        var outputNames = Object.keys(this.loss);\n        lossNames = {};\n        var _losses = this.loss;\n\n        for (var _i9 = 0, _outputNames = outputNames; _i9 < _outputNames.length; _i9++) {\n          var outputName = _outputNames[_i9];\n\n          if (typeof _losses[outputName] === 'string') {\n            lossNames[outputName] = toSnakeCase(_losses[outputName]);\n          } else {\n            throw new Error('Serialization of non-string loss is not supported.');\n          }\n        }\n      }\n\n      return lossNames;\n    }\n  }, {\n    key: \"getMetricIdentifiers\",\n    value: function getMetricIdentifiers() {\n      if (typeof this.metrics === 'string' || typeof this.metrics === 'function') {\n        return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n      } else if (Array.isArray(this.metrics)) {\n        return this.metrics.map(function (metric) {\n          return toSnakeCase(Metrics.getLossOrMetricName(metric));\n        });\n      } else {\n        var metricsIdentifiers = {};\n\n        for (var key in this.metrics) {\n          metricsIdentifiers[key] = toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n        }\n\n        return metricsIdentifiers;\n      }\n    }\n  }, {\n    key: \"getTrainingConfig\",\n    value: function getTrainingConfig() {\n      return {\n        loss: this.getLossIdentifiers(),\n        metrics: this.getMetricIdentifiers(),\n        optimizer_config: {\n          class_name: this.optimizer.getClassName(),\n          config: this.optimizer.getConfig()\n        }\n      };\n    }\n  }, {\n    key: \"loadTrainingConfig\",\n    value: function loadTrainingConfig(trainingConfig) {\n      if (trainingConfig.weighted_metrics != null) {\n        throw new Error('Loading weight_metrics is not supported yet.');\n      }\n\n      if (trainingConfig.loss_weights != null) {\n        throw new Error('Loading loss_weights is not supported yet.');\n      }\n\n      if (trainingConfig.sample_weight_mode != null) {\n        throw new Error('Loading sample_weight_mode is not supported yet.');\n      }\n\n      var tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n      var optimizer = deserialize(tsConfig);\n      var loss;\n\n      if (typeof trainingConfig.loss === 'string') {\n        loss = toCamelCase(trainingConfig.loss);\n      } else if (Array.isArray(trainingConfig.loss)) {\n        loss = trainingConfig.loss.map(function (lossEntry) {\n          return toCamelCase(lossEntry);\n        });\n      } else if (trainingConfig.loss != null) {\n        loss = {};\n\n        for (var key in trainingConfig.loss) {\n          loss[key] = toCamelCase(trainingConfig.loss[key]);\n        }\n      }\n\n      var metrics;\n\n      if (Array.isArray(trainingConfig.metrics)) {\n        metrics = trainingConfig.metrics.map(function (metric) {\n          return toCamelCase(metric);\n        });\n      } else if (trainingConfig.metrics != null) {\n        metrics = {};\n\n        for (var _key in trainingConfig.metrics) {\n          metrics[_key] = toCamelCase(trainingConfig.metrics[_key]);\n        }\n      }\n\n      this.compile({\n        loss: loss,\n        metrics: metrics,\n        optimizer: optimizer\n      });\n    }\n  }, {\n    key: \"save\",\n    value: function save(handlerOrURL, config) {\n      var handlers, weightDataAndSpecs, returnString, unusedArg, modelConfig, modelArtifacts, includeOptimizer, _weightDataAndSpecs$s, weightType, _await$io$encodeWeigh, optimizerWeightData, optimizerWeightSpecs, checkSize;\n\n      return _regeneratorRuntime.async(function save$(_context6) {\n        while (1) {\n          switch (_context6.prev = _context6.next) {\n            case 0:\n              if (!(typeof handlerOrURL === 'string')) {\n                _context6.next = 9;\n                break;\n              }\n\n              handlers = io.getSaveHandlers(handlerOrURL);\n\n              if (!(handlers.length === 0)) {\n                _context6.next = 6;\n                break;\n              }\n\n              throw new ValueError(\"Cannot find any save handlers for URL '\" + handlerOrURL + \"'\");\n\n            case 6:\n              if (!(handlers.length > 1)) {\n                _context6.next = 8;\n                break;\n              }\n\n              throw new ValueError(\"Found more than one (\" + handlers.length + \") save handlers for \" + (\"URL '\" + handlerOrURL + \"'\"));\n\n            case 8:\n              handlerOrURL = handlers[0];\n\n            case 9:\n              if (!(handlerOrURL.save == null)) {\n                _context6.next = 11;\n                break;\n              }\n\n              throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' + 'provided does not have the `save` attribute defined.');\n\n            case 11:\n              _context6.next = 13;\n              return _regeneratorRuntime.awrap(io.encodeWeights(this.getNamedWeights(config)));\n\n            case 13:\n              weightDataAndSpecs = _context6.sent;\n              returnString = false;\n              unusedArg = null;\n              modelConfig = this.toJSON(unusedArg, returnString);\n              modelArtifacts = {\n                modelTopology: modelConfig,\n                format: LAYERS_MODEL_FORMAT_NAME,\n                generatedBy: \"TensorFlow.js tfjs-layers v\" + version,\n                convertedBy: null\n              };\n              includeOptimizer = config == null ? false : config.includeOptimizer;\n\n              if (!(includeOptimizer && this.optimizer != null)) {\n                _context6.next = 36;\n                break;\n              }\n\n              modelArtifacts.trainingConfig = this.getTrainingConfig();\n              weightType = 'optimizer';\n              _context6.t0 = _regeneratorRuntime;\n              _context6.t1 = io;\n              _context6.next = 26;\n              return _regeneratorRuntime.awrap(this.optimizer.getWeights());\n\n            case 26:\n              _context6.t2 = _context6.sent;\n              _context6.t3 = weightType;\n              _context6.t4 = _context6.t1.encodeWeights.call(_context6.t1, _context6.t2, _context6.t3);\n              _context6.next = 31;\n              return _context6.t0.awrap.call(_context6.t0, _context6.t4);\n\n            case 31:\n              _await$io$encodeWeigh = _context6.sent;\n              optimizerWeightData = _await$io$encodeWeigh.data;\n              optimizerWeightSpecs = _await$io$encodeWeigh.specs;\n\n              (_weightDataAndSpecs$s = weightDataAndSpecs.specs).push.apply(_weightDataAndSpecs$s, _toConsumableArray(optimizerWeightSpecs));\n\n              weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n\n            case 36:\n              if (this.userDefinedMetadata != null) {\n                checkSize = true;\n                checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n                modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n              }\n\n              modelArtifacts.weightData = weightDataAndSpecs.data;\n              modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n              return _context6.abrupt(\"return\", handlerOrURL.save(modelArtifacts));\n\n            case 40:\n            case \"end\":\n              return _context6.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"setUserDefinedMetadata\",\n    value: function setUserDefinedMetadata(userDefinedMetadata) {\n      checkUserDefinedMetadata(userDefinedMetadata, this.name);\n      this.userDefinedMetadata = userDefinedMetadata;\n    }\n  }, {\n    key: \"getUserDefinedMetadata\",\n    value: function getUserDefinedMetadata() {\n      return this.userDefinedMetadata;\n    }\n  }]);\n\n  return LayersModel;\n}(Container);\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\nexport var Functional = function (_LayersModel) {\n  _inherits(Functional, _LayersModel);\n\n  var _super2 = _createSuper(Functional);\n\n  function Functional() {\n    _classCallCheck(this, Functional);\n\n    return _super2.apply(this, arguments);\n  }\n\n  return _createClass(Functional);\n}(LayersModel);\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);","map":{"version":3,"sources":["../../src/engine/training.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;AAQG;AAIH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAQ,EAAR,EAAoE,SAApE,EAAuF,MAAvF,EAA+F,aAA/F,EAA8G,MAA9G,EAAgI,QAAhI,EAA0I,IAA1I,QAAqJ,uBAArJ;AAEA,OAAO,KAAK,CAAZ;AAEA,SAAQ,SAAR;AACA,SAAQ,mBAAR,EAA6B,YAA7B,EAA2C,UAA3C;AAKA,SAAQ,WAAR;AACA,OAAO,KAAK,MAAZ;AACA,OAAO,KAAK,OAAZ;AACA,OAAO,KAAK,UAAZ;AAEA,SAAQ,wBAAR;AACA,SAAQ,KAAR,EAAe,YAAf,EAA6B,gBAA7B,EAA+C,WAA/C,EAA4D,WAA5D,EAAyE,MAAzE;AACA,SAAQ,YAAR;AACA,SAAQ,KAAR;AACA,SAAQ,mBAAR;AAEA,SAAQ,OAAR;AAEA,SAAQ,SAAR;AAEA,SAAQ,OAAO,IAAP,QAAR,EAAiB,QAAjB;AAEA,SAAQ,eAAe,IAAf,gBAAR,EAAyB,UAAU,IAAV,WAAzB;AACA,SAAQ,cAAR,EAAwB,iBAAxB,EAA2C,0BAA3C,EAAuE,UAAvE,EAAmF,WAAnF,EAA8G,WAA9G,EAA2H,oBAA3H;AACA,SAAqC,mBAArC,EAA0D,uBAA1D,EAAmF,kBAAnF;AAKA,OAAM,SAAU,YAAV,CAAuB,CAAvB,EACsD;EAC1D,OAAO,CAAC,YAAY,MAApB;AACD;AAKD,OAAM,SAAU,WAAV,CAAsB,CAAtB,EACmD;EACvD,OAAO,KAAK,CAAC,OAAN,CAAc,CAAd,CAAP;AACD;AAKD,OAAM,SAAU,UAAV,CAAqB,CAArB,EACkD;EACtD,OAAO,CAAC,YAAY,CAAC,CAAD,CAAb,IAAoB,CAAC,WAAW,CAAC,CAAD,CAAvC;AACD;AAaD,OAAM,SAAU,oBAAV,CACF,IADE,EACmD,KADnD,EAEF,MAFE,EAE2D;EAAA,IAA3C,cAA2C,uEAA1B,IAA0B;EAAA,IAApB,eAAoB,uEAAF,EAAE;;EAC/D,IAAI,KAAK,IAAI,IAAT,IAAiB,KAAK,CAAC,MAAN,KAAiB,CAAtC,EAAyC;IAGvC,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,IAAI,iBAAiB,GAAG,KAAxB;;MACA,IAAI,WAAW,CAAC,IAAD,CAAX,IAAsB,IAAiB,CAAC,MAAlB,GAA2B,CAArD,EAAwD;QACtD,iBAAiB,GAAG,IAApB;MACD,CAFD,MAEO,IAAI,UAAU,CAAC,IAAD,CAAd,EAAsB;QAC3B,KAAK,IAAM,GAAX,IAAkB,IAAlB,EAAwB;UACtB,IAAI,IAAI,CAAC,cAAL,CAAoB,GAApB,CAAJ,EAA8B;YAC5B,iBAAiB,GAAG,IAApB;YACA;UACD;QACF;MACF,CAPM,MAOA;QAEL,iBAAiB,GAAG,IAApB;MACD;;MACD,IAAI,iBAAJ,EAAuB;QACrB,MAAM,IAAI,UAAJ,CACF,+BAA6B,eAA7B,yCACW,IADX,CADE,CAAN;MAGD;IACF;;IACD,OAAO,EAAP;EACD;;EACD,IAAI,IAAI,IAAI,IAAZ,EAAkB;IAChB,OAAO,KAAK,CAAC,GAAN,CAAU,UAAA,IAAI;MAAA,OAAI,IAAJ;IAAA,CAAd,CAAP;EACD;;EAED,IAAI,MAAJ;;EACA,IAAI,UAAU,CAAC,IAAD,CAAd,EAAsB;IACpB,IAAI,GAAG,IAAP;IACA,MAAM,GAAG,EAAT;;IACA,qDAAmB,KAAnB,wCAA0B;MAAA,IAAf,IAAe;;MACxB,IAAI,IAAI,CAAC,IAAD,CAAJ,IAAc,IAAlB,EAAwB;QACtB,MAAM,IAAI,UAAJ,CACF,4BAAyB,IAAzB,6CACG,KADH,CADE,CAAN;MAGD;;MACD,MAAM,CAAC,IAAP,CAAY,IAAI,CAAC,IAAD,CAAhB;IACD;EACF,CAXD,MAWO,IAAI,WAAW,CAAC,IAAD,CAAf,EAAuB;IAC5B,IAAI,GAAG,IAAP;;IACA,IAAI,IAAI,CAAC,MAAL,KAAgB,KAAK,CAAC,MAA1B,EAAkC;MAChC,MAAM,IAAI,UAAJ,CACF,+BAA6B,eAA7B,iIAEmC,KAAK,CAAC,MAFzC,4EAGgD,IAHhD,CADE,CAAN;IAKD;;IACD,MAAM,GAAG,IAAT;EACD,CAVM,MAUA;IACL,IAAI,GAAG,IAAP;;IACA,IAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;MACpB,MAAM,IAAI,UAAJ,CACF,eAAa,eAAb,iBAAwC,KAAK,CAAC,MAA9C,iFAEI,IAAI,CAAC,KAFT,CADE,CAAN;IAID;;IACD,MAAM,GAAG,CAAC,IAAD,CAAT;EACD;;EAED,MAAM,GAAG,0BAA0B,CAAC,MAAD,CAAnC;;EAGA,IAAI,MAAM,IAAI,IAAd,EAAoB;IAClB,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,MAA1B,EAAkC,EAAE,CAApC,EAAuC;MACrC,IAAI,MAAM,CAAC,CAAD,CAAN,IAAa,IAAjB,EAAuB;QACrB;MACD;;MACD,IAAM,KAAK,GAAG,MAAM,CAAC,CAAD,CAApB;;MACA,IAAI,KAAK,CAAC,KAAN,CAAY,MAAZ,KAAuB,MAAM,CAAC,CAAD,CAAN,CAAU,MAArC,EAA6C;QAC3C,MAAM,IAAI,UAAJ,CACF,yBAAuB,eAAvB,mBAAoD,KAAK,CAAC,CAAD,CAAzD,uBACW,MAAM,CAAC,CAAD,CAAN,CAAU,MADrB,uDAES,KAAK,CAAC,KAFf,CADE,CAAN;MAID;;MACD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;QACzC,IAAI,CAAC,KAAK,CAAN,IAAW,CAAC,cAAhB,EAAgC;UAE9B;QACD;;QACD,IAAM,GAAG,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAZ;QACA,IAAM,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAAf;;QACA,IAAI,MAAM,IAAI,IAAV,IAAkB,MAAM,IAAI,CAA5B,IAAiC,GAAG,KAAK,MAA7C,EAAqD;UACnD,MAAM,IAAI,UAAJ,CACF,yBAAuB,eAAvB,mBAAoD,KAAK,CAAC,CAAD,CAAzD,8BACkB,MAAM,CAAC,CAAD,CADxB,4CAEI,KAAK,CAAC,KAFV,QADE,CAAN;QAID;MACF;IACF;EACF;;EACD,OAAO,MAAP;AACD;AASD,OAAM,SAAU,iBAAV,CACF,MADE,EACgB,OADhB,EACmC,OADnC,EACqD;EACzD,IAAM,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC,GAAP,CAAW,UAAA,KAAK;IAAA,OAAI,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAJ;EAAA,CAAhB,CAAD,CAAnB;EACA,IAAI,CAAC,IAAL;EACA,IAAM,IAAI,GAAG,MAAM,CAAC,OAAO,CAAC,GAAR,CAAY,UAAA,MAAM;IAAA,OAAI,MAAM,CAAC,KAAP,CAAa,CAAb,CAAJ;EAAA,CAAlB,CAAD,CAAnB;EACA,IAAI,CAAC,IAAL;;EAEA,IAAI,IAAI,CAAC,MAAL,GAAc,CAAlB,EAAqB;IACnB,MAAM,IAAI,UAAJ,CACF,gGAEG,IAAI,CAAC,SAAL,CAAe,MAAM,CAAC,GAAP,CAAW,UAAA,KAAK;MAAA,OAAI,KAAK,CAAC,KAAV;IAAA,CAAhB,CAAf,CAFH,CADE,CAAN;EAID;;EACD,IAAI,IAAI,CAAC,MAAL,GAAc,CAAlB,EAAqB;IACnB,MAAM,IAAI,UAAJ,CACF,iGAEG,IAAI,CAAC,SAAL,CAAe,OAAO,CAAC,GAAR,CAAY,UAAA,MAAM;MAAA,OAAI,MAAM,CAAC,KAAX;IAAA,CAAlB,CAAf,CAFH,CADE,CAAN;EAID;;EACD,IAAI,IAAI,CAAC,MAAL,GAAc,CAAd,IAAmB,IAAI,CAAC,MAAL,GAAc,CAAjC,IAAsC,CAAC,IAAI,CAAC,WAAL,CAAiB,IAAjB,EAAuB,IAAvB,CAA3C,EAAyE;IACvE,MAAM,IAAI,UAAJ,CACF,yFACkB,IAAI,CAAC,CAAD,CADtB,6BACiD,IAAI,CAAC,CAAD,CADrD,6BADE,CAAN;EAID;AACF;;AAWD,SAAS,+BAAT,CACI,OADJ,EACuB,OADvB,EACkD,YADlD,EACuE;EAErE,IAAM,SAAS,GAAG,CAChB,MAAM,CAAC,gBADS,EACS,MAAM,CAAC,kBADhB,EAEhB,MAAM,CAAC,uBAFS,CAAlB;;EAIA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;IACvC,IAAM,CAAC,GAAG,OAAO,CAAC,CAAD,CAAjB;IACA,IAAM,IAAI,GAAG,OAAO,CAAC,CAAD,CAApB;IACA,IAAM,KAAK,GAAG,YAAY,CAAC,CAAD,CAA1B;;IACA,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB;IACD;;IACD,IAAI,IAAI,KAAK,MAAM,CAAC,uBAApB,EAA6C;MAC3C,IAAI,CAAC,CAAC,KAAF,CAAQ,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAAzB,MAAgC,CAApC,EAAuC;QACrC,MAAM,IAAI,UAAJ,CACF,6CAA2C,CAAC,CAAC,KAA7C,4KADE,CAAN;MAMD;IACF;;IACD,IAAI,SAAS,CAAC,OAAV,CAAkB,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;MAClC,IAAM,YAAY,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,CAArB;MACA,IAAM,WAAW,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAApB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAAY,CAAC,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;QAC5C,IAAM,SAAS,GAAG,YAAY,CAAC,CAAD,CAA9B;QACA,IAAM,MAAM,GAAG,WAAW,CAAC,CAAD,CAA1B;;QACA,IAAI,MAAM,IAAI,IAAV,IAAkB,SAAS,KAAK,MAApC,EAA4C;UAC1C,MAAM,IAAI,UAAJ,CACF,gCAA8B,CAAC,CAAC,KAAhC,iDACmB,KADnB,mGADE,CAAN;QAID;MACF;IACF;EACF;AACF;;AA4BD,SAAS,cAAT,CACI,IADJ,EAC2B,KAD3B,EAC4C,MAD5C,EAE+C;EAAA,IAA3C,cAA2C,uEAA1B,IAA0B;EAAA,IAApB,eAAoB,uEAAF,EAAE;EAC7C,IAAI,MAAJ;;EACA,IAAI,KAAK,CAAC,OAAN,CAAc,IAAd,CAAJ,EAAyB;IACvB,IAAI,IAAI,CAAC,MAAL,KAAgB,KAAK,CAAC,MAA1B,EAAkC;MAChC,MAAM,IAAI,UAAJ,CACF,+BAA6B,eAA7B,qIAEuC,KAAK,CAAC,MAF7C,2CAGoB,IAAI,CAAC,MAHzB,kBADE,CAAN;IAKD;;IACD,MAAM,GAAG,IAAT;EACD,CATD,MASO;IACL,IAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;MACpB,MAAM,IAAI,UAAJ,CACF,uBAAqB,KAAK,CAAC,MAA3B,SAAqC,eAArC,8EAEG,IAAI,CAAC,SAAL,CAAe,IAAI,CAAC,KAApB,CAFH,OADE,CAAN;IAID;;IACD,MAAM,GAAG,CAAC,IAAD,CAAT;EACD;;EAED,IAAI,MAAM,IAAI,IAAd,EAAoB;IAClB,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,MAA1B,EAAkC,EAAE,CAApC,EAAuC;MACrC,IAAI,MAAM,CAAC,CAAD,CAAN,IAAa,IAAjB,EAAuB;QACrB;MACD;;MACD,IAAM,KAAK,GAAG,MAAM,CAAC,CAAD,CAApB;;MACA,IAAI,KAAK,CAAC,KAAN,CAAY,MAAZ,KAAuB,MAAM,CAAC,CAAD,CAAN,CAAU,MAArC,EAA6C;QAC3C,MAAM,IAAI,UAAJ,CACF,yBAAuB,eAAvB,mBAAoD,KAAK,CAAC,CAAD,CAAzD,uBACW,MAAM,CAAC,CAAD,CAAN,CAAU,MADrB,uDAES,IAAI,CAAC,SAAL,CAAe,KAAK,CAAC,KAArB,CAFT,CADE,CAAN;MAID;;MACD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;QACzC,IAAI,CAAC,KAAK,CAAN,IAAW,CAAC,cAAhB,EAAgC;UAC9B;QACD;;QACD,IAAM,GAAG,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAZ;QACA,IAAM,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAAf;;QACA,IAAI,MAAM,IAAI,IAAd,EAAoB;UAClB,IAAI,MAAM,KAAK,GAAf,EAAoB;YAClB,MAAM,IAAI,UAAJ,CACF,yBAAuB,eAAvB,oBACG,KAAK,CAAC,CAAD,CADR,uBAC6B,IAAI,CAAC,SAAL,CAAe,MAAM,CAAC,CAAD,CAArB,CAD7B,yCAEwB,IAAI,CAAC,SAAL,CAAe,KAAK,CAAC,KAArB,CAFxB,OADE,CAAN;UAID;QACF;MACF;IACF;EACF;AACF;;AAeD,OAAM,SAAU,cAAV,CACF,OADE,EAGF,WAHE,EAGmB;EACvB,IAAI,OAAO,IAAI,IAAX,IAAmB,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAApE,EAAuE;IACrE,OAAO,WAAW,CAAC,GAAZ,CAAgB,UAAA,IAAI;MAAA,OAAI,EAAJ;IAAA,CAApB,CAAP;EACD;;EAED,IAAI,cAAJ;;EAEA,IAAI,OAAO,OAAP,KAAmB,QAAnB,IAA+B,OAAO,OAAP,KAAmB,UAAtD,EAAkE;IAChE,cAAc,GAAG,CAAC,OAAD,CAAjB;EACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,OAAP,KAAmB,QAAjD,EAA2D;IAChE,cAAc,GAAG,OAAjB;EAED,CAHM,MAGA;IACL,MAAM,IAAI,SAAJ,CACF,0GACsC,OADtC,CADE,CAAN;EAGD;;EAED,IAAI,KAAK,CAAC,OAAN,CAAc,cAAd,CAAJ,EAAmC;IAEjC,OAAO,WAAW,CAAC,GAAZ,CACH,UAAA,IAAI;MAAA,OAAI,cAAJ;IAAA,CADD,CAAP;EAED,CAJD,MAIO;IAEL,IAAM,aAAa,GAAwC,EAA3D;;IACA,sDAAmB,WAAnB,2CAAgC;MAAA,IAArB,IAAqB;MAC9B,IAAI,aAAa,GACb,cAAc,CAAC,cAAf,CAA8B,IAA9B,IAAsC,cAAc,CAAC,IAAD,CAApD,GAA6D,EADjE;;MAEA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,aAAd,CAAL,EAAmC;QACjC,aAAa,GAAG,CAAC,aAAD,CAAhB;MACD;;MACD,aAAa,CAAC,IAAd,CAAmB,aAAnB;IACD;;IACD,OAAO,aAAP;EACD;AACF;AA2DD,IAAM,wBAAwB,GAAG,cAAjC;AAcA,WAAa,WAAb;EAAA;;EAAA;;EA4CE,qBAAY,IAAZ,EAA+B;IAAA;;IAAA;;IAC7B,0BAAM,IAAN;IACA,MAAK,UAAL,GAAkB,KAAlB;IAF6B;EAG9B;;EA/CH;IAAA;IAAA,OAoFE,iBACI,UADJ,EACyB,SADzB,EAImE;MAAA,IAF/D,OAE+D,uEAAX,OAAO,CAAC,GAAG;;MACjE,IAAI,CAAC,KAAK,KAAV,EAAiB;QACf,MAAM,IAAI,UAAJ,CACF,wLADE,CAAN;MAID;;MACD,YAAY,CAAC,IAAD,EAAO,UAAP,EAAmB,SAAnB,EAA8B,OAA9B,CAAZ;IACD;EAhGH;IAAA;IAAA,OA4GE,iBAAQ,IAAR,EAA8B;MAAA;;MAC5B,IAAI,IAAI,CAAC,IAAL,IAAa,IAAjB,EAAuB;QACrB,IAAI,CAAC,IAAL,GAAY,EAAZ;MACD;;MACD,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;;MAEA,IAAI,OAAO,IAAI,CAAC,SAAZ,KAA0B,QAA9B,EAAwC;QACtC,KAAK,UAAL,GAAkB,UAAU,CAAC,YAAX,CAAwB,IAAI,CAAC,SAA7B,CAAlB;QACA,KAAK,gBAAL,GAAwB,IAAxB;MACD,CAHD,MAGO;QACL,IAAI,EAAE,IAAI,CAAC,SAAL,YAA0B,SAA5B,CAAJ,EAA4C;UAC1C,MAAM,IAAI,UAAJ,+DAAN;QAED;;QACD,KAAK,UAAL,GAAkB,IAAI,CAAC,SAAvB;QACA,KAAK,gBAAL,GAAwB,KAAxB;MACD;;MAMD,IAAI,aAAa,GAAqB,EAAtC;;MACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAD,IAA6B,OAAO,IAAI,CAAC,IAAZ,KAAqB,QAAlD,IACA,OAAO,IAAI,CAAC,IAAZ,KAAqB,UADzB,EACqC;QACnC,IAAI,CAAC,IAAL,GAAY,IAAI,CAAC,IAAjB;;QACA,KAAK,IAAM,IAAX,IAAmB,IAAI,CAAC,IAAxB,EAA8B;UAC5B,IAAI,KAAK,WAAL,CAAiB,OAAjB,CAAyB,IAAzB,MAAmC,CAAC,CAAxC,EAA2C;YACzC,MAAM,IAAI,UAAJ,CACF,yCAAsC,IAAtC,oDACqC,KAAK,WAD1C,CADE,CAAN;UAGD;QACF;;QACD,sDAAmB,KAAK,WAAxB,2CAAqC;UAAA,IAA1B,KAA0B;;UACnC,IAAI,IAAI,CAAC,IAAL,CAAU,KAAV,KAAmB,IAAvB,EAA6B;YAC3B,OAAO,CAAC,IAAR,CACI,cAAW,KAAX,6IAEmB,KAFnB,sBADJ;UAID;;UACD,aAAa,CAAC,IAAd,CAAmB,MAAM,CAAC,GAAP,CAAW,IAAI,CAAC,IAAL,CAAU,KAAV,CAAX,CAAnB;QACD;MACF,CAnBD,MAmBO,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAJ,EAA8B;QACnC,IAAI,IAAI,CAAC,IAAL,CAAU,MAAV,KAAqB,KAAK,OAAL,CAAa,MAAtC,EAA8C;UAC5C,MAAM,IAAI,UAAJ,CACF,mGAC+B,KAAK,OAAL,CAAa,MAD5C,+CAEuB,IAAI,CAAC,IAF5B,OADE,CAAN;QAID;;QACD,IAAM,SAAS,GAAG,IAAI,CAAC,IAAvB;QACA,aAAa,GAAG,SAAS,CAAC,GAAV,CAAc,UAAA,CAAC;UAAA,OAAI,MAAM,CAAC,GAAP,CAAW,CAAX,CAAJ;QAAA,CAAf,CAAhB;MACD,CATM,MASA;QACL,IAAM,YAAY,GAAG,MAAM,CAAC,GAAP,CAAW,IAAI,CAAC,IAAhB,CAArB;QACA,KAAK,OAAL,CAAa,OAAb,CAAqB,UAAA,CAAC,EAAG;UACvB,aAAa,CAAC,IAAd,CAAmB,YAAnB;QACD,CAFD;MAGD;;MAED,KAAK,aAAL,GAAqB,aAArB;MAEA,KAAK,eAAL,GAAuB,EAAvB;MACA,KAAK,gBAAL,GAAwB,EAAxB;MACA,KAAK,WAAL,GAAmB,EAAnB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,OAAL,CAAa,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;QAE5C,IAAM,KAAK,GAAG,KAAK,oBAAL,CAA0B,CAA1B,CAAd;QACA,IAAM,MAAI,GAAG,KAAK,WAAL,CAAiB,CAAjB,CAAb;QACA,KAAK,eAAL,CAAqB,IAArB,CAA0B,MAA1B;QACA,KAAK,gBAAL,CAAsB,IAAtB,CAA2B,KAA3B;QACA,KAAK,WAAL,CAAiB,IAAjB,CAAsB,KAAK,aAAL,CAAmB,CAAnB,CAAtB;MACD;;MAID,IAAM,iBAAiB,GAAa,EAApC;MAGA,KAAK,OAAL,GAAe,IAAI,CAAC,OAApB;MAEA,KAAK,YAAL,GAAoB,CAAC,MAAD,CAApB;MACA,KAAK,cAAL,GAAsB,EAAtB;MAMA,SAAS,CAAC,MAAD,EAAS,YAAK;QACrB,KAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,MAAI,CAAC,OAAL,CAAa,MAAjC,EAAyC,EAAE,EAA3C,EAA8C;UAC5C,IAAI,iBAAiB,CAAC,OAAlB,CAA0B,EAA1B,MAAiC,CAAC,CAAtC,EAAyC;YACvC;UACD;;UAGD,IAAM,YAAY,GAAG,MAAI,CAAC,aAAL,CAAmB,EAAnB,CAArB;;UACA,IAAI,MAAI,CAAC,OAAL,CAAa,MAAb,GAAsB,CAA1B,EAA6B;YAC3B,MAAI,CAAC,cAAL,CAAoB,IAApB,CAAyB,CAAC,YAAD,EAAe,EAAf,CAAzB;;YACA,MAAI,CAAC,YAAL,CAAkB,IAAlB,CAAuB,MAAI,CAAC,WAAL,CAAiB,EAAjB,IAAsB,OAA7C;UACD;QACF;MAIF,CAhBQ,CAAT;MAkBA,IAAM,aAAa,GAAG,cAAc,CAAC,IAAI,CAAC,OAAN,EAAe,KAAK,WAApB,CAApC;;MAMA,IAAM,YAAY,GACd,SADE,YACF,CAAC,WAAD,EAAsB,UAAtB,EACC,YADD,EACiC;QAC/B,IAAI,MAAI,CAAC,WAAL,CAAiB,MAAjB,GAA0B,CAA9B,EAAiC;UAC/B,UAAU,GAAG,MAAI,CAAC,WAAL,CAAiB,WAAjB,IAAgC,GAAhC,GAAsC,UAAnD;QACD;;QACD,MAAI,CAAC,YAAL,CAAkB,IAAlB,CAAuB,UAAvB;;QACA,MAAI,CAAC,cAAL,CAAoB,IAApB,CAAyB,CAAC,YAAD,EAAe,WAAf,CAAzB;MACD,CARL;;MAUA,SAAS,CAAC,QAAD,EAAW,YAAK;QAAA,2BACd,GADc;UAErB,IAAI,iBAAiB,CAAC,OAAlB,CAA0B,GAA1B,MAAiC,CAAC,CAAtC,EAAyC;YACvC;UACD;;UACD,IAAM,aAAa,GAAG,aAAa,CAAC,GAAD,CAAnC;;UAIA,IAAM,aAAa,GAAG,SAAhB,aAAgB,CAAC,OAAD,EAA0C;YAC9D,IAAM,gBAAgB,GAAG,EAAzB;YACA,IAAI,UAAJ;YACA,IAAI,KAAJ;YACA,IAAI,gBAAJ;;YAGA,sDAAqB,OAArB,2CAA8B;cAAA,IAAnB,MAAmB;;cAC5B,IAAI,OAAO,MAAP,KAAkB,QAAlB,IACA,CAAC,UAAD,EAAa,KAAb,EAAoB,cAApB,EAAoC,IAApC,EAA0C,OAA1C,CAAkD,MAAlD,MACI,CAAC,CAFT,EAEY;gBACV,IAAM,WAAW,GAAG,MAAI,CAAC,oBAAL,CAA0B,GAA1B,CAApB;;gBAEA,IAAI,WAAW,CAAC,WAAW,CAAC,MAAZ,GAAqB,CAAtB,CAAX,KAAwC,CAAxC,IACA,MAAI,CAAC,aAAL,CAAmB,GAAnB,MAA0B,MAAM,CAAC,kBADrC,EACyD;kBAEvD,IAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;oBAC9C,KAAK,GAAG,OAAO,CAAC,cAAhB;kBACD,CAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;oBACxD,KAAK,GAAG,OAAO,CAAC,kBAAhB;kBACD;gBACF,CARD,MAQO,IACH,MAAI,CAAC,aAAL,CAAmB,GAAnB,MACA,MAAM,CAAC,6BAFJ,EAEmC;kBAGxC,IAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;oBAC9C,KAAK,GAAG,OAAO,CAAC,yBAAhB;kBACD,CAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;oBACxD,KAAK,GAAG,OAAO,CAAC,6BAAhB;kBACD;gBACF,CAVM,MAUA;kBAEL,IAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;oBAC9C,KAAK,GAAG,OAAO,CAAC,mBAAhB;kBACD,CAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;oBACxD,KAAK,GAAG,OAAO,CAAC,uBAAhB;kBACD;gBACF;;gBACD,IAAI,MAAc,SAAlB;;gBACA,IAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;kBAC9C,MAAM,GAAG,KAAT;gBACD,CAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;kBACxD,MAAM,GAAG,IAAT;gBACD;;gBAED,gBAAgB,GAAG,KAAnB;gBACA,UAAU,GAAG,gBAAgB,GAAG,MAAhC;cACD,CAxCD,MAwCO;gBACL,IAAM,QAAQ,GAAG,OAAO,CAAC,GAAR,CAAY,MAAZ,CAAjB;gBAEA,gBAAgB,GAAG,QAAnB;gBACA,UAAU,GACN,gBAAgB,GAAG,OAAO,CAAC,mBAAR,CAA4B,MAA5B,CADvB;cAED;;cAGD,IAAI,YAA4B,SAAhC;cACA,SAAS,CAAC,UAAD,EAAa,YAAK;gBACzB,YAAY,GAAG,gBAAf;cACD,CAFQ,CAAT;cAGA,YAAY,CAAC,GAAD,EAAI,UAAJ,EAAgB,YAAhB,CAAZ;YACD;UACF,CA/DD;;UAiEA,aAAa,CAAC,aAAD,CAAb;QA1EqB;;QACvB,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,MAAI,CAAC,OAAL,CAAa,MAAjC,EAAyC,EAAE,GAA3C,EAA8C;UAAA,iBAArC,GAAqC;;UAAA,yBAE1C;QAyEH;MACF,CA7EQ,CAAT;MAiFA,KAAK,yBAAL,GAAiC,KAAK,gBAAtC;IACD;EAtTH;IAAA;IAAA,OAiUY,4CAAgC;MACxC,IAAI,KAAK,yBAAL,IAAkC,IAAtC,EAA4C;QAC1C;MACD;;MACD,IAAI,KAAK,gBAAL,CAAsB,MAAtB,KACA,KAAK,yBAAL,CAA+B,MADnC,EAC2C;QACzC,OAAO,CAAC,IAAR,CACI,kEACA,yDADA,GAEA,+BAHJ;MAID;IACF;EA5UH;IAAA;IAAA,OA6WE,kBACI,CADJ,EACwB,CADxB,EAEgC;MAAA,IAA5B,IAA4B,uEAAF,EAAE;MAC9B,IAAM,SAAS,GAAG,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAArD;MACA,cAAc,CAAC,SAAD,CAAd;MAIA,IAAM,cAAc,GAAG,IAAvB;MACA,IAAM,gBAAgB,GAClB,KAAK,qBAAL,CAA2B,CAA3B,EAA8B,CAA9B,EAAiC,cAAjC,EAAiD,SAAjD,CADJ;;MAEA,IAAI;QAGF,IAAM,GAAG,GAAG,gBAAgB,CAAC,CAAD,CAAhB,CAAoB,MAApB,CAA2B,gBAAgB,CAAC,CAAD,CAA3C,CAAZ;QACA,KAAK,gBAAL;QACA,IAAM,CAAC,GAAG,KAAK,YAAf;QACA,IAAM,QAAQ,GACV,KAAK,QAAL,CAAc,CAAd,EAAiB,GAAjB,EAAsB,SAAtB,EAAiC,IAAI,CAAC,OAAtC,EAA+C,IAAI,CAAC,KAApD,CADJ;QAEA,OAAO,gBAAgB,CAAC,QAAD,CAAvB;MACD,CATD,SASU;QACR,iBAAiB,CAAC,gBAAgB,CAAC,CAAD,CAAjB,EAAsB,CAAtB,CAAjB;QACA,iBAAiB,CAAC,gBAAgB,CAAC,CAAD,CAAjB,EAAsB,CAAtB,CAAjB;MACD;IACF;EArYH;IAAA;IAAA,OA6ZE,yBAAsB,OAAtB,EAA4C,IAA5C;MAAA;QAAA;UAAA;YAAA;cAEE,KAAK,gBAAL;cAFF,iCAGS,gBAAe,CAAC,IAAD,EAAO,OAAP,EAAgB,IAAhB,CAHxB;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA7ZF;IAAA;IAAA,OA6aU,yBACJ,GADI,EACkB,SADlB,EACsC,KADtC,EAEe;MAAA,IAAnB,SAAmB,uEAAP,OAAO;MACrB,IAAI,UAAJ;;MACA,IAAI,KAAK,IAAI,IAAb,EAAmB;QACjB,UAAU,GAAG,IAAb;;QACA,IAAI,SAAS,IAAI,IAAjB,EAAuB;UACrB,MAAM,IAAI,UAAJ,CACF,QAAM,SAAN,2EACmB,SADnB,CADE,CAAN;QAGD;MACF,CAPD,MAOO,IAAI,GAAG,IAAI,IAAX,EAAiB;QACtB,IAAI,KAAK,CAAC,OAAN,CAAc,GAAd,CAAJ,EAAwB;UACtB,UAAU,GAAG,GAAG,CAAC,CAAD,CAAH,CAAO,KAAP,CAAa,CAAb,CAAb;QACD,CAFD,MAEO;UACL,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAb;QACD;MACF,CANM,MAMA;QACL,MAAM,IAAI,UAAJ,CACF,4DACG,SADH,0BADE,CAAN;MAGD;;MACD,OAAO,UAAP;IACD;EApcH;IAAA;IAAA,OA6cE,iBAAQ,MAAR,EAAgD,OAAhD,EAAwE;MAEtE,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAAjD,EAAoD;QAClD,MAAM,IAAI,UAAJ,CACF,oDADE,CAAN;MAED;;MAED,IAAM,cAAc,GAAG,KAAK,CAAC,OAAN,CAAc,OAAd,CAAvB;MACA,IAAM,WAAW,GACZ,cAAc,GAAG,OAAH,GAAyB,CAAC,OAAD,CAD5C;MAEA,IAAM,qBAAqB,GAAG,KAAK,uBAAL,CAA6B,WAA7B,CAA9B;MAGA,IAAM,QAAQ,GAAG,IAAI,QAAJ,EAAjB;;MACA,IAAI,MAAM,YAAY,MAAtB,EAA8B;QAC5B,MAAM,GAAG,CAAC,MAAD,CAAT;MACD;;MACD,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;QACzB,IAAI,MAAM,CAAC,MAAP,KAAkB,KAAK,MAAL,CAAY,MAAlC,EAA0C;UACxC,MAAM,IAAI,UAAJ,CACF,oCAAkC,MAAM,CAAC,MAAzC,wEAEI,KAAK,MAAL,CAAY,MAFhB,QADE,CAAN;QAID;;QACD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;UAC3C,QAAQ,CAAC,GAAT,CAAa,KAAK,MAAL,CAAY,CAAZ,CAAb,EAA6B,MAAM,CAAC,CAAD,CAAnC;QACD;MACF,CAVD,MAUO;QACL,sDAAoB,KAAK,MAAzB,2CAAiC;UAAA,IAAtB,KAAsB;UAC/B,IAAM,WAAW,GAAG,MAAM,CAAC,KAAK,CAAC,IAAP,CAA1B;;UACA,IAAI,WAAW,IAAI,IAAnB,EAAyB;YACvB,MAAM,IAAI,UAAJ,iDAC4C,KAAK,CAAC,IADlD,CAAN;UAED;;UACD,QAAQ,CAAC,GAAT,CAAa,KAAb,EAAoB,WAApB;QACD;MACF;;MAGD,IAAM,cAAc,GAAG,QAAO,CAAC,qBAAD,EAAwB,QAAxB,CAA9B;;MACA,OAAO,cAAc,GAAG,cAAH,GAAoB,cAAc,CAAC,CAAD,CAAvD;IACD;EAtfH;IAAA;IAAA,OA2fU,iCAAwB,mBAAxB,EAAqD;MAE3D,IAAM,qBAAqB,GACvB,YAAY,CAAC,IAAD,EAAO,mBAAmB,CAAC,MAA3B,CADhB;MAEA,IAAI,gBAAgB,GAAG,mBAAmB,CAAC,MAA3C;;MACA,sDAAoB,KAAK,MAAzB,2CAAiC;QAAA,IAAtB,KAAsB;QAC/B,IAAM,YAAY,GACd,KAAK,CAAC,OAAN,CAAc,KAAK,CAAC,MAApB,IAA8B,KAAK,CAAC,MAApC,GAA6C,CAAC,KAAK,CAAC,MAAP,CADjD;QAEA,IAAM,gBAAgB,GAAG,YAAY,CAAC,GAAb,CAAiB,UAAA,MAAM;UAAA,OAAI,MAAM,CAAC,IAAX;QAAA,CAAvB,CAAzB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,mBAAmB,CAAC,MAAxC,EAAgD,EAAE,CAAlD,EAAqD;UACnD,IAAM,KAAK,GAAG,gBAAgB,CAAC,OAAjB,CAAyB,mBAAmB,CAAC,CAAD,CAA5C,CAAd;;UACA,IAAI,KAAK,KAAK,CAAC,CAAf,EAAkB;YAChB,qBAAqB,CAAC,CAAD,CAArB,GAA2B,YAAY,CAAC,KAAD,CAAvC;YACA,gBAAgB;UACjB;;UACD,IAAI,gBAAgB,KAAK,CAAzB,EAA4B;YAC1B;UACD;QACF;;QACD,IAAI,gBAAgB,KAAK,CAAzB,EAA4B;UAC1B;QACD;MACF;;MAED,IAAI,gBAAgB,GAAG,CAAvB,EAA0B;QACxB,IAAM,cAAc,GAAa,EAAjC;QACA,qBAAqB,CAAC,OAAtB,CAA8B,UAAC,MAAD,EAAS,CAAT,EAAc;UAC1C,IAAI,MAAM,IAAI,IAAd,EAAoB;YAClB,cAAc,CAAC,IAAf,CAAoB,mBAAmB,CAAC,CAAD,CAAvC;UACD;QACF,CAJD;QAKA,MAAM,IAAI,UAAJ,CACF,2DACG,IAAI,CAAC,SAAL,CAAe,cAAf,CADH,CADE,CAAN;MAGD;;MACD,OAAO,qBAAP;IACD;EA/hBH;IAAA;IAAA,OA8iBU,qBAAY,GAAZ,EAAiE;MAAA;;MAAA,IAA/B,SAA+B,uEAAnB,EAAmB;MAAA,IAAf,OAAe,uEAAL,KAAK;MAEvE,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;QACnB,IAAM,UAAU,GAAG,MAAI,CAAC,eAAL,CAAqB,GAArB,CAAnB;;QACA,IAAI,OAAJ,EAAa;UACX,MAAM,IAAI,mBAAJ,CACF,+CADE,CAAN;QAED;;QAOD,IAAM,OAAO,GAAG,WAAW,CAAC,UAAD,EAAa,SAAb,CAA3B;;QACA,IAAM,WAAW,GAAe,MAAI,CAAC,OAAL,CAAa,GAAb,CAAiB,UAAA,MAAM;UAAA,OAAI,EAAJ;QAAA,CAAvB,CAAhC;;QAbmB,6BAgBV,UAhBU;UAiBjB,IAAM,SAAS,GAAG,GAAG,CAAC,IAAJ,CAAS,YAAK;YAC9B,IAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;YACA,IAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;YAGA,IAAM,QAAQ,GAAG,WAAW,CAAC,GAAD,EAAM,UAAN,EAAkB,QAAlB,CAA5B;YAGA,IAAM,KAAK,GAAG,EAAd;;YACA,IAAI,KAAK,CAAC,OAAN,CAAc,QAAd,CAAJ,EAA6B;cAC3B,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAAQ,CAAC,MAA7B,EAAqC,EAAE,CAAvC,EAA0C;gBACxC,KAAK,CAAC,IAAN,CAAW;kBAAC,GAAG,EAAE,MAAI,CAAC,MAAL,CAAY,CAAZ,CAAN;kBAAsB,KAAK,EAAE,QAAQ,CAAC,CAAD;gBAArC,CAAX;cACD;YACF,CAJD,MAIO;cACL,KAAK,CAAC,IAAN,CAAW;gBAAC,GAAG,EAAE,MAAI,CAAC,MAAL,CAAY,CAAZ,CAAN;gBAAsB,KAAK,EAAE;cAA7B,CAAX;YACD;;YACD,IAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;YACA,OAAO,QAAO,CAAC,MAAI,CAAC,OAAN,EAAe,QAAf,CAAd;UACD,CAlBiB,CAAlB;UAmBA,SAAS,CAAC,OAAV,CAAkB,UAAC,QAAD,EAAW,CAAX;YAAA,OAAiB,WAAW,CAAC,CAAD,CAAX,CAAe,IAAf,CAAoB,QAApB,CAAjB;UAAA,CAAlB;QApCiB;;QAgBnB,KAAK,IAAI,UAAU,GAAG,CAAtB,EAAyB,UAAU,GAAG,OAAO,CAAC,MAA9C,EAAsD,EAAE,UAAxD,EAAoE;UAAA,OAA3D,UAA2D;QAqBnE;;QACD,OAAO,gBAAgB,CACnB,WAAW,CAAC,GAAZ,CAAgB,UAAA,OAAO;UAAA,OAAI,GAAG,CAAC,MAAJ,CAAW,OAAX,EAAoB,CAApB,CAAJ;QAAA,CAAvB,CADmB,CAAvB;MAED,CAxCM,CAAP;IAyCD;EAzlBH;IAAA;IAAA,OAsnBE,iBAAQ,CAAR,EAAuD;MAAA,IAA3B,IAA2B,uEAAF,EAAE;MACrD,IAAM,eAAe,GAAG,0BAA0B,CAAC,CAAD,CAAlD;MACA,cAAc,CACV,eADU,EACO,KAAK,UADZ,EACwB,KAAK,eAD7B,EAC8C,KAD9C,CAAd;;MAEA,IAAI;QAKF,IAAM,SAAS,GAAG,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAArD;QACA,cAAc,CAAC,SAAD,CAAd;QACA,OAAO,KAAK,WAAL,CAAiB,eAAjB,EAAkC,SAAlC,CAAP;MACD,CARD,SAQU;QACR,iBAAiB,CAAC,eAAD,EAAkB,CAAlB,CAAjB;MACD;IACF;EAroBH;IAAA;IAAA,OAspBE,wBAAe,CAAf,EAAiC;MAC/B,cAAc,CAAC,CAAD,EAAI,KAAK,UAAT,EAAqB,KAAK,eAA1B,EAA2C,IAA3C,CAAd;MAGA,IAAM,SAAS,GAAG,CAAC,KAAK,CAAC,OAAN,CAAc,CAAd,IAAmB,CAAC,CAAC,CAAD,CAApB,GAA0B,CAA3B,EAA8B,KAA9B,CAAoC,CAApC,CAAlB;MACA,OAAO,KAAK,WAAL,CAAiB,CAAjB,EAAoB,SAApB,CAAP;IACD;EA5pBH;IAAA;IAAA,OA8pBY,+BACN,CADM,EAEN,CAFM,EAGY;MAAA,IADgC,cAChC,uEADiD,IACjD;MAAA,IAAlB,SAAkB;;MAEpB,IAAI,KAAK,UAAL,IAAmB,IAAvB,EAA6B;QAC3B,MAAM,IAAI,YAAJ,CACF,2DACA,wCAFE,CAAN;MAGD;;MACD,IAAM,YAAY,GAAY,EAA9B;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,gBAAL,CAAsB,MAA1C,EAAkD,EAAE,CAApD,EAAuD;QACrD,IAAM,WAAW,GAAG,KAAK,gBAAL,CAAsB,CAAtB,CAApB;QACA,IAAM,MAAM,GAAG,KAAK,WAAL,CAAiB,CAAjB,CAAf;;QACA,IAAI,MAAM,KAAK,MAAM,CAAC,6BAAtB,EAAqD;UACnD,YAAY,CAAC,IAAb,CACI,WAAW,CAAC,KAAZ,CAAkB,CAAlB,EAAqB,WAAW,CAAC,MAAZ,GAAqB,CAA1C,EAA6C,MAA7C,CAAoD,CAAC,CAAD,CAApD,CADJ;QAED,CAHD,MAGO;UAEL,YAAY,CAAC,IAAb,CAAkB,WAAlB;QACD;MACF;;MACD,CAAC,GAAG,oBAAoB,CACpB,CADoB,EACjB,KAAK,cADY,EACI,KAAK,eADT,EAC0B,KAD1B,EACiC,OADjC,CAAxB;MAEA,CAAC,GAAG,oBAAoB,CACpB,CADoB,EACjB,KAAK,eADY,EACK,YADL,EACmB,KADnB,EAC0B,QAD1B,CAAxB;MAGA,iBAAiB,CAAC,CAAD,EAAI,CAAJ,EAAO,IAAP,CAAjB;MAEA,+BAA+B,CAAC,CAAD,EAAI,KAAK,WAAT,EAAsB,KAAK,gBAA3B,CAA/B;;MACA,IAAI,KAAK,QAAL,IAAiB,SAAS,IAAI,IAA9B,IAAsC,SAAS,GAAG,CAAtD,EAAyD;QACvD,IAAI,CAAC,CAAC,CAAD,CAAD,CAAK,KAAL,CAAW,CAAX,IAAgB,SAAhB,KAA8B,CAAlC,EAAqC;UACnC,MAAM,IAAI,UAAJ,CACF,2HAEG,SAFH,iBAEwB,CAAC,CAAC,CAAD,CAAD,CAAK,KAAL,CAAW,CAAX,CAFxB,iBADE,CAAN;QAID;MACF;;MACD,OAAO,CAAC,CAAD,EAAI,CAAJ,CAAP;IACD;EArsBH;IAAA;IAAA,OAusBY,6BACN,CADM,EAEN,CAFM,EAGN,YAHM,EAIN,WAJM;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;;MAAA;QAAA;UAAA;YAAA;cAKN,cALM,8DAKW,IALX;cAMN,SANM;cAAA,wBAQJ,KAAK,qBAAL,CAA2B,CAA3B,EAA8B,CAA9B,EAAiC,cAAjC,EAAiD,SAAjD,CARI,qEAOD,UAPC,8BAOW,UAPX;;cAAA,MAUJ,YAAY,IAAI,IAVZ;gBAAA;gBAAA;cAAA;;cAAA,MAWA,IAAI,KAAJ,CAAU,qCAAV,CAXA;;YAAA;cAcJ,qBAdI,GAc8B,IAd9B;;cAAA,MAeJ,WAAW,IAAI,IAfX;gBAAA;gBAAA;cAAA;;cAgBA,YAhBA,GAiBF,uBAAuB,CAAC,WAAD,EAAc,KAAK,WAAnB,CAjBrB;cAkBN,qBAAqB,GAAG,EAAxB;cACS,CAnBH,GAmBO,CAnBP;;YAAA;cAAA,MAmBU,CAAC,GAAG,YAAY,CAAC,MAnB3B;gBAAA;gBAAA;cAAA;;cAAA,eAoBJ,qBApBI;cAAA;cAAA,iCAqBM,kBAAkB,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,IAAhB,EAAsB,YAAY,CAAC,CAAD,CAAlC,CArBxB;;YAAA;cAAA;;cAAA,aAoBkB,IApBlB;;YAAA;cAmBmC,EAAE,CAnBrC;cAAA;cAAA;;YAAA;cAAA,kCA0BD,CAAC,UAAD,EAAa,UAAb,EAAyB,qBAAzB,CA1BC;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EAvsBZ;IAAA;IAAA,OA+uBU,kBACJ,CADI,EAC6B,GAD7B,EAC4C,SAD5C,EAEuB;MAAA;;MAAA,IAA3B,OAA2B,uEAAjB,CAAiB;MAAA,IAAd,KAAc;MAC7B,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;QACnB,IAAM,UAAU,GAAG,MAAI,CAAC,eAAL,CAAqB,GAArB,EAA0B,SAA1B,EAAqC,KAArC,EAA4C,OAA5C,CAAnB;;QACA,IAAM,IAAI,GAAa,EAAvB;;QACA,IAAI,OAAO,GAAG,CAAd,EAAiB;UACf,MAAM,IAAI,mBAAJ,CAAwB,sCAAxB,CAAN;QACD;;QAED,IAAI,KAAK,IAAI,IAAb,EAAmB;UACjB,MAAM,IAAI,mBAAJ,CACF,iDADE,CAAN;QAED,CAHD,MAGO;UACL,IAAM,OAAO,GAAG,WAAW,CAAC,UAAD,EAAa,SAAb,CAA3B;UACA,IAAM,UAAU,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAD,EAAI,UAAJ,CAAN,CAA3B;;UACA,KAAK,IAAI,UAAU,GAAG,CAAtB,EAAyB,UAAU,GAAG,OAAO,CAAC,MAA9C,EAAsD,EAAE,UAAxD,EAAoE;YAClE,IAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;YACA,IAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;YACA,IAAM,QAAQ,GACV,CAAC,CAAC,mBAAF,CACI,UADJ,EACgB,UADhB,EAC4B,QAAQ,GAAG,UADvC,CADJ;YAKA,IAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAD,EAAM,QAAN,CAArC;YACA,IAAM,SAAS,GAAG,CAAC,CAAC,QAAD,CAAnB;;YACA,IAAI,UAAU,KAAK,CAAnB,EAAsB;cACpB,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;gBACzC,IAAI,CAAC,IAAL,CAAU,MAAM,CAAC,CAAD,CAAhB;cACD;YACF;;YACD,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,GAAxC,EAA2C;cACzC,IAAM,QAAQ,GAAG,SAAS,CAAC,GAAD,CAA1B;cACA,IAAI,CAAC,GAAD,CAAJ,GACI,GAAG,CAAC,GAAJ,CAAQ,IAAI,CAAC,GAAD,CAAZ,EAAiB,GAAG,CAAC,GAAJ,CAAQ,QAAQ,GAAG,UAAnB,EAA+B,QAA/B,CAAjB,CADJ;YAED;UACF;;UACD,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,IAAI,CAAC,MAAzB,EAAiC,EAAE,GAAnC,EAAsC;YACpC,IAAI,CAAC,GAAD,CAAJ,GAAU,GAAG,CAAC,GAAJ,CAAQ,IAAI,CAAC,GAAD,CAAZ,EAAiB,UAAjB,CAAV;UACD;QACF;;QACD,OAAO,IAAP;MACD,CAvCM,CAAP;IAwCD;EA1xBH;IAAA;IAAA,OA4xBY,kCAAsB;MAC9B,IAAM,SAAS,GAAG,KAAK,YAAvB;MAGA,IAAM,gBAAgB,GAAG,EAAzB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;QACzC,IAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;QACA,IAAI,QAAQ,GAAG,KAAf;;QACA,IAAI,KAAK,CAAC,SAAD,EAAY,KAAZ,CAAL,GAA0B,CAA9B,EAAiC;UAC/B,IAAM,QAAQ,GAAG,KAAK,CAAC,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,CAAnB,CAAD,EAAwB,KAAxB,CAAtB;UACA,QAAQ,UAAQ,QAAhB;QACD;;QACD,gBAAgB,CAAC,IAAjB,CAAsB,QAAtB;MACD;;MACD,OAAO,gBAAP;IACD;EA3yBH;IAAA;IAAA,OAuzBY,6BAAiB;MAAA;;MACzB,OAAO,UAAC,IAAD,EAAmB;QACxB,IAAM,UAAU,GAAa,EAA7B;QAEA,IAAM,MAAM,GAAG,IAAI,CAAC,KAAL,CAAW,CAAX,EAAc,MAAI,CAAC,MAAL,CAAY,MAA1B,CAAf;QACA,IAAM,OAAO,GAAG,IAAI,CAAC,KAAL,CACZ,MAAI,CAAC,MAAL,CAAY,MADA,EACQ,MAAI,CAAC,MAAL,CAAY,MAAZ,GAAqB,MAAI,CAAC,OAAL,CAAa,MAD1C,CAAhB;QAEA,IAAM,aAAa,GAAG,IAAI,CAAC,KAAL,CAClB,MAAI,CAAC,MAAL,CAAY,MAAZ,GAAqB,MAAI,CAAC,OAAL,CAAa,MADhB,EAElB,MAAI,CAAC,MAAL,CAAY,MAAZ,GAAqB,MAAI,CAAC,OAAL,CAAa,MAAb,GAAsB,CAFzB,CAAtB;QAIA,IAAM,aAAa,GAAa,EAAhC;;QAKA,IAAM,iBAAiB,GAAG,SAApB,iBAAoB,GAAK;UAC7B,IAAM,KAAK,GAAG,EAAd;;UACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAI,CAAC,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;YAC3C,KAAK,CAAC,IAAN,CAAW;cAAC,GAAG,EAAE,MAAI,CAAC,MAAL,CAAY,CAAZ,CAAN;cAAsB,KAAK,EAAE,MAAM,CAAC,CAAD;YAAnC,CAAX;UACD;;UACD,IAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;;UACA,IAAM,OAAO,GACT,QAAO,CAAC,MAAI,CAAC,OAAN,EAAe,QAAf,EAAyB;YAAC,YAAY;UAAb,CAAzB,CADX;;UAKA,IAAI,SAAJ;;UACA,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,MAAI,CAAC,aAAL,CAAmB,MAAvC,EAA+C,EAAE,GAAjD,EAAoD;YAClD,IAAM,YAAY,GAAG,MAAI,CAAC,aAAL,CAAmB,GAAnB,CAArB;YACA,IAAI,IAAI,GAAG,YAAY,CAAC,OAAO,CAAC,GAAD,CAAR,EAAa,OAAO,CAAC,GAAD,CAApB,CAAvB;;YACA,IAAI,aAAa,CAAC,GAAD,CAAb,IAAoB,IAAxB,EAA8B;cAC5B,IAAI,GAAG,mBAAmB,CAAC,IAAD,EAAO,aAAa,CAAC,GAAD,CAApB,CAA1B;YACD;;YAGD,IAAM,QAAQ,GAAW,GAAG,CAAC,IAAJ,CAAS,IAAT,CAAzB;YAEA,UAAU,CAAC,IAAX,CAAgB,QAAhB;;YACA,IAAI,GAAC,KAAK,CAAV,EAAa;cACX,SAAS,GAAG,IAAZ;YACD,CAFD,MAEO;cACL,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,IAAnB,CAAZ;YACD;UACF;;UAKD,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,MAAI,CAAC,cAAL,CAAoB,MAAxC,EAAgD,EAAE,GAAlD,EAAqD;YACnD,IAAI,cAAsB,SAA1B;;YAEA,IAAI,MAAI,CAAC,OAAL,CAAa,MAAb,GAAsB,CAAtB,IAA2B,GAAC,GAAG,MAAI,CAAC,OAAL,CAAa,MAAhD,EAAwD;cACtD,cAAc,GAAG,UAAU,CAAC,GAAD,CAA3B;YACD,CAFD,MAEO;cACL,IAAM,MAAM,GAAG,MAAI,CAAC,cAAL,CAAoB,GAApB,EAAuB,CAAvB,CAAf;cACA,IAAM,WAAW,GAAG,MAAI,CAAC,cAAL,CAAoB,GAApB,EAAuB,CAAvB,CAApB;cACA,cAAc,GACV,GAAG,CAAC,IAAJ,CAAS,MAAM,CAAC,OAAO,CAAC,WAAD,CAAR,EAAuB,OAAO,CAAC,WAAD,CAA9B,CAAf,CADJ;YAED;;YAED,GAAG,CAAC,IAAJ,CAAS,cAAT;YAEA,aAAa,CAAC,IAAd,CAAmB,cAAnB;UACD;;UAED,SAAS,GAAG,GAAG,CAAC,IAAJ,CAAS,SAAT,CAAZ;;UAGA,MAAI,CAAC,eAAL,GAAuB,OAAvB,CAA+B,UAAA,eAAe,EAAG;YAC/C,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,eAAnB,CAAZ;UACD,CAFD;;UAIA,OAAO,SAAP;QACD,CA1DD;;QA4DA,IAAM,SAAS,GAAG,MAAI,CAAC,yBAAL,CAA+B,GAA/B,CACd,UAAA,KAAK;UAAA,OAAI,KAAK,CAAC,IAAN,EAAJ;QAAA,CADS,CAAlB;;QAEA,IAAM,UAAU,GAAG,IAAnB;;QACA,IAAM,cAAc,GAChB,MAAI,CAAC,UAAL,CAAgB,QAAhB,CAAyB,iBAAzB,EAA4C,UAA5C,EAAwD,SAAxD,CADJ;;QAGA,OAAO,CAAC,cAAD,EAAiB,MAAjB,CAAwB,aAAxB,CAAP;MACD,CAlFD;IAmFD;EA34BH;IAAA;IAAA,OAk5BU,4BAAgB;MAAA;;MACtB,KAAK,YAAL,GAAoB,UAAC,IAAD,EAAmB;QACrC,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;UACnB,IAAM,UAAU,GAAa,EAA7B;UACA,IAAI,SAAJ;UACA,IAAM,MAAM,GAAG,IAAI,CAAC,KAAL,CAAW,CAAX,EAAc,MAAI,CAAC,MAAL,CAAY,MAA1B,CAAf;UACA,IAAM,OAAO,GAAG,IAAI,CAAC,KAAL,CACZ,MAAI,CAAC,MAAL,CAAY,MADA,EACQ,MAAI,CAAC,MAAL,CAAY,MAAZ,GAAqB,MAAI,CAAC,OAAL,CAAa,MAD1C,CAAhB;UAEA,IAAM,KAAK,GAAG,EAAd;;UACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAI,CAAC,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;YAC3C,KAAK,CAAC,IAAN,CAAW;cAAC,GAAG,EAAE,MAAI,CAAC,MAAL,CAAY,CAAZ,CAAN;cAAsB,KAAK,EAAE,MAAM,CAAC,CAAD;YAAnC,CAAX;UACD;;UACD,IAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;;UACA,IAAM,OAAO,GAAG,QAAO,CAAC,MAAI,CAAC,OAAN,EAAe,QAAf,CAAvB;;UAEA,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,MAAI,CAAC,aAAL,CAAmB,MAAvC,EAA+C,EAAE,GAAjD,EAAoD;YAClD,IAAM,YAAY,GAAG,MAAI,CAAC,aAAL,CAAmB,GAAnB,CAArB;YAGA,IAAM,IAAI,GAAW,GAAG,CAAC,IAAJ,CAAS,YAAY,CAAC,OAAO,CAAC,GAAD,CAAR,EAAa,OAAO,CAAC,GAAD,CAApB,CAArB,CAArB;;YACA,IAAI,GAAC,KAAK,CAAV,EAAa;cACX,SAAS,GAAG,IAAZ;YACD,CAFD,MAEO;cACL,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,IAAnB,CAAZ;YACD;;YACD,UAAU,CAAC,IAAX,CAAgB,SAAhB;UACD;;UAED,KAAK,IAAI,GAAC,GAAG,CAAb,EAAgB,GAAC,GAAG,MAAI,CAAC,cAAL,CAAoB,MAAxC,EAAgD,EAAE,GAAlD,EAAqD;YACnD,IAAM,MAAM,GAAG,MAAI,CAAC,cAAL,CAAoB,GAApB,EAAuB,CAAvB,CAAf;YACA,IAAM,WAAW,GAAG,MAAI,CAAC,cAAL,CAAoB,GAApB,EAAuB,CAAvB,CAApB;YAEA,IAAM,UAAU,GACZ,GAAG,CAAC,IAAJ,CAAS,MAAM,CAAC,OAAO,CAAC,WAAD,CAAR,EAAuB,OAAO,CAAC,WAAD,CAA9B,CAAf,CADJ;YAEA,UAAU,CAAC,IAAX,CAAgB,UAAhB;UACD;;UACD,OAAO,UAAP;QACD,CAnCM,CAAP;MAoCD,CArCD;IAsCD;EAz7BH;IAAA;IAAA,OA69BE,aACI,CADJ,EAEI,CAFJ;MAAA;MAAA;MAAA;QAAA;UAAA;YAAA;cAGI,IAHJ,8DAGyB,EAHzB;cAAA,kCAIS,UAAU,CAAC,IAAD,EAAO,CAAP,EAAU,CAAV,EAAa,IAAb,CAJnB;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA79BF;IAAA;IAAA,OA2/BE,oBAAoB,OAApB,EAAyC,IAAzC;MAAA;QAAA;UAAA;YAAA;cAAA,kCAES,WAAU,CAAC,IAAD,EAAO,OAAP,EAAgB,IAAhB,CAFnB;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA3/BF;IAAA;IAAA,OAuhCE,sBACI,CADJ,EAEI,CAFJ;MAAA;;MAAA;QAAA;UAAA;YAAA;cAAA;cAAA,iCAM+B,KAAK,mBAAL,CAAyB,CAAzB,EAA4B,CAA5B,CAN/B;;YAAA;cAMQ,cANR;cAOQ,MAPR,GAOiB,cAAc,CAAC,CAAD,CAP/B;cAQQ,OARR,GAQkB,cAAc,CAAC,CAAD,CARhC;cASQ,aATR,GASwB,KAAK,iBAAL,EATxB;cAUQ,MAVR,GAUiB,aAAa,CAAC,MAAM,CAAC,MAAP,CAAc,OAAd,CAAD,CAV9B;cAWQ,UAXR,GAW+B,EAX/B;cAAA,6CAYqB,MAZrB;;YAAA;cAAA;gBAAA;gBAAA;cAAA;;cAYa,IAZb;cAAA;cAAA,iCAaoB,IAAI,CAAC,IAAL,EAbpB;;YAAA;cAaU,CAbV;cAcI,UAAU,CAAC,IAAX,CAAgB,CAAC,CAAC,CAAD,CAAjB;;YAdJ;cAAA;cAAA;;YAAA;cAgBE,GAAG,CAAC,OAAJ,CAAY,MAAZ;cAhBF,kCAiBS,gBAAgB,CAAC,UAAD,CAjBzB;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EAvhCF;IAAA;IAAA,OAojCY,yBAAgB,MAAhB,EAAsC;MAC9C,IAAM,YAAY,GAAkB,EAApC;MAEA,IAAM,aAAa,GAAG,MAAM,IAAI,IAAV,IAAkB,MAAM,CAAC,aAA/C;MACA,IAAM,OAAO,GAAG,aAAa,GAAG,KAAK,gBAAR,GAA2B,KAAK,OAA7D;MACA,IAAM,YAAY,GAAG,KAAK,UAAL,CAAgB,aAAhB,CAArB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;QACvC,IAAI,aAAa,IAAI,CAAC,OAAO,CAAC,CAAD,CAAP,CAAW,SAAjC,EAA4C;UAE1C;QACD;;QACD,YAAY,CAAC,IAAb,CACI;UAAC,IAAI,EAAE,OAAO,CAAC,CAAD,CAAP,CAAW,YAAlB;UAAgC,MAAM,EAAE,YAAY,CAAC,CAAD;QAApD,CADJ;MAED;;MACD,OAAO,YAAP;IACD;EAnkCH;IAAA;IAAA,KAumCE,eAAgB;MACd,OAAO,KAAK,aAAZ;IACD,CAzmCH;IAAA,KAmmCE,aAAiB,IAAjB,EAA8B;MAC5B,KAAK,aAAL,GAAqB,IAArB;IACD;EArmCH;IAAA;IAAA,KA2mCE,eAAa;MACX,OAAO,KAAK,UAAZ;IACD,CA7mCH;IAAA,KA+mCE,aAAc,SAAd,EAAkC;MAChC,IAAI,KAAK,UAAL,KAAoB,SAAxB,EAAmC;QACjC,KAAK,UAAL,GAAkB,SAAlB;QACA,KAAK,gBAAL,GAAwB,KAAxB;MACD;IACF;EApnCH;IAAA;IAAA,OAsnCE,mBAAO;MACL,IAAM,MAAM,2EAAZ;;MACA,IAAI,MAAM,CAAC,oBAAP,KAAgC,CAAhC,IAAqC,KAAK,SAAL,IAAkB,IAAvD,IACA,KAAK,gBADT,EAC2B;QACzB,IAAM,gCAAgC,GAAG,GAAG,CAAC,MAAJ,GAAa,UAAtD;QACA,KAAK,UAAL,CAAgB,OAAhB;QACA,MAAM,CAAC,oBAAP,IACI,gCAAgC,GAAG,GAAG,CAAC,MAAJ,GAAa,UADpD;MAED;;MACD,OAAO,MAAP;IACD;EAhoCH;IAAA;IAAA,OAkoCU,8BAAkB;MAExB,IAAI,SAAJ;;MAEA,IAAI,OAAO,KAAK,IAAZ,KAAqB,QAAzB,EAAmC;QACjC,SAAS,GAAG,WAAW,CAAC,KAAK,IAAN,CAAvB;MACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAJ,EAA8B;QACnC,sDAAmB,KAAK,IAAxB,2CAA8B;UAAA,IAAnB,IAAmB;;UAC5B,IAAI,OAAO,IAAP,KAAgB,QAApB,EAA8B;YAC5B,MAAM,IAAI,KAAJ,CAAU,oDAAV,CAAN;UACD;QACF;;QACD,SAAS,GAAI,KAAK,IAAL,CAAuB,GAAvB,CAA2B,UAAA,IAAI;UAAA,OAAI,WAAW,CAAC,IAAD,CAAf;QAAA,CAA/B,CAAb;MAED,CARM,MAQA;QACL,IAAM,WAAW,GAAG,MAAM,CAAC,IAAP,CAAY,KAAK,IAAjB,CAApB;QACA,SAAS,GAAG,EAAZ;QACA,IAAM,OAAM,GACR,KAAK,IADT;;QAEA,iCAAyB,WAAzB,oCAAsC;UAAjC,IAAM,UAAU,oBAAhB;;UACH,IAAI,OAAO,OAAM,CAAC,UAAD,CAAb,KAA8B,QAAlC,EAA4C;YAC1C,SAAS,CAAC,UAAD,CAAT,GACI,WAAW,CAAC,OAAM,CAAC,UAAD,CAAP,CADf;UAED,CAHD,MAGO;YACL,MAAM,IAAI,KAAJ,CAAU,oDAAV,CAAN;UACD;QACF;MACF;;MACD,OAAO,SAAP;IACD;EA/pCH;IAAA;IAAA,OAiqCU,gCAAoB;MAE1B,IAAI,OAAO,KAAK,OAAZ,KAAwB,QAAxB,IACA,OAAO,KAAK,OAAZ,KAAwB,UAD5B,EACwC;QACtC,OAAO,CAAC,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,KAAK,OAAjC,CAAD,CAAZ,CAAP;MACD,CAHD,MAGO,IAAI,KAAK,CAAC,OAAN,CAAc,KAAK,OAAnB,CAAJ,EAAiC;QACtC,OAAO,KAAK,OAAL,CAAa,GAAb,CACH,UAAA,MAAM;UAAA,OAAI,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,MAA5B,CAAD,CAAf;QAAA,CADH,CAAP;MAED,CAHM,MAGA;QACL,IAAM,kBAAkB,GAAuC,EAA/D;;QACA,KAAK,IAAM,GAAX,IAAkB,KAAK,OAAvB,EAAgC;UAC9B,kBAAkB,CAAC,GAAD,CAAlB,GACI,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,KAAK,OAAL,CAAa,GAAb,CAA5B,CAAD,CADf;QAED;;QACD,OAAO,kBAAP;MACD;IACF;EAjrCH;IAAA;IAAA,OAmrCY,6BAAiB;MACzB,OAAO;QACL,IAAI,EAAE,KAAK,kBAAL,EADD;QAEL,OAAO,EAAE,KAAK,oBAAL,EAFJ;QAGL,gBAAgB,EAAE;UAChB,UAAU,EAAE,KAAK,SAAL,CAAe,YAAf,EADI;UAEhB,MAAM,EAAE,KAAK,SAAL,CAAe,SAAf;QAFQ;MAHb,CAAP;IAWD;EA/rCH;IAAA;IAAA,OAisCE,4BAAmB,cAAnB,EAAiD;MAC/C,IAAI,cAAc,CAAC,gBAAf,IAAmC,IAAvC,EAA6C;QAC3C,MAAM,IAAI,KAAJ,CAAU,8CAAV,CAAN;MACD;;MACD,IAAI,cAAc,CAAC,YAAf,IAA+B,IAAnC,EAAyC;QACvC,MAAM,IAAI,KAAJ,CAAU,4CAAV,CAAN;MACD;;MACD,IAAI,cAAc,CAAC,kBAAf,IAAqC,IAAzC,EAA+C;QAC7C,MAAM,IAAI,KAAJ,CAAU,kDAAV,CAAN;MACD;;MAED,IAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAC,gBAAhB,CAApC;MAEA,IAAM,SAAS,GAAG,WAAW,CAAC,QAAD,CAA7B;MAEA,IAAI,IAAJ;;MACA,IAAI,OAAO,cAAc,CAAC,IAAtB,KAA+B,QAAnC,EAA6C;QAC3C,IAAI,GAAG,WAAW,CAAC,cAAc,CAAC,IAAhB,CAAlB;MACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,cAAc,CAAC,IAA7B,CAAJ,EAAwC;QAC7C,IAAI,GAAG,cAAc,CAAC,IAAf,CAAoB,GAApB,CAAwB,UAAA,SAAS;UAAA,OAAI,WAAW,CAAC,SAAD,CAAf;QAAA,CAAjC,CAAP;MACD,CAFM,MAEA,IAAI,cAAc,CAAC,IAAf,IAAuB,IAA3B,EAAiC;QACtC,IAAI,GAAG,EAAP;;QACA,KAAK,IAAM,GAAX,IAAkB,cAAc,CAAC,IAAjC,EAAuC;UACrC,IAAI,CAAC,GAAD,CAAJ,GAAY,WAAW,CAAC,cAAc,CAAC,IAAf,CAAoB,GAApB,CAAD,CAAvB;QACD;MACF;;MAED,IAAI,OAAJ;;MACA,IAAI,KAAK,CAAC,OAAN,CAAc,cAAc,CAAC,OAA7B,CAAJ,EAA2C;QACzC,OAAO,GAAG,cAAc,CAAC,OAAf,CAAuB,GAAvB,CAA2B,UAAA,MAAM;UAAA,OAAI,WAAW,CAAC,MAAD,CAAf;QAAA,CAAjC,CAAV;MACD,CAFD,MAEO,IAAI,cAAc,CAAC,OAAf,IAA0B,IAA9B,EAAoC;QACzC,OAAO,GAAG,EAAV;;QACA,KAAK,IAAM,IAAX,IAAkB,cAAc,CAAC,OAAjC,EAA0C;UACxC,OAAO,CAAC,IAAD,CAAP,GAAe,WAAW,CAAC,cAAc,CAAC,OAAf,CAAuB,IAAvB,CAAD,CAA1B;QACD;MACF;;MAED,KAAK,OAAL,CAAa;QAAC,IAAI,EAAJ,IAAD;QAAO,OAAO,EAAP,OAAP;QAAgB,SAAS,EAAT;MAAhB,CAAb;IACD;EAvuCH;IAAA;IAAA,OA0zCE,cAAW,YAAX,EAA8C,MAA9C;MAAA;;MAAA;QAAA;UAAA;YAAA;cAAA,MAEM,OAAO,YAAP,KAAwB,QAF9B;gBAAA;gBAAA;cAAA;;cAGU,QAHV,GAGqB,EAAE,CAAC,eAAH,CAAmB,YAAnB,CAHrB;;cAAA,MAIQ,QAAQ,CAAC,MAAT,KAAoB,CAJ5B;gBAAA;gBAAA;cAAA;;cAAA,MAKY,IAAI,UAAJ,6CACwC,YADxC,OALZ;;YAAA;cAAA,MAOe,QAAQ,CAAC,MAAT,GAAkB,CAPjC;gBAAA;gBAAA;cAAA;;cAAA,MAQY,IAAI,UAAJ,CACF,0BAAwB,QAAQ,CAAC,MAAjC,uCACQ,YADR,OADE,CARZ;;YAAA;cAYI,YAAY,GAAG,QAAQ,CAAC,CAAD,CAAvB;;YAZJ;cAAA,MAcM,YAAY,CAAC,IAAb,IAAqB,IAd3B;gBAAA;gBAAA;cAAA;;cAAA,MAeU,IAAI,UAAJ,CACF,6DACA,sDAFE,CAfV;;YAAA;cAAA;cAAA,iCAqBY,EAAE,CAAC,aAAH,CAAiB,KAAK,eAAL,CAAqB,MAArB,CAAjB,CArBZ;;YAAA;cAoBQ,kBApBR;cAuBQ,YAvBR,GAuBuB,KAvBvB;cAwBQ,SAxBR,GAwBwB,IAxBxB;cAyBQ,WAzBR,GAyBsB,KAAK,MAAL,CAAY,SAAZ,EAAuB,YAAvB,CAzBtB;cA0BQ,cA1BR,GA0B4C;gBACxC,aAAa,EAAE,WADyB;gBAExC,MAAM,EAAE,wBAFgC;gBAGxC,WAAW,kCAAgC,OAHH;gBAIxC,WAAW,EAAE;cAJ2B,CA1B5C;cAiCQ,gBAjCR,GAiC2B,MAAM,IAAI,IAAV,GAAiB,KAAjB,GAAyB,MAAM,CAAC,gBAjC3D;;cAAA,MAkCM,gBAAgB,IAAI,KAAK,SAAL,IAAkB,IAlC5C;gBAAA;gBAAA;cAAA;;cAmCI,cAAc,CAAC,cAAf,GAAgC,KAAK,iBAAL,EAAhC;cACM,UApCV,GAoCuB,WApCvB;cAAA;cAAA,eAsCc,EAtCd;cAAA;cAAA,iCAsCqC,KAAK,SAAL,CAAe,UAAf,EAtCrC;;YAAA;cAAA;cAAA,eAsCkE,UAtClE;cAAA,4BAsCiB,aAtCjB;cAAA;cAAA;;YAAA;cAAA;cAqCiB,mBArCjB,yBAqCW,IArCX;cAqC6C,oBArC7C,yBAqCsC,KArCtC;;cAuCI,yBAAA,kBAAkB,CAAC,KAAnB,EAAyB,IAAzB,iDAAiC,oBAAjC;;cACA,kBAAkB,CAAC,IAAnB,GAA0B,EAAE,CAAC,uBAAH,CACtB,CAAC,kBAAkB,CAAC,IAApB,EAA0B,mBAA1B,CADsB,CAA1B;;YAxCJ;cA4CE,IAAI,KAAK,mBAAL,IAA4B,IAAhC,EAAsC;gBAE9B,SAF8B,GAElB,IAFkB;gBAGpC,wBAAwB,CAAC,KAAK,mBAAN,EAA2B,KAAK,IAAhC,EAAsC,SAAtC,CAAxB;gBACA,cAAc,CAAC,mBAAf,GAAqC,KAAK,mBAA1C;cACD;;cAED,cAAc,CAAC,UAAf,GAA4B,kBAAkB,CAAC,IAA/C;cACA,cAAc,CAAC,WAAf,GAA6B,kBAAkB,CAAC,KAAhD;cApDF,kCAqDS,YAAY,CAAC,IAAb,CAAkB,cAAlB,CArDT;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA1zCF;IAAA;IAAA,OA03CE,gCAAuB,mBAAvB,EAA8C;MAC5C,wBAAwB,CAAC,mBAAD,EAAsB,KAAK,IAA3B,CAAxB;MACA,KAAK,mBAAL,GAA2B,mBAA3B;IACD;EA73CH;IAAA;IAAA,OA04CE,kCAAsB;MACpB,OAAO,KAAK,mBAAZ;IACD;EA54CH;;EAAA;AAAA,EAAiC,SAAjC;AAIS,WAAA,CAAA,SAAA,GAAY,OAAZ;AA04CT,aAAa,CAAC,aAAd,CAA4B,WAA5B;AASA,WAAa,UAAb;EAAA;;EAAA;;EAAA;IAAA;;IAAA;EAAA;;EAAA;AAAA,EAAgC,WAAhC;AACS,UAAA,CAAA,SAAA,GAAY,YAAZ;AAET,aAAa,CAAC,aAAd,CAA4B,UAA5B","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original Source: engine/training.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { NotImplementedError, RuntimeError, ValueError } from '../errors';\nimport { deserialize } from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport { checkUserDefinedMetadata } from '../user_defined_metadata';\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from '../utils/generic_utils';\nimport { printSummary } from '../utils/layer_utils';\nimport { range } from '../utils/math_utils';\nimport { convertPythonicToTs } from '../utils/serialization_utils';\nimport { version } from '../version';\nimport { Container } from './container';\nimport { execute, FeedDict } from './executor';\nimport { evaluateDataset, fitDataset } from './training_dataset';\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from './training_tensors';\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from './training_utils';\n/**\n * Helper function for polymorphic input data: 1. singleton Tensor.\n */\nexport function isDataTensor(x) {\n    return x instanceof Tensor;\n}\n/**\n * Helper function for polymorphic input data: 2. Array of Tensor.\n */\nexport function isDataArray(x) {\n    return Array.isArray(x);\n}\n/**\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\n */\nexport function isDataDict(x) {\n    return !isDataTensor(x) && !isDataArray(x);\n}\n/**\n * Normalizes inputs and targets provided by users.\n * @param data User-provided input data (polymorphic).\n * @param names An Array of expected Tensor names.\n * @param shapes Optional Array of expected Tensor shapes.\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\n *   match  the expected value found in `shapes`.\n * @param exceptionPrefix String prefix used for exception formatting.\n * @returns List of standardized input Tensors (one Tensor per model input).\n * @throws ValueError: in case of improperly formatted user data.\n */\nexport function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n    if (names == null || names.length === 0) {\n        // Check for the case where the model expected no data, but some data got\n        // sent.\n        if (data != null) {\n            let gotUnexpectedData = false;\n            if (isDataArray(data) && data.length > 0) {\n                gotUnexpectedData = true;\n            }\n            else if (isDataDict(data)) {\n                for (const key in data) {\n                    if (data.hasOwnProperty(key)) {\n                        gotUnexpectedData = true;\n                        break;\n                    }\n                }\n            }\n            else {\n                // `data` is a singleton Tensor in this case.\n                gotUnexpectedData = true;\n            }\n            if (gotUnexpectedData) {\n                throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, ` +\n                    `but got ${data}`);\n            }\n        }\n        return [];\n    }\n    if (data == null) {\n        return names.map(name => null);\n    }\n    let arrays;\n    if (isDataDict(data)) {\n        data = data;\n        arrays = [];\n        for (const name of names) {\n            if (data[name] == null) {\n                throw new ValueError(`No data provided for \"${name}\". Need data for each key in: ` +\n                    `${names}`);\n            }\n            arrays.push(data[name]);\n        }\n    }\n    else if (isDataArray(data)) {\n        data = data;\n        if (data.length !== names.length) {\n            throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` +\n                `Tensors that you are passing to your model is not the size the ` +\n                `model expected. Expected to see ${names.length} Tensor(s), but ` +\n                `instead got the following list of Tensor(s): ${data}`);\n        }\n        arrays = data;\n    }\n    else {\n        data = data;\n        if (names.length > 1) {\n            throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), ` +\n                `but only received one Tensor. Found: Tensor with shape ${data.shape}`);\n        }\n        arrays = [data];\n    }\n    arrays = ensureTensorsRank2OrHigher(arrays);\n    // Check shape compatibility.\n    if (shapes != null) {\n        for (let i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            const array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                    `to have ${shapes[i].length} dimension(s). but got array with ` +\n                    `shape ${array.shape}`);\n            }\n            for (let j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    // Skip the first (batch) axis.\n                    continue;\n                }\n                const dim = array.shape[j];\n                const refDim = shapes[i][j];\n                if (refDim != null && refDim >= 0 && dim !== refDim) {\n                    throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                        `to have shape [${shapes[i]}], but got array with shape ` +\n                        `[${array.shape}].`);\n                }\n            }\n        }\n    }\n    return arrays;\n}\n/**\n * User input validation for Tensors.\n * @param inputs `Array` of `tf.Tensor`s for inputs.\n * @param targets `Array` of `tf.Tensor`s for targets.\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\n * @throws ValueError: in case of incorrectly formatted data.\n */\nexport function checkArrayLengths(inputs, targets, weights) {\n    const setX = unique(inputs.map(input => input.shape[0]));\n    setX.sort();\n    const setY = unique(targets.map(target => target.shape[0]));\n    setY.sort();\n    // TODO(cais): Check `weights` as well.\n    if (setX.length > 1) {\n        throw new ValueError(`All input Tensors (x) should have the same number of samples. ` +\n            `Got array shapes: ` +\n            `${JSON.stringify(inputs.map(input => input.shape))}`);\n    }\n    if (setY.length > 1) {\n        throw new ValueError(`All target Tensors (y) should have the same number of samples. ` +\n            `Got array shapes: ` +\n            `${JSON.stringify(targets.map(target => target.shape))}`);\n    }\n    if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n        throw new ValueError(`Input Tensors should have the same number of samples as target ` +\n            `Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target ` +\n            `sample(s).`);\n    }\n}\n/**\n * Validation on the compatibility of targes and loss functions.\n *\n * This helps prevent users from using loss functions incorrectly.\n *\n * @param targets `Array` of `tf.Tensor`s of targets.\n * @param lossFns `Array` of loss functions.\n * @param outputShapes `Array` of shapes of model outputs.\n */\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n    // TODO(cais): Dedicated test coverage?\n    const keyLosses = [\n        losses.meanSquaredError, losses.binaryCrossentropy,\n        losses.categoricalCrossentropy\n    ];\n    for (let i = 0; i < targets.length; ++i) {\n        const y = targets[i];\n        const loss = lossFns[i];\n        const shape = outputShapes[i];\n        if (loss == null) {\n            continue;\n        }\n        if (loss === losses.categoricalCrossentropy) {\n            if (y.shape[y.shape.length - 1] === 1) {\n                throw new ValueError(`You are passing a target array of shape ${y.shape} while using ` +\n                    `a loss 'categorical_crossentropy'. 'categorical_crossentropy'` +\n                    `expects targets to be binary matrices (1s and 0s) of shape ` +\n                    `[samples, classes].`);\n                // TODO(cais): Example code in error message.\n            }\n        }\n        if (keyLosses.indexOf(loss) !== -1) {\n            const slicedYShape = y.shape.slice(1);\n            const slicedShape = shape.slice(1);\n            for (let j = 0; j < slicedYShape.length; ++j) {\n                const targetDim = slicedYShape[j];\n                const outDim = slicedShape[j];\n                if (outDim != null && targetDim !== outDim) {\n                    throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an ` +\n                        `output of shape ${shape}, while using a loss function that ` +\n                        `expects targets to have the same shape as the output.`);\n                }\n            }\n        }\n    }\n}\n/**\n * Check inputs provided by the user.\n *\n * Porting Note: This corresponds to _standardize_input_data() in Python\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\n *   the data. Specifically:\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\n *      example. We don't need to worry about that here because there is no\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\n *      If one becomes available in the future, we can add support.\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\n * may add support for `Object` data inputs in the future when the need\n * arises.\n *\n * Instead, we perform basic checks for number of parameters and shapes.\n *\n * @param data: The input data.\n * @param names: Name for the inputs, from the model.\n * @param shapes: Expected shapes for the input data, from the model.\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\n *   first dimension) will be checked for matching.\n * @param exceptionPrefix: Execption prefix message, used in generating error\n *   messages.\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\n */\nfunction checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n    let arrays;\n    if (Array.isArray(data)) {\n        if (data.length !== names.length) {\n            throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` +\n                `Tensors that you are passing to your model is not the size the ` +\n                `the model expected. Expected to see ${names.length} Tensor(s),` +\n                ` but instead got ${data.length} Tensors(s).`);\n        }\n        arrays = data;\n    }\n    else {\n        if (names.length > 1) {\n            throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, ` +\n                `but only received one Tensor. Found: array with shape ` +\n                `${JSON.stringify(data.shape)}.`);\n        }\n        arrays = [data];\n    }\n    if (shapes != null) {\n        for (let i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            const array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                    `to have ${shapes[i].length} dimension(s), but got array with ` +\n                    `shape ${JSON.stringify(array.shape)}`);\n            }\n            for (let j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    continue;\n                }\n                const dim = array.shape[j];\n                const refDim = shapes[i][j];\n                if (refDim != null) {\n                    if (refDim !== dim) {\n                        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ` +\n                            `${names[i]} to have shape ${JSON.stringify(shapes[i])} but ` +\n                            `got array with shape ${JSON.stringify(array.shape)}.`);\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Maps metric functions to model outputs.\n * @param metrics An shortcut strings name, metric function, `Array` or dict\n *   (`Object`) of metric functions.\n * @param outputNames An `Array` of the names of model outputs.\n * @returns An `Array` (one entry per model output) of `Array` of metric\n *   functions. For instance, if the model has 2 outputs, and for the first\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\n *   and just `binaryAccuracy` for the second output, the `Array` would look\n *   like:\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\n * @throws TypeError: incompatible metrics format.\n */\nexport function collectMetrics(metrics, outputNames) {\n    if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n        return outputNames.map(name => []);\n    }\n    let wrappedMetrics;\n    if (typeof metrics === 'string' || typeof metrics === 'function') {\n        wrappedMetrics = [metrics];\n    }\n    else if (Array.isArray(metrics) || typeof metrics === 'object') {\n        wrappedMetrics = metrics;\n    }\n    else {\n        throw new TypeError('Type of metrics argument not understood. Expected an string,' +\n            `function, Array, or Object, found: ${metrics}`);\n    }\n    if (Array.isArray(wrappedMetrics)) {\n        // We then apply all metrics to all outputs.\n        return outputNames.map(name => wrappedMetrics);\n    }\n    else {\n        // In this case, metrics is a dict.\n        const nestedMetrics = [];\n        for (const name of outputNames) {\n            let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n            if (!Array.isArray(outputMetrics)) {\n                outputMetrics = [outputMetrics];\n            }\n            nestedMetrics.push(outputMetrics);\n        }\n        return nestedMetrics;\n    }\n}\nconst LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n/**\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\n * for training, evaluation, prediction and saving.\n *\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\n *\n * See also:\n *   `tf.Sequential`, `tf.loadLayersModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class LayersModel extends Container {\n    constructor(args) {\n        super(args);\n        this.isTraining = false;\n    }\n    /**\n     * Print a text summary of the model's layers.\n     *\n     * The summary includes\n     * - Name and type of all layers that comprise the model.\n     * - Output shape(s) of the layers\n     * - Number of weight parameters of each layer\n     * - If the model has non-sequential-like topology, the inputs each layer\n     *   receives\n     * - The total number of trainable and non-trainable parameters of the model.\n     *\n     * ```js\n     * const input1 = tf.input({shape: [10]});\n     * const input2 = tf.input({shape: [20]});\n     * const dense1 = tf.layers.dense({units: 4}).apply(input1);\n     * const dense2 = tf.layers.dense({units: 8}).apply(input2);\n     * const concat = tf.layers.concatenate().apply([dense1, dense2]);\n     * const output =\n     *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\n     *\n     * const model = tf.model({inputs: [input1, input2], outputs: output});\n     * model.summary();\n     * ```\n     *\n     * @param lineLength Custom line length, in number of characters.\n     * @param positions Custom widths of each of the columns, as either\n     *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n     *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n     *   right-most (i.e., ending) position of a column.\n     * @param printFn Custom print function. Can be used to replace the default\n     *   `console.log`. For example, you can use `x => {}` to mute the printed\n     *   messages in the console.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    summary(lineLength, positions, printFn = console.log) {\n        if (!this.built) {\n            throw new ValueError(`This model has never been called, thus its weights have not been ` +\n                `created yet. So no summary can be displayed. Build the model ` +\n                `first (e.g., by calling it on some test data).`);\n        }\n        printSummary(this, lineLength, positions, printFn);\n    }\n    /**\n     * Configures and prepares the model for training and evaluation.  Compiling\n     * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\n     * or `evaluate` on an un-compiled model will throw an error.\n     *\n     * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\n     * metrics to be used for fitting and evaluating this model.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    compile(args) {\n        if (args.loss == null) {\n            args.loss = [];\n        }\n        this.loss = args.loss;\n        if (typeof args.optimizer === 'string') {\n            this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n            this.isOptimizerOwned = true;\n        }\n        else {\n            if (!(args.optimizer instanceof Optimizer)) {\n                throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);\n            }\n            this.optimizer_ = args.optimizer;\n            this.isOptimizerOwned = false;\n        }\n        // TODO(cais): Add lossWeights.\n        // TODO(cais): Add sampleWeightMode.\n        // Prepare loss functions.\n        let lossFunctions = [];\n        if (!Array.isArray(args.loss) && typeof args.loss !== 'string' &&\n            typeof args.loss !== 'function') {\n            args.loss = args.loss;\n            for (const name in args.loss) {\n                if (this.outputNames.indexOf(name) === -1) {\n                    throw new ValueError(`Unknown entry in loss dictionary: \"${name}\". ` +\n                        `Only expected the following keys: ${this.outputNames}`);\n                }\n            }\n            for (const name of this.outputNames) {\n                if (args.loss[name] == null) {\n                    console.warn(`Output \"${name}\" is missing from loss dictionary. We assume ` +\n                        `this was done on purpose, and we will not be expecting data ` +\n                        `to be passed to ${name} during training`);\n                }\n                lossFunctions.push(losses.get(args.loss[name]));\n            }\n        }\n        else if (Array.isArray(args.loss)) {\n            if (args.loss.length !== this.outputs.length) {\n                throw new ValueError(`When passing an Array as loss, it should have one entry per ` +\n                    `model output. The model has ${this.outputs.length} output(s), ` +\n                    `but you passed loss=${args.loss}.`);\n            }\n            const theLosses = args.loss;\n            lossFunctions = theLosses.map(l => losses.get(l));\n        }\n        else {\n            const lossFunction = losses.get(args.loss);\n            this.outputs.forEach(_ => {\n                lossFunctions.push(lossFunction);\n            });\n        }\n        this.lossFunctions = lossFunctions;\n        this.feedOutputNames = [];\n        this.feedOutputShapes = [];\n        this.feedLossFns = [];\n        for (let i = 0; i < this.outputs.length; ++i) {\n            // TODO(cais): Logic for skipping target(s).\n            const shape = this.internalOutputShapes[i];\n            const name = this.outputNames[i];\n            this.feedOutputNames.push(name);\n            this.feedOutputShapes.push(shape);\n            this.feedLossFns.push(this.lossFunctions[i]);\n        }\n        // TODO(cais): Add logic for output masks.\n        // TODO(cais): Add logic for sample weights.\n        const skipTargetIndices = [];\n        // Prepare metrics.\n        this.metrics = args.metrics;\n        // TODO(cais): Add weightedMetrics.\n        this.metricsNames = ['loss'];\n        this.metricsTensors = [];\n        // Compute total loss.\n        // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n        //   Here, metricsTensors are TypeScript functions. This difference is due\n        //   to the difference in symbolic/imperative property of the backends.\n        nameScope('loss', () => {\n            for (let i = 0; i < this.outputs.length; ++i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    continue;\n                }\n                // TODO(cais): Add weightedLoss, sampleWeight and mask.\n                //   The following line should be weightedLoss\n                const weightedLoss = this.lossFunctions[i];\n                if (this.outputs.length > 1) {\n                    this.metricsTensors.push([weightedLoss, i]);\n                    this.metricsNames.push(this.outputNames[i] + '_loss');\n                }\n            }\n            // Porting Note: Due to the imperative nature of the backend, we calculate\n            //   the regularizer penalties in the totalLossFunction, instead of here.\n        });\n        const nestedMetrics = collectMetrics(args.metrics, this.outputNames);\n        // TODO(cais): Add nestedWeightedMetrics.\n        /**\n         * Helper function used in loop below.\n         */\n        const appendMetric = (outputIndex, metricName, metricTensor) => {\n            if (this.outputNames.length > 1) {\n                metricName = this.outputNames[outputIndex] + '_' + metricName;\n            }\n            this.metricsNames.push(metricName);\n            this.metricsTensors.push([metricTensor, outputIndex]);\n        };\n        nameScope('metric', () => {\n            for (let i = 0; i < this.outputs.length; ++i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    continue;\n                }\n                const outputMetrics = nestedMetrics[i];\n                // TODO(cais): Add weights and outputWeightedMetrics.\n                // TODO(cais): Add optional arg `weights` to the following function.\n                const handleMetrics = (metrics) => {\n                    const metricNamePrefix = '';\n                    let metricName;\n                    let accFn;\n                    let weightedMetricFn;\n                    //  TODO(cais): Use 'weights_' for weighted metrics.\n                    for (const metric of metrics) {\n                        if (typeof metric === 'string' &&\n                            ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !==\n                                -1) {\n                            const outputShape = this.internalOutputShapes[i];\n                            if (outputShape[outputShape.length - 1] === 1 ||\n                                this.lossFunctions[i] === losses.binaryCrossentropy) {\n                                // case: binary accuracy/crossentropy.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryCrossentropy;\n                                }\n                            }\n                            else if (this.lossFunctions[i] ===\n                                losses.sparseCategoricalCrossentropy) {\n                                // case: categorical accuracy / crossentropy with sparse\n                                // targets.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalCrossentropy;\n                                }\n                            }\n                            else {\n                                // case: categorical accuracy / crossentropy.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalCrossentropy;\n                                }\n                            }\n                            let suffix;\n                            if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                suffix = 'acc';\n                            }\n                            else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                suffix = 'ce';\n                            }\n                            // TODO(cais): Add weighting actually.\n                            weightedMetricFn = accFn;\n                            metricName = metricNamePrefix + suffix;\n                        }\n                        else {\n                            const metricFn = Metrics.get(metric);\n                            // TODO(cais): Add weighting actually.\n                            weightedMetricFn = metricFn;\n                            metricName =\n                                metricNamePrefix + Metrics.getLossOrMetricName(metric);\n                        }\n                        // TODO(cais): Add weighting and masking to metricResult.\n                        let metricResult;\n                        nameScope(metricName, () => {\n                            metricResult = weightedMetricFn;\n                        });\n                        appendMetric(i, metricName, metricResult);\n                    }\n                };\n                handleMetrics(outputMetrics);\n                // TODO(cais): Call handleMetrics with weights.\n            }\n        });\n        // Porting Notes: Given the imperative backend of tfjs-core,\n        //   there is no need for constructing the symbolic graph and placeholders.\n        this.collectedTrainableWeights = this.trainableWeights;\n    }\n    /**\n     * Check trainable weights count consistency.\n     *\n     * This will raise a warning if `this.trainableWeights` and\n     * `this.collectedTrainableWeights` are inconsistent (i.e., have different\n     * numbers of parameters).\n     * Inconsistency will typically arise when one modifies `model.trainable`\n     * without calling `model.compile()` again.\n     */\n    checkTrainableWeightsConsistency() {\n        if (this.collectedTrainableWeights == null) {\n            return;\n        }\n        if (this.trainableWeights.length !==\n            this.collectedTrainableWeights.length) {\n            console.warn('Discrepancy between trainableweights and collected trainable ' +\n                'weights. Did you set `model.trainable` without calling ' +\n                '`model.compile()` afterwards?');\n        }\n    }\n    /**\n     * Returns the loss value & metrics values for the model in test mode.\n     *\n     * Loss and metrics are specified during `compile()`, which needs to happen\n     * before calls to `evaluate()`.\n     *\n     * Computation is done in batches.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const result = model.evaluate(\n     *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\n     * result.print();\n     * ```\n     *\n     * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple inputs.\n     * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple outputs.\n     * @param args A `ModelEvaluateArgs`, containing optional fields.\n     *\n     * @return `Scalar` test loss (if the model has a single output and no\n     *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n     *   and/or metrics). The attribute `model.metricsNames`\n     *   will give you the display labels for the scalar outputs.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    evaluate(x, y, args = {}) {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // TODO(cais): Standardize `config.sampleWeights` as well.\n        // Validate user data.\n        const checkBatchAxis = true;\n        const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n        try {\n            // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n            // of the input to 0.\n            const ins = standardizedOuts[0].concat(standardizedOuts[1]);\n            this.makeTestFunction();\n            const f = this.testFunction;\n            const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n            return singletonOrArray(testOuts);\n        }\n        finally {\n            disposeNewTensors(standardizedOuts[0], x);\n            disposeNewTensors(standardizedOuts[1], y);\n        }\n    }\n    // TODO(cais): Add code snippet below once real dataset objects are\n    //   available.\n    /**\n     * Evaluate model using a dataset object.\n     *\n     * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for evaluation. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs. Of the two items in the array, the\n     *   first is the input feature(s) and the second is the output target(s).\n     * @param args A configuration object for the dataset-based evaluation.\n     * @returns Loss and metric values as an Array of `Scalar` objects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async evaluateDataset(dataset, args) {\n        this.makeTestFunction();\n        return evaluateDataset(this, dataset, args);\n    }\n    /**\n     * Get number of samples provided for training, evaluation or prediction.\n     *\n     * @param ins Input `tf.Tensor`.\n     * @param batchSize Integer batch size, optional.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring loop finished. Optional.\n     * @param stepsName The public API's parameter name for `steps`.\n     * @returns Number of samples provided.\n     */\n    checkNumSamples(ins, batchSize, steps, stepsName = 'steps') {\n        let numSamples;\n        if (steps != null) {\n            numSamples = null;\n            if (batchSize != null) {\n                throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.` +\n                    `Got batchSize = ${batchSize}`);\n            }\n        }\n        else if (ins != null) {\n            if (Array.isArray(ins)) {\n                numSamples = ins[0].shape[0];\n            }\n            else {\n                numSamples = ins.shape[0];\n            }\n        }\n        else {\n            throw new ValueError(`Either the input data should have a defined shape, or ` +\n                `${stepsName} shoud be specified.`);\n        }\n        return numSamples;\n    }\n    /**\n     * Execute internal tensors of the model with input data feed.\n     * @param inputs Input data feed. Must match the inputs of the model.\n     * @param outputs Names of the output tensors to be fetched. Must match\n     *   names of the SymbolicTensors that belong to the graph.\n     * @returns Fetched values for `outputs`.\n     */\n    execute(inputs, outputs) {\n        if (Array.isArray(outputs) && outputs.length === 0) {\n            throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n        }\n        const outputsIsArray = Array.isArray(outputs);\n        const outputNames = (outputsIsArray ? outputs : [outputs]);\n        const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);\n        // Format the input into a FeedDict.\n        const feedDict = new FeedDict();\n        if (inputs instanceof Tensor) {\n            inputs = [inputs];\n        }\n        if (Array.isArray(inputs)) {\n            if (inputs.length !== this.inputs.length) {\n                throw new ValueError(`The number of inputs provided (${inputs.length}) ` +\n                    `does not match the number of inputs of this model ` +\n                    `(${this.inputs.length}).`);\n            }\n            for (let i = 0; i < this.inputs.length; ++i) {\n                feedDict.add(this.inputs[i], inputs[i]);\n            }\n        }\n        else {\n            for (const input of this.inputs) {\n                const tensorValue = inputs[input.name];\n                if (tensorValue == null) {\n                    throw new ValueError(`No value is provided for the model's input ${input.name}`);\n                }\n                feedDict.add(input, tensorValue);\n            }\n        }\n        // Run execution.\n        const executeOutputs = execute(outputSymbolicTensors, feedDict);\n        return outputsIsArray ? executeOutputs : executeOutputs[0];\n    }\n    /**\n     * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\n     */\n    retrieveSymbolicTensors(symbolicTensorNames) {\n        const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n        let outputsRemaining = symbolicTensorNames.length;\n        for (const layer of this.layers) {\n            const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n            const layerOutputNames = layerOutputs.map(output => output.name);\n            for (let i = 0; i < symbolicTensorNames.length; ++i) {\n                const index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n                if (index !== -1) {\n                    outputSymbolicTensors[i] = layerOutputs[index];\n                    outputsRemaining--;\n                }\n                if (outputsRemaining === 0) {\n                    break;\n                }\n            }\n            if (outputsRemaining === 0) {\n                break;\n            }\n        }\n        if (outputsRemaining > 0) {\n            const remainingNames = [];\n            outputSymbolicTensors.forEach((tensor, i) => {\n                if (tensor == null) {\n                    remainingNames.push(symbolicTensorNames[i]);\n                }\n            });\n            throw new ValueError(`Cannot find SymbolicTensors for output name(s): ` +\n                `${JSON.stringify(remainingNames)}`);\n        }\n        return outputSymbolicTensors;\n    }\n    /**\n     * Helper method to loop over some data in batches.\n     *\n     * Porting Note: Not using the functional approach in the Python equivalent\n     *   due to the imperative backend.\n     * Porting Note: Does not support step mode currently.\n     *\n     * @param ins: input data\n     * @param batchSize: integer batch size.\n     * @param verbose: verbosity model\n     * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\n     *   `tf.Tensor` (if multipe outputs).\n     */\n    predictLoop(ins, batchSize = 32, verbose = false) {\n        return tfc.tidy(() => {\n            const numSamples = this.checkNumSamples(ins);\n            if (verbose) {\n                throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n            }\n            // Sample-based predictions.\n            // Porting Note: Tensor currently does not support sliced assignments as\n            //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n            //   iterating over the batches.\n            const batches = makeBatches(numSamples, batchSize);\n            const outsBatches = this.outputs.map(output => []);\n            // TODO(cais): Can the scope() be pushed down inside the for loop?\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchOuts = tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    // TODO(cais): Take care of the case of the last element is a flag for\n                    //   training/test.\n                    const insBatch = sliceArrays(ins, batchStart, batchEnd);\n                    // Construct the feeds for execute();\n                    const feeds = [];\n                    if (Array.isArray(insBatch)) {\n                        for (let i = 0; i < insBatch.length; ++i) {\n                            feeds.push({ key: this.inputs[i], value: insBatch[i] });\n                        }\n                    }\n                    else {\n                        feeds.push({ key: this.inputs[0], value: insBatch });\n                    }\n                    const feedDict = new FeedDict(feeds);\n                    return execute(this.outputs, feedDict);\n                });\n                batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));\n            }\n            return singletonOrArray(outsBatches.map(batches => tfc.concat(batches, 0)));\n        });\n    }\n    /**\n     * Generates output predictions for the input samples.\n     *\n     * Computation is done in batches.\n     *\n     * Note: the \"step\" mode of predict() is currently not supported.\n     *   This is because the TensorFlow.js core backend is imperative only.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\n     * ```\n     *\n     * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n     *   the model has multiple inputs.\n     * @param args A `ModelPredictArgs` object containing optional fields.\n     *\n     * @return Prediction results as a `tf.Tensor`(s).\n     *\n     * @exception ValueError In case of mismatch between the provided input data\n     *   and the model's expectations, or in case a stateful model receives a\n     *   number of samples that is not a multiple of the batch size.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    predict(x, args = {}) {\n        const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n        checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n        try {\n            // TODO(cais): Take care of stateful models.\n            //   if (this.stateful) ...\n            // TODO(cais): Take care of the learning_phase boolean flag.\n            //   if (this.useLearningPhase) ...\n            const batchSize = args.batchSize == null ? 32 : args.batchSize;\n            checkBatchSize(batchSize);\n            return this.predictLoop(xsRank2OrHigher, batchSize);\n        }\n        finally {\n            disposeNewTensors(xsRank2OrHigher, x);\n        }\n    }\n    /**\n     * Returns predictions for a single batch of samples.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predictOnBatch(tf.ones([8, 10])).print();\n     * ```\n     * @param x: Input samples, as a Tensor (for models with exactly one\n     *   input) or an array of Tensors (for models with more than one input).\n     * @return Tensor(s) of predictions\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    predictOnBatch(x) {\n        checkInputData(x, this.inputNames, this.feedInputShapes, true);\n        // TODO(cais): Take care of the learning_phase boolean flag.\n        //   if (this.useLearningPhase) ...\n        const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n        return this.predictLoop(x, batchSize);\n    }\n    standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {\n        // TODO(cais): Add sampleWeight, classWeight\n        if (this.optimizer_ == null) {\n            throw new RuntimeError('You must compile a model before training/testing. Use ' +\n                'LayersModel.compile(modelCompileArgs).');\n        }\n        const outputShapes = [];\n        for (let i = 0; i < this.feedOutputShapes.length; ++i) {\n            const outputShape = this.feedOutputShapes[i];\n            const lossFn = this.feedLossFns[i];\n            if (lossFn === losses.sparseCategoricalCrossentropy) {\n                outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n            }\n            else {\n                // Porting Note: Because of strong typing `lossFn` must be a function.\n                outputShapes.push(outputShape);\n            }\n        }\n        x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n        y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target');\n        // TODO(cais): Standardize sampleWeights & classWeights.\n        checkArrayLengths(x, y, null);\n        // TODO(cais): Check sampleWeights as well.\n        checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n        if (this.stateful && batchSize != null && batchSize > 0) {\n            if (x[0].shape[0] % batchSize !== 0) {\n                throw new ValueError(`In a stateful network, you should only pass inputs with a ` +\n                    `number of samples that is divisible by the batch size ` +\n                    `${batchSize}. Found: ${x[0].shape[0]} sample(s).`);\n            }\n        }\n        return [x, y];\n    }\n    async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {\n        const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n        // TODO(cais): Handle sampleWeights.\n        if (sampleWeight != null) {\n            throw new Error('sample weight is not supported yet.');\n        }\n        let standardSampleWeights = null;\n        if (classWeight != null) {\n            const classWeights = standardizeClassWeights(classWeight, this.outputNames);\n            standardSampleWeights = [];\n            for (let i = 0; i < classWeights.length; ++i) {\n                standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));\n            }\n        }\n        // TODO(cais): Deal with the case of model.stateful == true.\n        return [standardXs, standardYs, standardSampleWeights];\n    }\n    /**\n     * Loop over some test data in batches.\n     * @param f A Function returning a list of tensors.\n     * @param ins Array of tensors to be fed to `f`.\n     * @param batchSize Integer batch size or `null` / `undefined`.\n     * @param verbose verbosity mode.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring test finished. Ignored with the default value of `null` /\n     * `undefined`.\n     * @returns Array of Scalars.\n     */\n    testLoop(f, ins, batchSize, verbose = 0, steps) {\n        return tfc.tidy(() => {\n            const numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n            const outs = [];\n            if (verbose > 0) {\n                throw new NotImplementedError('Verbose mode is not implemented yet.');\n            }\n            // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n            if (steps != null) {\n                throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n            }\n            else {\n                const batches = makeBatches(numSamples, batchSize);\n                const indexArray = tensor1d(range(0, numSamples));\n                for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const batchOuts = f(insBatch);\n                    if (batchIndex === 0) {\n                        for (let i = 0; i < batchOuts.length; ++i) {\n                            outs.push(scalar(0));\n                        }\n                    }\n                    for (let i = 0; i < batchOuts.length; ++i) {\n                        const batchOut = batchOuts[i];\n                        outs[i] =\n                            tfc.add(outs[i], tfc.mul(batchEnd - batchStart, batchOut));\n                    }\n                }\n                for (let i = 0; i < outs.length; ++i) {\n                    outs[i] = tfc.div(outs[i], numSamples);\n                }\n            }\n            return outs;\n        });\n    }\n    getDedupedMetricsNames() {\n        const outLabels = this.metricsNames;\n        // Rename duplicated metrics names (can happen with an output layer\n        // shared among multiple dataflows).\n        const dedupedOutLabels = [];\n        for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            let newLabel = label;\n            if (count(outLabels, label) > 1) {\n                const dupIndex = count(outLabels.slice(0, i), label);\n                newLabel += `_${dupIndex}`;\n            }\n            dedupedOutLabels.push(newLabel);\n        }\n        return dedupedOutLabels;\n    }\n    /**\n     * Creates a function that performs the following actions:\n     *\n     * 1. computes the losses\n     * 2. sums them to get the total loss\n     * 3. call the optimizer computes the gradients of the LayersModel's\n     *    trainable weights w.r.t. the total loss and update the variables\n     * 4. calculates the metrics\n     * 5. returns the values of the losses and metrics.\n     */\n    makeTrainFunction() {\n        return (data) => {\n            const lossValues = [];\n            const inputs = data.slice(0, this.inputs.length);\n            const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n            const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);\n            const metricsValues = [];\n            // Create a function that computes the total loss based on the\n            // inputs. This function is used for obtaining gradients through\n            // backprop.\n            const totalLossFunction = () => {\n                const feeds = [];\n                for (let i = 0; i < this.inputs.length; ++i) {\n                    feeds.push({ key: this.inputs[i], value: inputs[i] });\n                }\n                const feedDict = new FeedDict(feeds);\n                const outputs = execute(this.outputs, feedDict, { 'training': true });\n                // TODO(cais): Take care of the case of multiple outputs from a\n                //   single layer?\n                let totalLoss;\n                for (let i = 0; i < this.lossFunctions.length; ++i) {\n                    const lossFunction = this.lossFunctions[i];\n                    let loss = lossFunction(targets[i], outputs[i]);\n                    if (sampleWeights[i] != null) {\n                        loss = computeWeightedLoss(loss, sampleWeights[i]);\n                    }\n                    // TODO(cais): push Scalar instead.\n                    const meanLoss = tfc.mean(loss);\n                    // TODO(cais): Use a scope() instead, to avoid ownership.\n                    lossValues.push(meanLoss);\n                    if (i === 0) {\n                        totalLoss = loss;\n                    }\n                    else {\n                        totalLoss = tfc.add(totalLoss, loss);\n                    }\n                }\n                // Compute the metrics.\n                // TODO(cais): These should probably be calculated outside\n                //   totalLossFunction to benefit speed?\n                for (let i = 0; i < this.metricsTensors.length; ++i) {\n                    let weightedMetric;\n                    if (this.outputs.length > 1 && i < this.outputs.length) {\n                        weightedMetric = lossValues[i];\n                    }\n                    else {\n                        const metric = this.metricsTensors[i][0];\n                        const outputIndex = this.metricsTensors[i][1];\n                        weightedMetric =\n                            tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                    }\n                    tfc.keep(weightedMetric);\n                    // TODO(cais): Use a scope() instead, to avoid ownership.\n                    metricsValues.push(weightedMetric);\n                }\n                totalLoss = tfc.mean(totalLoss);\n                // Add regularizer penalties.\n                this.calculateLosses().forEach(regularizerLoss => {\n                    totalLoss = tfc.add(totalLoss, regularizerLoss);\n                });\n                return totalLoss;\n            };\n            const variables = this.collectedTrainableWeights.map(param => param.read());\n            const returnCost = true;\n            const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);\n            return [totalLossValue].concat(metricsValues);\n        };\n    }\n    /**\n     * Create a function which, when invoked with an array of `tf.Tensor`s as a\n     * batch of inputs, returns the prespecified loss and metrics of the model\n     * under the batch of input data.\n     */\n    makeTestFunction() {\n        this.testFunction = (data) => {\n            return tfc.tidy(() => {\n                const valOutputs = [];\n                let totalLoss;\n                const inputs = data.slice(0, this.inputs.length);\n                const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n                const feeds = [];\n                for (let i = 0; i < this.inputs.length; ++i) {\n                    feeds.push({ key: this.inputs[i], value: inputs[i] });\n                }\n                const feedDict = new FeedDict(feeds);\n                const outputs = execute(this.outputs, feedDict);\n                // Compute total loss.\n                for (let i = 0; i < this.lossFunctions.length; ++i) {\n                    const lossFunction = this.lossFunctions[i];\n                    // TODO(cais): Add sample weighting and replace the simple\n                    // averaging.\n                    const loss = tfc.mean(lossFunction(targets[i], outputs[i]));\n                    if (i === 0) {\n                        totalLoss = loss;\n                    }\n                    else {\n                        totalLoss = tfc.add(totalLoss, loss);\n                    }\n                    valOutputs.push(totalLoss);\n                }\n                // Compute the metrics.\n                for (let i = 0; i < this.metricsTensors.length; ++i) {\n                    const metric = this.metricsTensors[i][0];\n                    const outputIndex = this.metricsTensors[i][1];\n                    // TODO(cais): Replace K.mean() with a proper weighting function.\n                    const meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                    valOutputs.push(meanMetric);\n                }\n                return valOutputs;\n            });\n        };\n    }\n    /**\n     * Trains the model for a fixed number of epochs (iterations on a\n     * dataset).\n     *\n     * ```js\n     * const model = tf.sequential({\n     *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * for (let i = 1; i < 5 ; ++i) {\n     *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n     *       batchSize: 4,\n     *       epochs: 3\n     *   });\n     *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\n     * }\n     * ```\n     *\n     * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n     * model has multiple inputs. If all inputs in the model are named, you\n     * can also pass a dictionary mapping input names to `tf.Tensor`s.\n     * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n     * the model has multiple outputs. If all outputs in the model are named,\n     * you can also pass a dictionary mapping output names to `tf.Tensor`s.\n     * @param args A `ModelFitArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @exception ValueError In case of mismatch between the provided input\n     * data and what the model expects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async fit(x, y, args = {}) {\n        return fitTensors(this, x, y, args);\n    }\n    // TODO(cais): Add code snippet below when it's possible to instantiate\n    //   actual dataset objects.\n    /**\n     * Trains the model using a dataset object.\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for training. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs.\n     *   Of the two items in the array, the first is the input feature(s) and\n     *   the second is the output target(s).\n     * @param args A `ModelFitDatasetArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async fitDataset(dataset, args) {\n        return fitDataset(this, dataset, args);\n    }\n    /**\n     * Runs a single gradient update on a single batch of data.\n     *\n     * This method differs from `fit()` and `fitDataset()` in the following\n     * regards:\n     *   - It operates on exactly one batch of data.\n     *   - It returns only the loss and matric values, instead of\n     *     returning the batch-by-batch loss and metric values.\n     *   - It doesn't support fine-grained options such as verbosity and\n     *     callbacks.\n     *\n     * @param x Input data. It could be one of the following:\n     *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n     *     multiple inputs).\n     *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n     *     model has named inputs).\n     * @param y Target darta. It could be either a `tf.Tensor` a multiple\n     *   `tf.Tensor`s. It should be consistent with `x`.\n     * @returns Training loss or losses (in case the model has\n     *   multiple outputs), along with metrics (if any), as numbers.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async trainOnBatch(x, y) {\n        // TODO(cais): Support sampleWeight and classWeight.\n        // TODO(cais): Support Dataset objects.\n        const standardizeOut = await this.standardizeUserData(x, y);\n        const inputs = standardizeOut[0];\n        const targets = standardizeOut[1];\n        const trainFunction = this.makeTrainFunction();\n        const losses = trainFunction(inputs.concat(targets));\n        const lossValues = [];\n        for (const loss of losses) {\n            const v = await loss.data();\n            lossValues.push(v[0]);\n        }\n        tfc.dispose(losses);\n        return singletonOrArray(lossValues);\n    }\n    /**\n     * Extract weight values of the model.\n     *\n     * @param config: An instance of `io.SaveConfig`, which specifies\n     * model-saving options such as whether only trainable weights are to be\n     * saved.\n     * @returns A `NamedTensorMap` mapping original weight names (i.e.,\n     *   non-uniqueified weight names) to their values.\n     */\n    getNamedWeights(config) {\n        const namedWeights = [];\n        const trainableOnly = config != null && config.trainableOnly;\n        const weights = trainableOnly ? this.trainableWeights : this.weights;\n        const weightValues = this.getWeights(trainableOnly);\n        for (let i = 0; i < weights.length; ++i) {\n            if (trainableOnly && !weights[i].trainable) {\n                // Optionally skip non-trainable weights.\n                continue;\n            }\n            namedWeights.push({ name: weights[i].originalName, tensor: weightValues[i] });\n        }\n        return namedWeights;\n    }\n    /**\n     * Setter used for force stopping of LayersModel.fit() (i.e., training).\n     *\n     * Example:\n     *\n     * ```js\n     * const input = tf.input({shape: [10]});\n     * const output = tf.layers.dense({units: 1}).apply(input);\n     * const model = tf.model({inputs: [input], outputs: [output]});\n     * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n     * const xs = tf.ones([8, 10]);\n     * const ys = tf.zeros([8, 1]);\n     *\n     * const history = await model.fit(xs, ys, {\n     *   epochs: 10,\n     *   callbacks: {\n     *     onEpochEnd: async (epoch, logs) => {\n     *       if (epoch === 2) {\n     *         model.stopTraining = true;\n     *       }\n     *     }\n     *   }\n     * });\n     *\n     * // There should be only 3 values in the loss array, instead of 10\n     * values,\n     * // due to the stopping after 3 epochs.\n     * console.log(history.history.loss);\n     * ```\n     */\n    set stopTraining(stop) {\n        this.stopTraining_ = stop;\n    }\n    get stopTraining() {\n        return this.stopTraining_;\n    }\n    get optimizer() {\n        return this.optimizer_;\n    }\n    set optimizer(optimizer) {\n        if (this.optimizer_ !== optimizer) {\n            this.optimizer_ = optimizer;\n            this.isOptimizerOwned = false;\n        }\n    }\n    dispose() {\n        const result = super.dispose();\n        if (result.refCountAfterDispose === 0 && this.optimizer != null &&\n            this.isOptimizerOwned) {\n            const numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n            this.optimizer_.dispose();\n            result.numDisposedVariables +=\n                numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n        }\n        return result;\n    }\n    getLossIdentifiers() {\n        let lossNames;\n        if (typeof this.loss === 'string') {\n            lossNames = toSnakeCase(this.loss);\n        }\n        else if (Array.isArray(this.loss)) {\n            for (const loss of this.loss) {\n                if (typeof loss !== 'string') {\n                    throw new Error('Serialization of non-string loss is not supported.');\n                }\n            }\n            lossNames = this.loss.map(name => toSnakeCase(name));\n        }\n        else {\n            const outputNames = Object.keys(this.loss);\n            lossNames = {};\n            const losses = this.loss;\n            for (const outputName of outputNames) {\n                if (typeof losses[outputName] === 'string') {\n                    lossNames[outputName] =\n                        toSnakeCase(losses[outputName]);\n                }\n                else {\n                    throw new Error('Serialization of non-string loss is not supported.');\n                }\n            }\n        }\n        return lossNames;\n    }\n    getMetricIdentifiers() {\n        if (typeof this.metrics === 'string' ||\n            typeof this.metrics === 'function') {\n            return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n        }\n        else if (Array.isArray(this.metrics)) {\n            return this.metrics.map(metric => toSnakeCase(Metrics.getLossOrMetricName(metric)));\n        }\n        else {\n            const metricsIdentifiers = {};\n            for (const key in this.metrics) {\n                metricsIdentifiers[key] =\n                    toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n            }\n            return metricsIdentifiers;\n        }\n    }\n    getTrainingConfig() {\n        return {\n            loss: this.getLossIdentifiers(),\n            metrics: this.getMetricIdentifiers(),\n            optimizer_config: {\n                class_name: this.optimizer.getClassName(),\n                config: this.optimizer.getConfig()\n            }\n        };\n        // TODO(cais): Add weight_metrics when they are supported.\n        // TODO(cais): Add sample_weight_mode when it's supported.\n        // TODO(cais): Add loss_weights when it's supported.\n    }\n    loadTrainingConfig(trainingConfig) {\n        if (trainingConfig.weighted_metrics != null) {\n            throw new Error('Loading weight_metrics is not supported yet.');\n        }\n        if (trainingConfig.loss_weights != null) {\n            throw new Error('Loading loss_weights is not supported yet.');\n        }\n        if (trainingConfig.sample_weight_mode != null) {\n            throw new Error('Loading sample_weight_mode is not supported yet.');\n        }\n        const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n        const optimizer = deserialize(tsConfig);\n        let loss;\n        if (typeof trainingConfig.loss === 'string') {\n            loss = toCamelCase(trainingConfig.loss);\n        }\n        else if (Array.isArray(trainingConfig.loss)) {\n            loss = trainingConfig.loss.map(lossEntry => toCamelCase(lossEntry));\n        }\n        else if (trainingConfig.loss != null) {\n            loss = {};\n            for (const key in trainingConfig.loss) {\n                loss[key] = toCamelCase(trainingConfig.loss[key]);\n            }\n        }\n        let metrics;\n        if (Array.isArray(trainingConfig.metrics)) {\n            metrics = trainingConfig.metrics.map(metric => toCamelCase(metric));\n        }\n        else if (trainingConfig.metrics != null) {\n            metrics = {};\n            for (const key in trainingConfig.metrics) {\n                metrics[key] = toCamelCase(trainingConfig.metrics[key]);\n            }\n        }\n        this.compile({ loss, metrics, optimizer });\n    }\n    /**\n     * Save the configuration and/or weights of the LayersModel.\n     *\n     * An `IOHandler` is an object that has a `save` method of the proper\n     * signature defined. The `save` method manages the storing or\n     * transmission of serialized data (\"artifacts\") that represent the\n     * model's topology and weights onto or via a specific medium, such as\n     * file downloads, local storage, IndexedDB in the web browser and HTTP\n     * requests to a server. TensorFlow.js provides `IOHandler`\n     * implementations for a number of frequently used saving mediums, such as\n     * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n     * for more details.\n     *\n     * This method also allows you to refer to certain types of `IOHandler`s\n     * as URL-like string shortcuts, such as 'localstorage://' and\n     * 'indexeddb://'.\n     *\n     * Example 1: Save `model`'s topology and weights to browser [local\n     * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('localstorage://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 2. Saving `model`'s topology and weights to browser\n     * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('indexeddb://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 3. Saving `model`'s topology and weights as two files\n     * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\n     * browser.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('downloads://my-model-1');\n     * ```\n     *\n     * Example 4. Send  `model`'s topology and weights to an HTTP server.\n     * See the documentation of `tf.io.http` for more details\n     * including specifying request parameters and implementation of the\n     * server.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('http://my-server/model/upload');\n     * ```\n     *\n     * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n     * scheme-based string shortcut for `IOHandler`.\n     * @param config Options for saving the model.\n     * @returns A `Promise` of `SaveResult`, which summarizes the result of\n     * the saving, such as byte sizes of the saved artifacts for the model's\n     *   topology and weight values.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n     */\n    async save(handlerOrURL, config) {\n        if (typeof handlerOrURL === 'string') {\n            const handlers = io.getSaveHandlers(handlerOrURL);\n            if (handlers.length === 0) {\n                throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);\n            }\n            else if (handlers.length > 1) {\n                throw new ValueError(`Found more than one (${handlers.length}) save handlers for ` +\n                    `URL '${handlerOrURL}'`);\n            }\n            handlerOrURL = handlers[0];\n        }\n        if (handlerOrURL.save == null) {\n            throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' +\n                'provided does not have the `save` attribute defined.');\n        }\n        const weightDataAndSpecs = await io.encodeWeights(this.getNamedWeights(config));\n        const returnString = false;\n        const unusedArg = null;\n        const modelConfig = this.toJSON(unusedArg, returnString);\n        const modelArtifacts = {\n            modelTopology: modelConfig,\n            format: LAYERS_MODEL_FORMAT_NAME,\n            generatedBy: `TensorFlow.js tfjs-layers v${version}`,\n            convertedBy: null,\n        };\n        const includeOptimizer = config == null ? false : config.includeOptimizer;\n        if (includeOptimizer && this.optimizer != null) {\n            modelArtifacts.trainingConfig = this.getTrainingConfig();\n            const weightType = 'optimizer';\n            const { data: optimizerWeightData, specs: optimizerWeightSpecs } = await io.encodeWeights(await this.optimizer.getWeights(), weightType);\n            weightDataAndSpecs.specs.push(...optimizerWeightSpecs);\n            weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n        }\n        if (this.userDefinedMetadata != null) {\n            // Check serialized size of user-defined metadata.\n            const checkSize = true;\n            checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n            modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n        }\n        modelArtifacts.weightData = weightDataAndSpecs.data;\n        modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n        return handlerOrURL.save(modelArtifacts);\n    }\n    /**\n     * Set user-defined metadata.\n     *\n     * The set metadata will be serialized together with the topology\n     * and weights of the model during `save()` calls.\n     *\n     * @param setUserDefinedMetadata\n     */\n    setUserDefinedMetadata(userDefinedMetadata) {\n        checkUserDefinedMetadata(userDefinedMetadata, this.name);\n        this.userDefinedMetadata = userDefinedMetadata;\n    }\n    /**\n     * Get user-defined metadata.\n     *\n     * The metadata is supplied via one of the two routes:\n     *   1. By calling `setUserDefinedMetadata()`.\n     *   2. Loaded during model loading (if the model is constructed\n     *      via `tf.loadLayersModel()`.)\n     *\n     * If no user-defined metadata is available from either of the\n     * two routes, this function will return `undefined`.\n     */\n    getUserDefinedMetadata() {\n        return this.userDefinedMetadata;\n    }\n}\n// The class name is 'Model' rather than 'LayersModel' for backwards\n// compatibility since this class name shows up in the serialization format.\n/** @nocollapse */\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\n/**\n * A `tf.Functional` is an alias to `tf.LayersModel`.\n *\n * See also:\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class Functional extends LayersModel {\n}\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);\n//# sourceMappingURL=training.js.map"]},"metadata":{},"sourceType":"module"}