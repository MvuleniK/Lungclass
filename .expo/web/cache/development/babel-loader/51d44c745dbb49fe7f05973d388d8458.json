{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from \"../backend/tfjs_backend\";\nimport { configureCallbacks, standardizeCallbacks } from \"../base_callbacks\";\nimport { NotImplementedError, ValueError } from \"../errors\";\nimport { disposeTensorsInLogs } from \"../logs\";\nimport { range } from \"../utils/math_utils\";\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), function () {\n    return \"batchSize is required to be a positive integer, but got \" + batchSize;\n  });\n}\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(function (array) {\n      return sliceAlongFirstAxis(array, start, stop - start);\n    });\n  } else {\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(function () {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(function (array) {\n        return sliceArraysByIndices(array, indices);\n      });\n    } else {\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\nexport function makeBatches(size, batchSize) {\n  var output = [];\n  var batchStart = 0;\n  var batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n\nfunction fitLoop(model, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n  var doValidation, numTrainSamples, indexArray, _configureCallbacks, callbackList, history, _loop, epoch, _ret;\n\n  return _regeneratorRuntime.async(function fitLoop$(_context4) {\n    while (1) {\n      switch (_context4.prev = _context4.next) {\n        case 0:\n          if (batchSize == null) {\n            batchSize = 32;\n          }\n\n          if (epochs == null) {\n            epochs = 1;\n          }\n\n          if (shuffle == null) {\n            shuffle = true;\n          }\n\n          if (initialEpoch == null) {\n            initialEpoch = 0;\n          }\n\n          doValidation = false;\n\n          if (valF != null && valIns != null) {\n            doValidation = true;\n          }\n\n          if (!(validationSteps != null)) {\n            _context4.next = 10;\n            break;\n          }\n\n          doValidation = true;\n\n          if (!(stepsPerEpoch == null)) {\n            _context4.next = 10;\n            break;\n          }\n\n          throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n\n        case 10:\n          numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n\n          if (numTrainSamples != null) {\n            indexArray = range(0, numTrainSamples);\n          }\n\n          if (verbose == null) {\n            verbose = 1;\n          }\n\n          _configureCallbacks = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics), callbackList = _configureCallbacks.callbackList, history = _configureCallbacks.history;\n          callbackList.setModel(model);\n          model.history = history;\n          _context4.next = 18;\n          return _regeneratorRuntime.awrap(callbackList.onTrainBegin());\n\n        case 18:\n          model.stopTraining_ = false;\n\n          _loop = function _loop(epoch) {\n            var epochLogs;\n            return _regeneratorRuntime.async(function _loop$(_context3) {\n              while (1) {\n                switch (_context3.prev = _context3.next) {\n                  case 0:\n                    _context3.next = 2;\n                    return _regeneratorRuntime.awrap(callbackList.onEpochBegin(epoch));\n\n                  case 2:\n                    epochLogs = {};\n\n                    if (!(stepsPerEpoch != null)) {\n                      _context3.next = 7;\n                      break;\n                    }\n\n                    throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n\n                  case 7:\n                    _context3.next = 9;\n                    return _regeneratorRuntime.awrap(function _callee() {\n                      var epochIndexArray1D, batches, _loop2, batchIndex, _ret2;\n\n                      return _regeneratorRuntime.async(function _callee$(_context2) {\n                        while (1) {\n                          switch (_context2.prev = _context2.next) {\n                            case 0:\n                              if (!(shuffle === 'batch')) {\n                                _context2.next = 4;\n                                break;\n                              }\n\n                              throw new NotImplementedError('batch shuffling is not implemneted yet');\n\n                            case 4:\n                              if (shuffle) {\n                                util.shuffle(indexArray);\n                              }\n\n                            case 5:\n                              epochIndexArray1D = tensor1d(indexArray);\n                              batches = makeBatches(numTrainSamples, batchSize);\n\n                              _loop2 = function _loop2(batchIndex) {\n                                var batchLogs;\n                                return _regeneratorRuntime.async(function _loop2$(_context) {\n                                  while (1) {\n                                    switch (_context.prev = _context.next) {\n                                      case 0:\n                                        batchLogs = {};\n                                        _context.next = 3;\n                                        return _regeneratorRuntime.awrap(callbackList.onBatchBegin(batchIndex, batchLogs));\n\n                                      case 3:\n                                        tfc.tidy(function () {\n                                          var batchStart = batches[batchIndex][0];\n                                          var batchEnd = batches[batchIndex][1];\n                                          var batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                                          batchLogs['batch'] = batchIndex;\n                                          batchLogs['size'] = batchEnd - batchStart;\n                                          var insBatch = sliceArraysByIndices(ins, batchIds);\n                                          var outs = f(insBatch);\n\n                                          for (var i = 0; i < outLabels.length; ++i) {\n                                            var label = outLabels[i];\n                                            var out = outs[i];\n                                            batchLogs[label] = out;\n                                            tfc.keep(out);\n                                          }\n\n                                          if (batchIndex === batches.length - 1) {\n                                            if (doValidation) {\n                                              var valOuts = model.testLoop(valF, valIns, batchSize);\n\n                                              for (var _i = 0; _i < outLabels.length; ++_i) {\n                                                var _label = outLabels[_i];\n                                                var _out = valOuts[_i];\n                                                tfc.keep(_out);\n                                                epochLogs['val_' + _label] = _out;\n                                              }\n                                            }\n                                          }\n                                        });\n                                        _context.next = 6;\n                                        return _regeneratorRuntime.awrap(callbackList.onBatchEnd(batchIndex, batchLogs));\n\n                                      case 6:\n                                        disposeTensorsInLogs(batchLogs);\n\n                                        if (!model.stopTraining_) {\n                                          _context.next = 9;\n                                          break;\n                                        }\n\n                                        return _context.abrupt(\"return\", \"break\");\n\n                                      case 9:\n                                      case \"end\":\n                                        return _context.stop();\n                                    }\n                                  }\n                                }, null, null, null, Promise);\n                              };\n\n                              batchIndex = 0;\n\n                            case 9:\n                              if (!(batchIndex < batches.length)) {\n                                _context2.next = 18;\n                                break;\n                              }\n\n                              _context2.next = 12;\n                              return _regeneratorRuntime.awrap(_loop2(batchIndex));\n\n                            case 12:\n                              _ret2 = _context2.sent;\n\n                              if (!(_ret2 === \"break\")) {\n                                _context2.next = 15;\n                                break;\n                              }\n\n                              return _context2.abrupt(\"break\", 18);\n\n                            case 15:\n                              ++batchIndex;\n                              _context2.next = 9;\n                              break;\n\n                            case 18:\n                              epochIndexArray1D.dispose();\n\n                            case 19:\n                            case \"end\":\n                              return _context2.stop();\n                          }\n                        }\n                      }, null, null, null, Promise);\n                    }());\n\n                  case 9:\n                    _context3.next = 11;\n                    return _regeneratorRuntime.awrap(callbackList.onEpochEnd(epoch, epochLogs));\n\n                  case 11:\n                    if (!model.stopTraining_) {\n                      _context3.next = 13;\n                      break;\n                    }\n\n                    return _context3.abrupt(\"return\", \"break\");\n\n                  case 13:\n                  case \"end\":\n                    return _context3.stop();\n                }\n              }\n            }, null, null, null, Promise);\n          };\n\n          epoch = initialEpoch;\n\n        case 21:\n          if (!(epoch < epochs)) {\n            _context4.next = 30;\n            break;\n          }\n\n          _context4.next = 24;\n          return _regeneratorRuntime.awrap(_loop(epoch));\n\n        case 24:\n          _ret = _context4.sent;\n\n          if (!(_ret === \"break\")) {\n            _context4.next = 27;\n            break;\n          }\n\n          return _context4.abrupt(\"break\", 30);\n\n        case 27:\n          ++epoch;\n          _context4.next = 21;\n          break;\n\n        case 30:\n          _context4.next = 32;\n          return _regeneratorRuntime.awrap(callbackList.onTrainEnd());\n\n        case 32:\n          _context4.next = 34;\n          return _regeneratorRuntime.awrap(model.history.syncData());\n\n        case 34:\n          return _context4.abrupt(\"return\", model.history);\n\n        case 35:\n        case \"end\":\n          return _context4.stop();\n      }\n    }\n  }, null, null, null, Promise);\n}\n\nexport function fitTensors(model, x, y) {\n  var args,\n      inputs,\n      targets,\n      inputValX,\n      inputValY,\n      valX,\n      valY,\n      sampleWeights,\n      batchSize,\n      checkBatchAxis,\n      standardizedOuts,\n      _doValidation,\n      valIns,\n      _checkBatchAxis,\n      valStandardized,\n      splitAt,\n      originalBatchSize,\n      ins,\n      trainFunction,\n      outLabels,\n      valFunction,\n      callbackMetrics,\n      callbacks,\n      out,\n      _args5 = arguments;\n\n  return _regeneratorRuntime.async(function fitTensors$(_context5) {\n    while (1) {\n      switch (_context5.prev = _context5.next) {\n        case 0:\n          args = _args5.length > 3 && _args5[3] !== undefined ? _args5[3] : {};\n\n          if (!model.isTraining) {\n            _context5.next = 3;\n            break;\n          }\n\n          throw new Error('Cannot start training because another fit() call is ongoing.');\n\n        case 3:\n          model.isTraining = true;\n          _context5.prev = 4;\n          batchSize = args.batchSize == null ? 32 : args.batchSize;\n          checkBatchSize(batchSize);\n          checkBatchAxis = false;\n          _context5.next = 10;\n          return _regeneratorRuntime.awrap(model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize));\n\n        case 10:\n          standardizedOuts = _context5.sent;\n          inputs = standardizedOuts[0];\n          targets = standardizedOuts[1];\n          sampleWeights = standardizedOuts[2];\n          _doValidation = false;\n\n          if (!(args.validationData != null && args.validationData.length > 0)) {\n            _context5.next = 36;\n            break;\n          }\n\n          _doValidation = true;\n\n          if (!(args.validationData.length === 2)) {\n            _context5.next = 22;\n            break;\n          }\n\n          inputValX = args.validationData[0];\n          inputValY = args.validationData[1];\n          _context5.next = 27;\n          break;\n\n        case 22:\n          if (!(args.validationData.length === 3)) {\n            _context5.next = 26;\n            break;\n          }\n\n          throw new NotImplementedError('validationData including sample weights is not supported yet.');\n\n        case 26:\n          throw new ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" + \"or 3 (valX, valY, valSampleWeight) items; \" + (args.validationData + \" is invalid.\"));\n\n        case 27:\n          _checkBatchAxis = true;\n          _context5.next = 30;\n          return _regeneratorRuntime.awrap(model.standardizeUserData(inputValX, inputValY, null, null, _checkBatchAxis, batchSize));\n\n        case 30:\n          valStandardized = _context5.sent;\n          valX = valStandardized[0];\n          valY = valStandardized[1];\n          valIns = valX.concat(valY);\n          _context5.next = 37;\n          break;\n\n        case 36:\n          if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n            _doValidation = true;\n            splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            valIns = valX.concat(valY);\n          } else if (args.validationSteps != null) {\n            _doValidation = true;\n          }\n\n        case 37:\n          ins = inputs.concat(targets).concat(sampleWeights);\n          model.checkTrainableWeightsConsistency();\n          trainFunction = model.makeTrainFunction();\n          outLabels = model.getDedupedMetricsNames();\n\n          if (_doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics = outLabels.slice().concat(outLabels.map(function (n) {\n              return 'val_' + n;\n            }));\n          } else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n          }\n\n          callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n          _context5.next = 45;\n          return _regeneratorRuntime.awrap(fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null));\n\n        case 45:\n          out = _context5.sent;\n          return _context5.abrupt(\"return\", out);\n\n        case 47:\n          _context5.prev = 47;\n          model.isTraining = false;\n          disposeNewTensors(inputs, x);\n          disposeNewTensors(targets, y);\n          disposeNewTensors(valX, inputValX);\n          disposeNewTensors(valY, inputValY);\n\n          if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n          }\n\n          return _context5.finish(47);\n\n        case 55:\n        case \"end\":\n          return _context5.stop();\n      }\n    }\n  }, null, null, [[4,, 47, 55]], Promise);\n}\nexport function ensureTensorsRank2OrHigher(tensors) {\n  var outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n\n  for (var i = 0; i < tensors.length; ++i) {\n    var tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  var oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(function (t) {\n      return oldTensorIds.push(t.id);\n    });\n  } else if (refTensors != null) {\n    for (var name in refTensors) {\n      var oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  var tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(function (t) {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    for (var _name in tensors) {\n      var tensor = tensors[_name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(function (t) {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"sources":["../../src/engine/training_tensors.ts"],"names":[],"mappings":";;AAAA;;;;;;;;AAQG;AAMH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAgB,MAAhB,EAAkC,QAAlC,EAA4C,IAA5C,QAAuD,uBAAvD;AAEA,SAAQ,UAAR,EAAoB,MAApB,EAA4B,mBAA5B;AACA,SAAsB,kBAAtB,EAA8F,oBAA9F;AACA,SAAQ,mBAAR,EAA6B,UAA7B;AACA,SAAQ,oBAAR;AACA,SAAQ,KAAR;AA4IA,OAAM,SAAU,cAAV,CAAyB,SAAzB,EAA0C;EAC9C,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,SAAS,GAAG,CAAZ,IAAiB,MAAM,CAAC,SAAP,CAAiB,SAAjB,CADrB,EAEI;IAAA,oEACI,SADJ;EAAA,CAFJ;AAID;AAeD,OAAM,SAAU,WAAV,CACF,MADE,EACuB,KADvB,EACsC,IADtC,EACkD;EACtD,IAAI,MAAM,IAAI,IAAd,EAAoB;IAClB,OAAO,CAAC,IAAD,CAAP;EACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IAChC,OAAO,MAAM,CAAC,GAAP,CAAW,UAAA,KAAK;MAAA,OAAI,mBAAmB,CAAC,KAAD,EAAQ,KAAR,EAAe,IAAI,GAAG,KAAtB,CAAvB;IAAA,CAAhB,CAAP;EACD,CAFM,MAEA;IACL,OAAO,mBAAmB,CAAC,MAAD,EAAS,KAAT,EAAgB,IAAI,GAAG,KAAvB,CAA1B;EACD;AACF;AAeD,OAAM,SAAU,oBAAV,CACF,MADE,EACuB,OADvB,EACwC;EAC5C,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;IACnB,IAAI,MAAM,IAAI,IAAd,EAAoB;MAClB,OAAO,IAAP;IACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;MAChC,OAAO,MAAM,CAAC,GAAP,CACH,UAAA,KAAK;QAAA,OAAK,oBAAoB,CAAC,KAAD,EAAQ,OAAR,CAAzB;MAAA,CADF,CAAP;IAED,CAHM,MAGA;MAGL,OAAO,MAAM,CACT,MADS,EACD,OAAO,CAAC,KAAR,KAAkB,OAAlB,GAA4B,OAA5B,GAAsC,OAAO,CAAC,KAAR,EADrC,CAAb;IAED;EACF,CAZM,CAAP;AAaD;AAUD,OAAM,SAAU,WAAV,CACF,IADE,EACY,SADZ,EAC6B;EACjC,IAAM,MAAM,GAA4B,EAAxC;EACA,IAAI,UAAU,GAAG,CAAjB;EACA,IAAI,QAAQ,GAAW,IAAvB;;EACA,OAAO,UAAU,GAAG,IAApB,EAA0B;IACxB,QAAQ,GAAG,UAAU,GAAG,SAAxB;;IACA,IAAI,QAAQ,IAAI,IAAhB,EAAsB;MACpB,QAAQ,GAAG,IAAX;IACD;;IACD,MAAM,CAAC,IAAP,CAAY,CAAC,UAAD,EAAa,QAAb,CAAZ;IACA,UAAU,GAAG,QAAb;EACD;;EACD,OAAO,MAAP;AACD;;AA6BD,SAAe,OAAf,CAGI,KAHJ,EAGgB,CAHhB,EAGiD,GAHjD,EAII,SAJJ,EAI0B,SAJ1B,EAI8C,MAJ9C,EAI+D,OAJ/D,EAKI,SALJ,EAKgC,IALhC,EAMI,MANJ,EAMuB,OANvB,EAMiD,eANjD,EAOI,YAPJ,EAO2B,aAP3B,EAQI,eARJ;EAAA;;EAAA;IAAA;MAAA;QAAA;UASE,IAAI,SAAS,IAAI,IAAjB,EAAuB;YACrB,SAAS,GAAG,EAAZ;UACD;;UACD,IAAI,MAAM,IAAI,IAAd,EAAoB;YAClB,MAAM,GAAG,CAAT;UACD;;UACD,IAAI,OAAO,IAAI,IAAf,EAAqB;YACnB,OAAO,GAAG,IAAV;UACD;;UACD,IAAI,YAAY,IAAI,IAApB,EAA0B;YACxB,YAAY,GAAG,CAAf;UACD;;UAGG,YAvBN,GAuBqB,KAvBrB;;UAwBE,IAAI,IAAI,IAAI,IAAR,IAAgB,MAAM,IAAI,IAA9B,EAAoC;YAClC,YAAY,GAAG,IAAf;UAED;;UA3BH,MA4BM,eAAe,IAAI,IA5BzB;YAAA;YAAA;UAAA;;UA6BI,YAAY,GAAG,IAAf;;UA7BJ,MA8BQ,aAAa,IAAI,IA9BzB;YAAA;YAAA;UAAA;;UAAA,MA+BY,IAAI,UAAJ,CACF,mEACA,oCAFE,CA/BZ;;QAAA;UAqCQ,eArCR,GAsCM,KAAK,CAAC,eAAN,CAAsB,GAAtB,EAA2B,SAA3B,EAAsC,aAAtC,EAAqD,iBAArD,CAtCN;;UAwCE,IAAI,eAAe,IAAI,IAAvB,EAA6B;YAC3B,UAAU,GAAG,KAAK,CAAC,CAAD,EAAI,eAAJ,CAAlB;UACD;;UAED,IAAI,OAAO,IAAI,IAAf,EAAqB;YACnB,OAAO,GAAG,CAAV;UACD;;UA9CH,sBAgDkC,kBAAkB,CAC9C,SAD8C,EACnC,OADmC,EAC1B,MAD0B,EAClB,YADkB,EACJ,eADI,EACa,aADb,EAE9C,SAF8C,EAEnC,YAFmC,EAErB,eAFqB,CAhDpD,EAgDS,YAhDT,uBAgDS,YAhDT,EAgDuB,OAhDvB,uBAgDuB,OAhDvB;UAmDE,YAAY,CAAC,QAAb,CAAsB,KAAtB;UACA,KAAK,CAAC,OAAN,GAAgB,OAAhB;UApDF;UAAA,iCAqDQ,YAAY,CAAC,YAAb,EArDR;;QAAA;UAsDE,KAAK,CAAC,aAAN,GAAsB,KAAtB;;UAtDF,uBA0DW,KA1DX;YAAA;YAAA;cAAA;gBAAA;kBAAA;oBAAA;oBAAA,iCA2DU,YAAY,CAAC,YAAb,CAA0B,KAA1B,CA3DV;;kBAAA;oBA4DU,SA5DV,GA4DsC,EA5DtC;;oBAAA,MA6DQ,aAAa,IAAI,IA7DzB;sBAAA;sBAAA;oBAAA;;oBAAA,MA8DY,IAAI,mBAAJ,CACF,4CADE,CA9DZ;;kBAAA;oBAAA;oBAAA;sBAAA;;sBAAA;wBAAA;0BAAA;4BAAA;8BAAA,MAiEU,OAAO,KAAK,OAjEtB;gCAAA;gCAAA;8BAAA;;8BAAA,MAkEc,IAAI,mBAAJ,CAAwB,wCAAxB,CAlEd;;4BAAA;8BAmEa,IAAI,OAAJ,EAAa;gCAClB,IAAI,CAAC,OAAL,CAAa,UAAb;8BACD;;4BArEP;8BAwEY,iBAxEZ,GAwEgC,QAAQ,CAAC,UAAD,CAxExC;8BA0EY,OA1EZ,GA0EsB,WAAW,CAAC,eAAD,EAAkB,SAAlB,CA1EjC;;8BAAA,yBA2Ee,UA3Ef;gCAAA;gCAAA;kCAAA;oCAAA;sCAAA;wCA4Ec,SA5Ed,GA4E0C,EA5E1C;wCAAA;wCAAA,iCA6Ec,YAAY,CAAC,YAAb,CAA0B,UAA1B,EAAsC,SAAtC,CA7Ed;;sCAAA;wCA+EQ,GAAG,CAAC,IAAJ,CAAS,YAAK;0CACZ,IAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;0CACA,IAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;0CACA,IAAM,QAAQ,GAAG,mBAAmB,CACf,iBADe,EACI,UADJ,EAEf,QAAQ,GAAG,UAFI,CAApC;0CAGA,SAAS,CAAC,OAAD,CAAT,GAAqB,UAArB;0CACA,SAAS,CAAC,MAAD,CAAT,GAAoB,QAAQ,GAAG,UAA/B;0CAIA,IAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAD,EAAM,QAAN,CAArC;0CACA,IAAM,IAAI,GAAG,CAAC,CAAC,QAAD,CAAd;;0CACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;4CACzC,IAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;4CACA,IAAM,GAAG,GAAG,IAAI,CAAC,CAAD,CAAhB;4CACA,SAAS,CAAC,KAAD,CAAT,GAAmB,GAAnB;4CACA,GAAG,CAAC,IAAJ,CAAS,GAAT;0CAED;;0CAED,IAAI,UAAU,KAAK,OAAO,CAAC,MAAR,GAAiB,CAApC,EAAuC;4CACrC,IAAI,YAAJ,EAAkB;8CAChB,IAAM,OAAO,GAAG,KAAK,CAAC,QAAN,CAAe,IAAf,EAAqB,MAArB,EAA6B,SAA7B,CAAhB;;8CAEA,KAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,EAAxC,EAA2C;gDACzC,IAAM,MAAK,GAAG,SAAS,CAAC,EAAD,CAAvB;gDACA,IAAM,IAAG,GAAG,OAAO,CAAC,EAAD,CAAnB;gDACA,GAAG,CAAC,IAAJ,CAAS,IAAT;gDAEA,SAAS,CAAC,SAAS,MAAV,CAAT,GAA4B,IAA5B;8CACD;4CACF;0CACF;wCACF,CAlCD;wCA/ER;wCAAA,iCAmHc,YAAY,CAAC,UAAb,CAAwB,UAAxB,EAAoC,SAApC,CAnHd;;sCAAA;wCAoHQ,oBAAoB,CAAC,SAAD,CAApB;;wCApHR,KAsHY,KAAK,CAAC,aAtHlB;0CAAA;0CAAA;wCAAA;;wCAAA;;sCAAA;sCAAA;wCAAA;oCAAA;kCAAA;gCAAA;8BAAA;;8BA2Ee,UA3Ef,GA2E4B,CA3E5B;;4BAAA;8BAAA,MA2E+B,UAAU,GAAG,OAAO,CAAC,MA3EpD;gCAAA;gCAAA;8BAAA;;8BAAA;8BAAA,wCA2Ee,UA3Ef;;4BAAA;8BAAA;;8BAAA;gCAAA;gCAAA;8BAAA;;8BAAA;;4BAAA;8BA2E4D,EAAE,UA3E9D;8BAAA;8BAAA;;4BAAA;8BA4HM,iBAAiB,CAAC,OAAlB;;4BA5HN;4BAAA;8BAAA;0BAAA;wBAAA;sBAAA;oBAAA;;kBAAA;oBAAA;oBAAA,iCA+HU,YAAY,CAAC,UAAb,CAAwB,KAAxB,EAA+B,SAA/B,CA/HV;;kBAAA;oBAAA,KAgIQ,KAAK,CAAC,aAhId;sBAAA;sBAAA;oBAAA;;oBAAA;;kBAAA;kBAAA;oBAAA;gBAAA;cAAA;YAAA;UAAA;;UA0DW,KA1DX,GA0DmB,YA1DnB;;QAAA;UAAA,MA0DiC,KAAK,GAAG,MA1DzC;YAAA;YAAA;UAAA;;UAAA;UAAA,uCA0DW,KA1DX;;QAAA;UAAA;;UAAA;YAAA;YAAA;UAAA;;UAAA;;QAAA;UA0DiD,EAAE,KA1DnD;UAAA;UAAA;;QAAA;UAAA;UAAA,iCAoIQ,YAAY,CAAC,UAAb,EApIR;;QAAA;UAAA;UAAA,iCAsIQ,KAAK,CAAC,OAAN,CAAc,QAAd,EAtIR;;QAAA;UAAA,kCAuIS,KAAK,CAAC,OAvIf;;QAAA;QAAA;UAAA;MAAA;IAAA;EAAA;AAAA;;AA0IA,OAAO,SAAe,UAAf,CAGH,KAHG,EAGS,CAHT,EAIH,CAJG;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;;EAAA;IAAA;MAAA;QAAA;UAKH,IALG,8DAKkB,EALlB;;UAAA,KAMD,KAAK,CAAC,UANL;YAAA;YAAA;UAAA;;UAAA,MAOG,IAAI,KAAJ,CACF,8DADE,CAPH;;QAAA;UAUL,KAAK,CAAC,UAAN,GAAmB,IAAnB;UAVK;UAmBG,SAnBH,GAmBe,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAnBlD;UAoBH,cAAc,CAAC,SAAD,CAAd;UAIM,cAxBH,GAwBoB,KAxBpB;UAAA;UAAA,iCA0BO,KAAK,CAAC,mBAAN,CACF,CADE,EACC,CADD,EACI,IAAI,CAAC,YADT,EACuB,IAAI,CAAC,WAD5B,EACyC,cADzC,EAEF,SAFE,CA1BP;;QAAA;UAyBG,gBAzBH;UA6BH,MAAM,GAAG,gBAAgB,CAAC,CAAD,CAAzB;UACA,OAAO,GAAG,gBAAgB,CAAC,CAAD,CAA1B;UACA,aAAa,GAAG,gBAAgB,CAAC,CAAD,CAAhC;UAGI,aAlCD,GAkCgB,KAlChB;;UAAA,MAoCC,IAAI,CAAC,cAAL,IAAuB,IAAvB,IAA+B,IAAI,CAAC,cAAL,CAAoB,MAApB,GAA6B,CApC7D;YAAA;YAAA;UAAA;;UAqCD,aAAY,GAAG,IAAf;;UArCC,MAsCG,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CAtClC;YAAA;YAAA;UAAA;;UAwCC,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;UACA,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;UAzCD;UAAA;;QAAA;UAAA,MA0CU,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CA1CzC;YAAA;YAAA;UAAA;;UAAA,MA2CO,IAAI,mBAAJ,CACF,+DADE,CA3CP;;QAAA;UAAA,MA8CO,IAAI,UAAJ,CACF,kHAEG,IAAI,CAAC,cAFR,kBADE,CA9CP;;QAAA;UAoDK,eApDL,GAoDsB,IApDtB;UAAA;UAAA,iCAsDS,KAAK,CAAC,mBAAN,CACF,SADE,EACS,SADT,EACoB,IADpB,EAEF,IAFE,EAGF,eAHE,EAGc,SAHd,CAtDT;;QAAA;UAqDK,eArDL;UA0DD,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;UACA,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;UACA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT;UA5DC;UAAA;;QAAA;UA8DI,IACH,IAAI,CAAC,eAAL,IAAwB,IAAxB,IAAgC,IAAI,CAAC,eAAL,GAAuB,CAAvD,IACA,IAAI,CAAC,eAAL,GAAuB,CAFpB,EAEuB;YAC5B,aAAY,GAAG,IAAf;YAEM,OAHsB,GAIxB,IAAI,CAAC,KAAL,CAAW,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,KAAsB,IAAI,IAAI,CAAC,eAA/B,CAAX,CAJwB;YAKtB,iBALsB,GAKF,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,CALE;YAM5B,IAAI,GAAG,WAAW,CAAC,MAAD,EAAS,OAAT,EAAkB,iBAAlB,CAAlB;YACA,MAAM,GAAG,WAAW,CAAC,MAAD,EAAS,CAAT,EAAY,OAAZ,CAApB;YACA,IAAI,GAAG,WAAW,CAAC,OAAD,EAAU,OAAV,EAAmB,iBAAnB,CAAlB;YACA,OAAO,GAAG,WAAW,CAAC,OAAD,EAAU,CAAV,EAAa,OAAb,CAArB;YAGA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT;UAGD,CAjBM,MAiBA,IAAI,IAAI,CAAC,eAAL,IAAwB,IAA5B,EAAkC;YACvC,aAAY,GAAG,IAAf;UAED;;QAlFE;UAoFG,GApFH,GAoFS,MAAM,CAAC,MAAP,CAAc,OAAd,EAAuB,MAAvB,CAA8B,aAA9B,CApFT;UAsFH,KAAK,CAAC,gCAAN;UAcM,aApGH,GAoGmB,KAAK,CAAC,iBAAN,EApGnB;UAqGG,SArGH,GAqGe,KAAK,CAAC,sBAAN,EArGf;;UAyGH,IAAI,aAAJ,EAAkB;YAChB,KAAK,CAAC,gBAAN;YACA,WAAW,GAAG,KAAK,CAAC,YAApB;YACA,eAAe,GACX,SAAS,CAAC,KAAV,GAAkB,MAAlB,CAAyB,SAAS,CAAC,GAAV,CAAc,UAAA,CAAC;cAAA,OAAI,SAAS,CAAb;YAAA,CAAf,CAAzB,CADJ;UAED,CALD,MAKO;YACL,WAAW,GAAG,IAAd;YACA,MAAM,GAAG,EAAT;YACA,eAAe,GAAG,SAAS,CAAC,KAAV,EAAlB;UACD;;UAEK,SApHH,GAoHe,oBAAoB,CAAC,IAAI,CAAC,SAAN,EAAiB,IAAI,CAAC,UAAtB,CApHnC;UAAA;UAAA,iCAqHe,OAAO,CACrB,KADqB,EACd,aADc,EACC,GADD,EACM,SADN,EACiB,SADjB,EAC4B,IAAI,CAAC,MADjC,EAErB,IAAI,CAAC,OAFgB,EAEP,SAFO,EAEI,WAFJ,EAEiB,MAFjB,EAEyB,IAAI,CAAC,OAF9B,EAGrB,eAHqB,EAGJ,IAAI,CAAC,YAHD,EAGe,IAHf,EAGqB,IAHrB,CArHtB;;QAAA;UAqHG,GArHH;UAAA,kCAyHI,GAzHJ;;QAAA;UAAA;UA2HH,KAAK,CAAC,UAAN,GAAmB,KAAnB;UAEA,iBAAiB,CAAC,MAAD,EAAS,CAAT,CAAjB;UACA,iBAAiB,CAAC,OAAD,EAAU,CAAV,CAAjB;UACA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;UACA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;;UACA,IAAI,aAAa,IAAI,IAArB,EAA2B;YACzB,GAAG,CAAC,OAAJ,CAAY,aAAZ;UACD;;UAnIE;;QAAA;QAAA;UAAA;MAAA;IAAA;EAAA;AAAA;AA8IP,OAAM,SAAU,0BAAV,CAAqC,OAArC,EAA6D;EACjE,IAAM,IAAI,GAAa,EAAvB;;EACA,IAAI,OAAO,YAAY,MAAvB,EAA+B;IAC7B,OAAO,GAAG,CAAC,OAAD,CAAV;EACD;;EAGD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;IACvC,IAAM,MAAM,GAAG,OAAO,CAAC,CAAD,CAAtB;;IACA,IAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;MACrB,IAAI,CAAC,IAAL,CAAU,UAAU,CAAC,MAAD,EAAS,CAAT,CAApB;IACD,CAFD,MAEO,IAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;MAC5B,MAAM,IAAI,KAAJ,CACF,iEACA,WAFE,CAAN;IAGD,CAJM,MAIA;MACL,IAAI,CAAC,IAAL,CAAU,MAAV;IACD;EACF;;EACD,OAAO,IAAP;AACD;AAcD,OAAM,SAAU,iBAAV,CACF,OADE,EAEF,UAFE,EAEuD;EAC3D,IAAI,OAAO,IAAI,IAAf,EAAqB;IACnB;EACD;;EACD,IAAM,YAAY,GAAa,EAA/B;;EACA,IAAI,UAAU,YAAY,MAA1B,EAAkC;IAChC,YAAY,CAAC,IAAb,CAAkB,UAAU,CAAC,EAA7B;EACD,CAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,UAAd,CAAJ,EAA+B;IACpC,UAAU,CAAC,OAAX,CAAmB,UAAA,CAAC;MAAA,OAAI,YAAY,CAAC,IAAb,CAAkB,CAAC,CAAC,EAApB,CAAJ;IAAA,CAApB;EACD,CAFM,MAEA,IAAI,UAAU,IAAI,IAAlB,EAAwB;IAE7B,KAAK,IAAM,IAAX,IAAmB,UAAnB,EAA+B;MAC7B,IAAM,SAAS,GAAG,UAAU,CAAC,IAAD,CAA5B;MACA,YAAY,CAAC,IAAb,CAAkB,SAAS,CAAC,EAA5B;IACD;EACF;;EAED,IAAM,gBAAgB,GAAa,EAAnC;;EACA,IAAI,OAAO,YAAY,MAAvB,EAA+B;IAC7B,IAAI,YAAY,CAAC,OAAb,CAAqB,OAAO,CAAC,EAA7B,MAAqC,CAAC,CAA1C,EAA6C;MAC3C,gBAAgB,CAAC,IAAjB,CAAsB,OAAtB;IACD;EACF,CAJD,MAIO,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,CAAJ,EAA4B;IACjC,OAAO,CAAC,OAAR,CAAgB,UAAA,CAAC,EAAG;MAClB,IAAI,YAAY,CAAC,OAAb,CAAqB,CAAC,CAAC,EAAvB,MAA+B,CAAC,CAApC,EAAuC;QACrC,gBAAgB,CAAC,IAAjB,CAAsB,CAAtB;MACD;IACF,CAJD;EAKD,CANM,MAMA,IAAI,OAAO,IAAI,IAAf,EAAqB;IAE1B,KAAK,IAAM,KAAX,IAAmB,OAAnB,EAA4B;MAC1B,IAAM,MAAM,GAAG,OAAO,CAAC,KAAD,CAAtB;;MACA,IAAI,YAAY,CAAC,OAAb,CAAqB,MAAM,CAAC,EAA5B,MAAoC,CAAC,CAAzC,EAA4C;QAC1C,gBAAgB,CAAC,IAAjB,CAAsB,MAAtB;MACD;IACF;EACF;;EAED,gBAAgB,CAAC,OAAjB,CAAyB,UAAA,CAAC,EAAG;IAC3B,IAAI,CAAC,CAAC,CAAC,UAAP,EAAmB;MACjB,CAAC,CAAC,OAAF;IACD;EACF,CAJD;AAKD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n    }\n    else { // Tensor.\n        return sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(() => {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(array => sliceArraysByIndices(array, indices));\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n    const output = [];\n    let batchStart = 0;\n    let batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n        batchSize = 32;\n    }\n    if (epochs == null) {\n        epochs = 1;\n    }\n    if (shuffle == null) {\n        shuffle = true;\n    }\n    if (initialEpoch == null) {\n        initialEpoch = 0;\n    }\n    // TODO(cais): Change const to let below when implementing validation.\n    let doValidation = false;\n    if (valF != null && valIns != null) {\n        doValidation = true;\n        // TODO(cais): verbose message.\n    }\n    if (validationSteps != null) {\n        doValidation = true;\n        if (stepsPerEpoch == null) {\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                'i.e., `stepsPerEpoch` must be set.');\n        }\n    }\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n    if (numTrainSamples != null) {\n        indexArray = range(0, numTrainSamples);\n    }\n    if (verbose == null) {\n        verbose = 1;\n    }\n    const { callbackList, history } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n        await callbackList.onEpochBegin(epoch);\n        const epochLogs = {};\n        if (stepsPerEpoch != null) {\n            throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n        }\n        else {\n            if (shuffle === 'batch') {\n                throw new NotImplementedError('batch shuffling is not implemneted yet');\n            }\n            else if (shuffle) {\n                util.shuffle(indexArray);\n            }\n            // Convert the potentially shuffled indices to Tensor1D, to avoid the\n            // cost of repeated creation of Array1Ds later on.\n            const epochIndexArray1D = tensor1d(indexArray);\n            const batches = makeBatches(numTrainSamples, batchSize);\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchLogs = {};\n                await callbackList.onBatchBegin(batchIndex, batchLogs);\n                tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = batchEnd - batchStart;\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const outs = f(insBatch);\n                    for (let i = 0; i < outLabels.length; ++i) {\n                        const label = outLabels[i];\n                        const out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                        // TODO(cais): Use scope() to avoid ownership.\n                    }\n                    if (batchIndex === batches.length - 1) { // Last batch.\n                        if (doValidation) {\n                            const valOuts = model.testLoop(valF, valIns, batchSize);\n                            // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                            for (let i = 0; i < outLabels.length; ++i) {\n                                const label = outLabels[i];\n                                const out = valOuts[i];\n                                tfc.keep(out);\n                                // TODO(cais): Use scope() to avoid ownership.\n                                epochLogs['val_' + label] = out;\n                            }\n                        }\n                    }\n                });\n                await callbackList.onBatchEnd(batchIndex, batchLogs);\n                disposeTensorsInLogs(batchLogs);\n                if (model.stopTraining_) {\n                    break;\n                }\n                // TODO(cais): return outs as list of Tensor.\n            }\n            epochIndexArray1D.dispose();\n        }\n        // TODO(cais): Run validation at the end of the epoch.\n        await callbackList.onEpochEnd(epoch, epochLogs);\n        if (model.stopTraining_) {\n            break;\n        }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n    if (model.isTraining) {\n        throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n    try {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // Validate user data.\n        // TODO(cais): Support sampleWeight.\n        const checkBatchAxis = false;\n        const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        sampleWeights = standardizedOuts[2];\n        // Prepare validation data.\n        let doValidation = false;\n        let valIns;\n        if (args.validationData != null && args.validationData.length > 0) {\n            doValidation = true;\n            if (args.validationData.length === 2) {\n                // config.validationData consists of valX and valY.\n                inputValX = args.validationData[0];\n                inputValY = args.validationData[1];\n            }\n            else if (args.validationData.length === 3) {\n                throw new NotImplementedError('validationData including sample weights is not supported yet.');\n            }\n            else {\n                throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` +\n                    `or 3 (valX, valY, valSampleWeight) items; ` +\n                    `${args.validationData} is invalid.`);\n            }\n            const checkBatchAxis = true;\n            const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis, batchSize);\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSplit != null && args.validationSplit > 0 &&\n            args.validationSplit < 1) {\n            doValidation = true;\n            // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            const originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            // TODO(cais): Once sampleWeights becomes available, slice it to get\n            //   valSampleWeights.\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSteps != null) {\n            doValidation = true;\n            // TODO(cais): Add useLearningPhase.\n        }\n        const ins = inputs.concat(targets).concat(sampleWeights);\n        model.checkTrainableWeightsConsistency();\n        // TODO(cais): Handle use_learning_phase and learning_phase?\n        // Porting Note: Here we see a key deviation of tfjs-layers from\n        // Keras.\n        //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n        //  we do not construct symbolic computation graphs to embody the\n        //  training process. Instead, we define a function that performs the\n        //  training action. In PyKeras, the data (inputs and targets) are fed\n        //  through graph placeholders. In tfjs-layers, the data are fed as\n        //  function arguments. Since the function are defined below in the\n        //  scope, we don't have equivalents of PyKeras's\n        //  `_make_train_funciton`.\n        const trainFunction = model.makeTrainFunction();\n        const outLabels = model.getDedupedMetricsNames();\n        let valFunction;\n        let callbackMetrics;\n        if (doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics =\n                outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n        }\n        else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n        }\n        const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n        const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n        return out;\n    }\n    finally {\n        model.isTraining = false;\n        // Memory clean up.\n        disposeNewTensors(inputs, x);\n        disposeNewTensors(targets, y);\n        disposeNewTensors(valX, inputValX);\n        disposeNewTensors(valY, inputValY);\n        if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n        }\n    }\n    // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n    const outs = [];\n    if (tensors instanceof Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (let i = 0; i < tensors.length; ++i) {\n        const tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    const oldTensorIds = [];\n    if (refTensors instanceof Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(t => oldTensorIds.push(t.id));\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in refTensors) {\n            const oldTensor = refTensors[name];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    const tensorsToDispose = [];\n    if (tensors instanceof Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(t => {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in tensors) {\n            const tensor = tensors[name];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(t => {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\n//# sourceMappingURL=training_tensors.js.map"]},"metadata":{},"sourceType":"module"}