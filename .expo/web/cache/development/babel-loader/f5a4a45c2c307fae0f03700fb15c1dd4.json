{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { dispose, mul, tensor1d, tidy } from '@tensorflow/tfjs-core';\n\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n  var numOutputs = outputNames.length;\n\n  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {\n    return outputNames.map(function (name) {\n      return null;\n    });\n  }\n\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [xWeight[outputNames[0]]];\n    } else {\n      return [xWeight];\n    }\n  }\n\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\"Provided \" + weightType + \" is an array of \" + xWeight.length + \" \" + (\"element(s), but the model has \" + numOutputs + \" outputs. \") + \"Make sure a set of weights is provided for each model output.\");\n    }\n\n    return xWeight;\n  } else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === 'object') {\n    var output = [];\n    outputNames.forEach(function (outputName) {\n      if (outputName in xWeight) {\n        output.push(xWeight[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\"The model has multiple (\" + numOutputs + \") outputs, \" + (\"so \" + weightType + \" must be either an array with \") + (numOutputs + \" elements or an object with \" + outputNames + \" keys. \") + (\"Provided \" + weightType + \" not understood: \" + JSON.stringify(xWeight)));\n  }\n}\n\nexport function standardizeClassWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\nexport function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {\n  var yClasses, yClassIndices, classSampleWeight;\n  return _regeneratorRuntime.async(function standardizeWeights$(_context) {\n    while (1) {\n      switch (_context.prev = _context.next) {\n        case 0:\n          if (!(sampleWeight != null || sampleWeightMode != null)) {\n            _context.next = 2;\n            break;\n          }\n\n          throw new Error('Support sampleWeight is not implemented yet');\n\n        case 2:\n          if (!(classWeight != null)) {\n            _context.next = 15;\n            break;\n          }\n\n          yClasses = tidy(function () {\n            if (y.shape.length === 1) {\n              return y.clone();\n            } else if (y.shape.length === 2) {\n              if (y.shape[1] > 1) {\n                var axis = 1;\n                return y.argMax(axis);\n              } else if (y.shape[1] === 1) {\n                return y.reshape([y.shape[0]]);\n              } else {\n                throw new Error(\"Encountered unexpected last-dimension size (\" + y.shape[1] + \") \" + \"during handling of class weights. The size is expected to be \" + \">= 1.\");\n              }\n            } else {\n              throw new Error(\"Unexpected rank of target (y) tensor (\" + y.rank + \") during \" + \"handling of class weights. The rank is expected to be 1 or 2.\");\n            }\n          });\n          _context.t0 = Array;\n          _context.next = 7;\n          return _regeneratorRuntime.awrap(yClasses.data());\n\n        case 7:\n          _context.t1 = _context.sent;\n          yClassIndices = _context.t0.from.call(_context.t0, _context.t1);\n          dispose(yClasses);\n          classSampleWeight = [];\n          yClassIndices.forEach(function (classIndex) {\n            if (classWeight[classIndex] == null) {\n              throw new Error(\"classWeight must contain all classes in the training data. \" + (\"The class \" + classIndex + \" exists in the data but not in \") + \"classWeight\");\n            } else {\n              classSampleWeight.push(classWeight[classIndex]);\n            }\n          });\n          return _context.abrupt(\"return\", tensor1d(classSampleWeight, 'float32'));\n\n        case 15:\n          return _context.abrupt(\"return\", null);\n\n        case 16:\n        case \"end\":\n          return _context.stop();\n      }\n    }\n  }, null, null, null, Promise);\n}\nexport function computeWeightedLoss(losses, sampleWeights) {\n  return mul(losses, sampleWeights);\n}","map":{"version":3,"sources":["../../src/engine/training_utils.ts"],"names":[],"mappings":";;AAAA;;;;;;;;AAQG;AAEH,SAAQ,OAAR,EAAiB,GAAjB,EAAwC,QAAxC,EAAkD,IAAlD,QAA6D,uBAA7D;;AAuBA,SAAS,+BAAT,CACI,OADJ,EACuD,WADvD,EAEI,UAFJ,EAE4C;EAC1C,IAAM,UAAU,GAAG,WAAW,CAAC,MAA/B;;EACA,IAAI,OAAO,IAAI,IAAX,IAAoB,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAArE,EAAyE;IACvE,OAAO,WAAW,CAAC,GAAZ,CAAgB,UAAA,IAAI;MAAA,OAAI,IAAJ;IAAA,CAApB,CAAP;EACD;;EACD,IAAI,UAAU,KAAK,CAAnB,EAAsB;IACpB,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAAjD,EAAoD;MAClD,OAAO,OAAP;IACD,CAFD,MAEO,IAAI,OAAO,OAAP,KAAmB,QAAnB,IAA+B,WAAW,CAAC,CAAD,CAAX,IAAkB,OAArD,EAA8D;MACnE,OAAO,CAAE,OAA0B,CAAC,WAAW,CAAC,CAAD,CAAZ,CAA5B,CAAP;IACD,CAFM,MAEA;MACL,OAAO,CAAC,OAAD,CAAP;IACD;EACF;;EACD,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,CAAJ,EAA4B;IAC1B,IAAI,OAAO,CAAC,MAAR,KAAmB,UAAvB,EAAmC;MACjC,MAAM,IAAI,KAAJ,CACF,cAAY,UAAZ,wBAAyC,OAAO,CAAC,MAAjD,6CACiC,UADjC,kFADE,CAAN;IAID;;IACD,OAAO,OAAP;EACD,CARD,MAQO,IACH,OAAO,OAAP,KAAmB,QAAnB,IAA+B,MAAM,CAAC,IAAP,CAAY,OAAZ,EAAqB,MAArB,GAA8B,CAA7D,IACA,OAAQ,OAA0B,CAAC,MAAM,CAAC,IAAP,CAAY,OAAZ,EAAqB,CAArB,CAAD,CAAlC,KACI,QAHD,EAGW;IAChB,IAAM,MAAM,GAAkB,EAA9B;IACA,WAAW,CAAC,OAAZ,CAAoB,UAAA,UAAU,EAAG;MAC/B,IAAI,UAAU,IAAI,OAAlB,EAA2B;QACzB,MAAM,CAAC,IAAP,CAAa,OAA0B,CAAC,UAAD,CAAvC;MACD,CAFD,MAEO;QACL,MAAM,CAAC,IAAP,CAAY,IAAZ;MACD;IACF,CAND;IAOA,OAAO,MAAP;EACD,CAbM,MAaA;IACL,MAAM,IAAI,KAAJ,CACF,6BAA2B,UAA3B,4BACM,UADN,wCAEG,UAFH,oCAE4C,WAF5C,+BAGY,UAHZ,yBAG0C,IAAI,CAAC,SAAL,CAAe,OAAf,CAH1C,CADE,CAAN;EAKD;AACF;;AAeD,OAAM,SAAU,uBAAV,CACF,WADE,EAEF,WAFE,EAEmB;EACvB,OAAO,+BAA+B,CAClC,WADkC,EACrB,WADqB,EACR,aADQ,CAAtC;AAED;AAED,OAAM,SAAU,wBAAV,CACF,WADE,EAEF,WAFE,EAEmB;EACvB,OAAO,+BAA+B,CAClC,WADkC,EACrB,WADqB,EACR,cADQ,CAAtC;AAED;AAoBD,OAAO,SAAe,kBAAf,CACH,CADG,EACQ,YADR,EAC+B,WAD/B,EAEH,gBAFG;EAAA;EAAA;IAAA;MAAA;QAAA;UAAA,MAGD,YAAY,IAAI,IAAhB,IAAwB,gBAAgB,IAAI,IAH3C;YAAA;YAAA;UAAA;;UAAA,MAMG,IAAI,KAAJ,CAAU,6CAAV,CANH;;QAAA;UAAA,MASD,WAAW,IAAI,IATd;YAAA;YAAA;UAAA;;UAWG,QAXH,GAWwB,IAAI,CAAC,YAAK;YACnC,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAAvB,EAA0B;cAExB,OAAO,CAAC,CAAC,KAAF,EAAP;YACD,CAHD,MAGO,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAAvB,EAA0B;cAC/B,IAAI,CAAC,CAAC,KAAF,CAAQ,CAAR,IAAa,CAAjB,EAAoB;gBAElB,IAAM,IAAI,GAAG,CAAb;gBACA,OAAO,CAAC,CAAC,MAAF,CAAS,IAAT,CAAP;cACD,CAJD,MAIO,IAAI,CAAC,CAAC,KAAF,CAAQ,CAAR,MAAe,CAAnB,EAAsB;gBAE3B,OAAO,CAAC,CAAC,OAAF,CAAU,CAAC,CAAC,CAAC,KAAF,CAAQ,CAAR,CAAD,CAAV,CAAP;cACD,CAHM,MAGA;gBACL,MAAM,IAAI,KAAJ,CACF,iDAA+C,CAAC,CAAC,KAAF,CAAQ,CAAR,CAA/C,mFADE,CAAN;cAID;YACF,CAdM,MAcA;cACL,MAAM,IAAI,KAAJ,CACF,2CAAyC,CAAC,CAAC,IAA3C,gFADE,CAAN;YAGD;UACF,CAvB8B,CAX5B;UAAA,cAoCmB,KApCnB;UAAA;UAAA,iCAoCoC,QAAQ,CAAC,IAAT,EApCpC;;QAAA;UAAA;UAoCG,aApCH,eAoCyB,IApCzB;UAqCH,OAAO,CAAC,QAAD,CAAP;UACM,iBAtCH,GAsCiC,EAtCjC;UAuCH,aAAa,CAAC,OAAd,CAAsB,UAAA,UAAU,EAAG;YACjC,IAAI,WAAW,CAAC,UAAD,CAAX,IAA2B,IAA/B,EAAqC;cACnC,MAAM,IAAI,KAAJ,CACF,gFACa,UADb,qDADE,CAAN;YAID,CALD,MAKO;cACL,iBAAiB,CAAC,IAAlB,CAAuB,WAAW,CAAC,UAAD,CAAlC;YACD;UACF,CATD;UAvCG,iCAkDI,QAAQ,CAAC,iBAAD,EAAoB,SAApB,CAlDZ;;QAAA;UAAA,iCAoDI,IApDJ;;QAAA;QAAA;UAAA;MAAA;IAAA;EAAA;AAAA;AA+DP,OAAM,SAAU,mBAAV,CAA8B,MAA9B,EAA8C,aAA9C,EAAmE;EACvE,OAAO,GAAG,CAAC,MAAD,EAAS,aAAT,CAAV;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { dispose, mul, tensor1d, tidy } from '@tensorflow/tfjs-core';\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n    const numOutputs = outputNames.length;\n    if (xWeight == null || (Array.isArray(xWeight) && xWeight.length === 0)) {\n        return outputNames.map(name => null);\n    }\n    if (numOutputs === 1) {\n        if (Array.isArray(xWeight) && xWeight.length === 1) {\n            return xWeight;\n        }\n        else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n            return [xWeight[outputNames[0]]];\n        }\n        else {\n            return [xWeight];\n        }\n    }\n    if (Array.isArray(xWeight)) {\n        if (xWeight.length !== numOutputs) {\n            throw new Error(`Provided ${weightType} is an array of ${xWeight.length} ` +\n                `element(s), but the model has ${numOutputs} outputs. ` +\n                `Make sure a set of weights is provided for each model output.`);\n        }\n        return xWeight;\n    }\n    else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 &&\n        typeof xWeight[Object.keys(xWeight)[0]] ===\n            'object') {\n        const output = [];\n        outputNames.forEach(outputName => {\n            if (outputName in xWeight) {\n                output.push(xWeight[outputName]);\n            }\n            else {\n                output.push(null);\n            }\n        });\n        return output;\n    }\n    else {\n        throw new Error(`The model has multiple (${numOutputs}) outputs, ` +\n            `so ${weightType} must be either an array with ` +\n            `${numOutputs} elements or an object with ${outputNames} keys. ` +\n            `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n    }\n}\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(classWeight, outputNames) {\n    return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n    return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {\n    if (sampleWeight != null || sampleWeightMode != null) {\n        // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n        // string.\n        throw new Error('Support sampleWeight is not implemented yet');\n    }\n    if (classWeight != null) {\n        // Apply class weights per sample.\n        const yClasses = tidy(() => {\n            if (y.shape.length === 1) {\n                // Assume class indices.\n                return y.clone();\n            }\n            else if (y.shape.length === 2) {\n                if (y.shape[1] > 1) {\n                    // Assume one-hot encoding of classes.\n                    const axis = 1;\n                    return y.argMax(axis);\n                }\n                else if (y.shape[1] === 1) {\n                    // Class index.\n                    return y.reshape([y.shape[0]]);\n                }\n                else {\n                    throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) ` +\n                        `during handling of class weights. The size is expected to be ` +\n                        `>= 1.`);\n                }\n            }\n            else {\n                throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during ` +\n                    `handling of class weights. The rank is expected to be 1 or 2.`);\n            }\n        });\n        const yClassIndices = Array.from(await yClasses.data());\n        dispose(yClasses);\n        const classSampleWeight = [];\n        yClassIndices.forEach(classIndex => {\n            if (classWeight[classIndex] == null) {\n                throw new Error(`classWeight must contain all classes in the training data. ` +\n                    `The class ${classIndex} exists in the data but not in ` +\n                    `classWeight`);\n            }\n            else {\n                classSampleWeight.push(classWeight[classIndex]);\n            }\n        });\n        return tensor1d(classSampleWeight, 'float32');\n    }\n    else {\n        return null;\n    }\n}\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nexport function computeWeightedLoss(losses, sampleWeights) {\n    return mul(losses, sampleWeights);\n}\n//# sourceMappingURL=training_utils.js.map"]},"metadata":{},"sourceType":"module"}