{"ast":null,"code":"import _extends from \"@babel/runtime/helpers/extends\";\nimport _get from \"@babel/runtime/helpers/get\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport _inherits from \"@babel/runtime/helpers/inherits\";\nimport _possibleConstructorReturn from \"@babel/runtime/helpers/possibleConstructorReturn\";\nimport _getPrototypeOf from \"@babel/runtime/helpers/getPrototypeOf\";\n\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport * as K from \"../backend/tfjs_backend\";\nimport { Layer } from \"../engine/topology\";\nimport { NotImplementedError, ValueError } from \"../errors\";\nimport { l2Normalize } from \"../losses\";\nimport * as generic_utils from \"../utils/generic_utils\";\nimport * as mathUtils from \"../utils/math_utils\";\nimport { getExactlyOneShape } from \"../utils/types_utils\";\nexport var Merge = function (_Layer) {\n  _inherits(Merge, _Layer);\n\n  var _super = _createSuper(Merge);\n\n  function Merge(args) {\n    var _this;\n\n    _classCallCheck(this, Merge);\n\n    _this = _super.call(this, args || {});\n    _this.supportsMasking = true;\n    return _this;\n  }\n\n  _createClass(Merge, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      throw new NotImplementedError();\n    }\n  }, {\n    key: \"computeElementwiseOpOutputShape\",\n    value: function computeElementwiseOpOutputShape(shape1, shape2) {\n      if (shape1 == null || shape2 == null) {\n        return null;\n      } else if (shape1.length < shape2.length) {\n        return this.computeElementwiseOpOutputShape(shape2, shape1);\n      } else if (shape2.length === 0) {\n        return shape1;\n      }\n\n      var outputShape = shape1.slice(0, shape1.length - shape2.length);\n\n      for (var k = 0; k < shape2.length; ++k) {\n        var i = shape1[shape1.length - shape2.length + k];\n        var j = shape2[k];\n\n        if (i == null || j == null || i < 0 || j < 0) {\n          outputShape.push(null);\n        } else if (i === 1) {\n          outputShape.push(j);\n        } else if (j === 1) {\n          outputShape.push(i);\n        } else {\n          if (i !== j) {\n            throw new ValueError('Operands could not be broadcast together with shapes ' + JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n          }\n\n          outputShape.push(i);\n        }\n      }\n\n      return outputShape;\n    }\n  }, {\n    key: \"build\",\n    value: function build(inputShape) {\n      if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n        inputShape = [getExactlyOneShape(inputShape)];\n      }\n\n      inputShape = inputShape;\n\n      if (inputShape.length < 2) {\n        throw new ValueError('A merge layer should be called on an Array of at least 2 inputs.' + (\" Got \" + inputShape.length + \" input(s).\"));\n      }\n\n      var batchSizes = [];\n\n      for (var _iterator = _createForOfIteratorHelperLoose(inputShape), _step; !(_step = _iterator()).done;) {\n        var shape = _step.value;\n\n        if (shape != null && shape[0] !== null) {\n          batchSizes.push(shape[0]);\n        }\n      }\n\n      batchSizes = generic_utils.unique(batchSizes);\n\n      if (batchSizes.length > 1) {\n        throw new ValueError(\"Can not merge tensors with different batch sizes. \" + (\"Got tensors with shapes: \" + JSON.stringify(inputShape) + \".\"));\n      }\n\n      var outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);\n\n      for (var i = 1; i < inputShape.length; ++i) {\n        var _shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n\n        outputShape = this.computeElementwiseOpOutputShape(outputShape, _shape);\n      }\n\n      var allRanks = inputShape.map(function (shape) {\n        return shape.length;\n      });\n\n      if (inputShape.indexOf(null) === -1 && generic_utils.unique(allRanks).length === 1) {\n        this.reshapeRequired = false;\n      } else {\n        this.reshapeRequired = true;\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n\n      return tidy(function () {\n        inputs = inputs;\n\n        if (_this2.reshapeRequired) {\n          var reshapedInputs = [];\n          var inputDims = inputs.map(function (input) {\n            return input.rank;\n          });\n\n          if (inputDims.indexOf(null) === -1) {\n            var maxNDim = mathUtils.max(inputDims);\n\n            for (var _iterator2 = _createForOfIteratorHelperLoose(inputs), _step2; !(_step2 = _iterator2()).done;) {\n              var x = _step2.value;\n              var xNDim = x.rank;\n\n              for (var k = 0; k < maxNDim - xNDim; ++k) {\n                x = K.expandDims(x, 1);\n              }\n\n              reshapedInputs.push(x);\n            }\n\n            return _this2.mergeFunction(reshapedInputs);\n          } else {\n            var transposed = false;\n\n            for (var _iterator3 = _createForOfIteratorHelperLoose(inputs), _step3; !(_step3 = _iterator3()).done;) {\n              var _x = _step3.value;\n              var _xNDim = _x.rank;\n\n              if (_xNDim == null) {\n                var xShape = _x.shape;\n                var _batchSize = xShape[0];\n\n                var _newShape = xShape.slice(1).concat([_batchSize]);\n\n                var xTransposed = _x.reshape([_batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n\n                xTransposed = tfc.transpose(xTransposed, [1, 0]);\n                xTransposed = xTransposed.reshape(_newShape);\n                reshapedInputs.push(xTransposed);\n                transposed = true;\n              } else if (_xNDim > 1) {\n                var _dims = mathUtils.range(1, _xNDim).concat([0]);\n\n                reshapedInputs.push(tfc.transpose(_x, _dims));\n                transposed = true;\n              } else {\n                reshapedInputs.push(_x);\n              }\n            }\n\n            var y = _this2.mergeFunction(reshapedInputs);\n\n            var yNDim = y.rank;\n\n            if (transposed) {\n              if (yNDim == null) {\n                var yShape = y.shape;\n                var _yNDim = yShape.length;\n                var batchSize = yShape[_yNDim - 1];\n                var newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));\n                y = tfc.transpose(y.reshape([-1, batchSize]), [1, 0]).reshape(newShape);\n              } else if (yNDim > 1) {\n                var dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n                y = tfc.transpose(y, dims);\n              }\n            }\n\n            return y;\n          }\n        } else {\n          return _this2.mergeFunction(inputs);\n        }\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = inputShape;\n      var outputShape;\n\n      if (inputShape[0] == null) {\n        outputShape = null;\n      } else {\n        outputShape = inputShape[0].slice(1);\n      }\n\n      for (var i = 1; i < inputShape.length; ++i) {\n        var shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n        outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n      }\n\n      var batchSizes = [];\n\n      for (var _iterator4 = _createForOfIteratorHelperLoose(inputShape), _step4; !(_step4 = _iterator4()).done;) {\n        var _shape2 = _step4.value;\n\n        if (_shape2 != null && _shape2[0] !== null) {\n          batchSizes.push(_shape2[0]);\n        }\n      }\n\n      batchSizes = generic_utils.unique(batchSizes);\n\n      if (batchSizes.length === 1) {\n        outputShape = batchSizes.concat(outputShape);\n      } else {\n        outputShape = [null].concat(outputShape);\n      }\n\n      return outputShape;\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      return tfc.tidy(function () {\n        if (mask == null) {\n          return null;\n        }\n\n        if (!Array.isArray(mask)) {\n          throw new ValueError('`mask` should be an Array');\n        }\n\n        if (!Array.isArray(inputs)) {\n          throw new ValueError('`inputs` should be an Array');\n        }\n\n        if (mask.length !== inputs.length) {\n          throw new ValueError(\"The Array 'inputs' and 'mask' are expected to have the same \" + \"length, but have different lengths \" + (\"(\" + inputs.length + \" vs \" + mask.length + \")\"));\n        }\n\n        if (mask.every(function (m) {\n          return m == null;\n        })) {\n          return null;\n        }\n\n        mask = mask.map(function (m) {\n          return m == null ? m : tfc.expandDims(m, 0);\n        });\n        var output = mask[0];\n\n        for (var i = 1; i < mask.length - 1; ++i) {\n          output = tfc.logicalAnd(output, mask[i]);\n        }\n\n        return output;\n      });\n    }\n  }]);\n\n  return Merge;\n}(Layer);\nexport var Add = function (_Merge) {\n  _inherits(Add, _Merge);\n\n  var _super2 = _createSuper(Add);\n\n  function Add(args) {\n    _classCallCheck(this, Add);\n\n    return _super2.call(this, args);\n  }\n\n  _createClass(Add, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      return tidy(function () {\n        var output = inputs[0].clone();\n\n        for (var i = 1; i < inputs.length; ++i) {\n          output = tfc.add(output, inputs[i]);\n        }\n\n        return output;\n      });\n    }\n  }]);\n\n  return Add;\n}(Merge);\nAdd.className = 'Add';\nserialization.registerClass(Add);\nexport function add(config) {\n  if (Array.isArray(config)) {\n    var layer = new Add({});\n    return layer.apply(config);\n  } else {\n    return new Add(config);\n  }\n}\nexport var Multiply = function (_Merge2) {\n  _inherits(Multiply, _Merge2);\n\n  var _super3 = _createSuper(Multiply);\n\n  function Multiply(args) {\n    _classCallCheck(this, Multiply);\n\n    return _super3.call(this, args);\n  }\n\n  _createClass(Multiply, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      return tidy(function () {\n        var output = inputs[0].clone();\n\n        for (var i = 1; i < inputs.length; ++i) {\n          output = tfc.mul(output, inputs[i]);\n        }\n\n        return output;\n      });\n    }\n  }]);\n\n  return Multiply;\n}(Merge);\nMultiply.className = 'Multiply';\nserialization.registerClass(Multiply);\nexport function multiply(config) {\n  if (Array.isArray(config)) {\n    var layer = new Multiply({});\n    return layer.apply(config);\n  } else {\n    return new Multiply(config);\n  }\n}\nexport var Average = function (_Merge3) {\n  _inherits(Average, _Merge3);\n\n  var _super4 = _createSuper(Average);\n\n  function Average(args) {\n    _classCallCheck(this, Average);\n\n    return _super4.call(this, args);\n  }\n\n  _createClass(Average, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      return tidy(function () {\n        var output = inputs[0].clone();\n\n        for (var i = 1; i < inputs.length; ++i) {\n          output = tfc.add(output, inputs[i]);\n        }\n\n        return tfc.mul(1 / inputs.length, output);\n      });\n    }\n  }]);\n\n  return Average;\n}(Merge);\nAverage.className = 'Average';\nserialization.registerClass(Average);\nexport function average(config) {\n  if (Array.isArray(config)) {\n    var layer = new Average({});\n    return layer.apply(config);\n  } else {\n    return new Average(config);\n  }\n}\nexport var Maximum = function (_Merge4) {\n  _inherits(Maximum, _Merge4);\n\n  var _super5 = _createSuper(Maximum);\n\n  function Maximum(args) {\n    _classCallCheck(this, Maximum);\n\n    return _super5.call(this, args);\n  }\n\n  _createClass(Maximum, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      return tidy(function () {\n        var output = inputs[0];\n\n        for (var i = 1; i < inputs.length; ++i) {\n          output = tfc.maximum(output, inputs[i]);\n        }\n\n        return output;\n      });\n    }\n  }]);\n\n  return Maximum;\n}(Merge);\nMaximum.className = 'Maximum';\nserialization.registerClass(Maximum);\nexport function maximum(config) {\n  if (Array.isArray(config)) {\n    var layer = new Maximum({});\n    return layer.apply(config);\n  } else {\n    return new Maximum(config);\n  }\n}\nexport var Minimum = function (_Merge5) {\n  _inherits(Minimum, _Merge5);\n\n  var _super6 = _createSuper(Minimum);\n\n  function Minimum(args) {\n    _classCallCheck(this, Minimum);\n\n    return _super6.call(this, args);\n  }\n\n  _createClass(Minimum, [{\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      return tidy(function () {\n        var output = inputs[0];\n\n        for (var i = 1; i < inputs.length; ++i) {\n          output = tfc.minimum(output, inputs[i]);\n        }\n\n        return output;\n      });\n    }\n  }]);\n\n  return Minimum;\n}(Merge);\nMinimum.className = 'Minimum';\nserialization.registerClass(Minimum);\nexport function minimum(config) {\n  if (Array.isArray(config)) {\n    var layer = new Minimum({});\n    return layer.apply(config);\n  } else {\n    return new Minimum(config);\n  }\n}\nexport var Concatenate = function (_Merge6) {\n  _inherits(Concatenate, _Merge6);\n\n  var _super7 = _createSuper(Concatenate);\n\n  function Concatenate(args) {\n    var _this3;\n\n    _classCallCheck(this, Concatenate);\n\n    _this3 = _super7.call(this, args);\n    _this3.DEFAULT_AXIS = -1;\n\n    if (args == null) {\n      args = {};\n    }\n\n    _this3.axis = args.axis == null ? _this3.DEFAULT_AXIS : args.axis;\n    _this3.supportsMasking = true;\n    _this3.reshapeRequired = false;\n    return _this3;\n  }\n\n  _createClass(Concatenate, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {\n        throw new ValueError('A `Concatenate` layer should be called on a list of at least 2 ' + 'inputs');\n      }\n\n      inputShape = inputShape;\n      var allNoneShape = true;\n\n      for (var _iterator5 = _createForOfIteratorHelperLoose(inputShape), _step5; !(_step5 = _iterator5()).done;) {\n        var shape = _step5.value;\n\n        if (shape != null) {\n          allNoneShape = false;\n          break;\n        }\n      }\n\n      if (allNoneShape) {\n        return;\n      }\n\n      var shapeSet = [];\n\n      for (var i = 0; i < inputShape.length; ++i) {\n        var shapeWithoutConcatAxis = inputShape[i].slice();\n        shapeWithoutConcatAxis.splice(this.axis, 1);\n        var exists = false;\n\n        for (var _iterator6 = _createForOfIteratorHelperLoose(shapeSet), _step6; !(_step6 = _iterator6()).done;) {\n          var _shape3 = _step6.value;\n\n          if (util.arraysEqual(_shape3, shapeWithoutConcatAxis)) {\n            exists = true;\n            break;\n          }\n        }\n\n        if (!exists) {\n          shapeSet.push(shapeWithoutConcatAxis);\n        }\n      }\n\n      if (shapeSet.length > 1) {\n        throw new ValueError('A `Concatenate` layer requires inputs with matching shapes ' + 'except for the concat axis. Got input shapes: ' + JSON.stringify(inputShape));\n      }\n    }\n  }, {\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      var _this4 = this;\n\n      return tidy(function () {\n        return K.concatenate(inputs, _this4.axis);\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n        throw new ValueError('A `Concatenate` layer should be called on a list of inputs.');\n      }\n\n      var inputShapes = inputShape;\n      var outputShape = inputShapes[0].slice();\n      var axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;\n\n      for (var _iterator7 = _createForOfIteratorHelperLoose(inputShapes.slice(1)), _step7; !(_step7 = _iterator7()).done;) {\n        var shape = _step7.value;\n\n        if (outputShape[axis] == null || shape[axis] == null) {\n          outputShape[axis] = null;\n          break;\n        }\n\n        outputShape[axis] += shape[axis];\n      }\n\n      return outputShape;\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      var _this5 = this;\n\n      if (mask == null) {\n        return null;\n      }\n\n      if (!Array.isArray(mask)) {\n        throw new ValueError('`mask` should be an array for Concatenate');\n      }\n\n      if (!Array.isArray(inputs)) {\n        throw new ValueError('`inputs` should be an array for Concatenate');\n      }\n\n      if (mask.length !== inputs.length) {\n        throw new ValueError(\"Mismatch in the length of mask (\" + mask.length + \") \" + (\"and the legnth of inputs (\" + inputs.length + \")\"));\n      }\n\n      return tfc.tidy(function () {\n        var allNullMasks = true;\n        mask.forEach(function (m) {\n          if (m != null) {\n            allNullMasks = false;\n            return;\n          }\n        });\n\n        if (allNullMasks) {\n          return null;\n        }\n\n        var outputMasks = [];\n\n        for (var i = 0; i < inputs.length; ++i) {\n          if (mask[i] == null) {\n            outputMasks.push(tfc.onesLike(inputs[i]).asType('bool'));\n          } else if (mask[i].rank < inputs[i].rank) {\n            outputMasks.push(tfc.expandDims(mask[i], -1));\n          } else {\n            outputMasks.push(mask[i]);\n          }\n        }\n\n        var concatenatedMasks = tfc.concat(outputMasks, _this5.axis);\n        return tfc.all(concatenatedMasks, -1, false);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        'axis': this.axis\n      };\n\n      var baseConfig = _get(_getPrototypeOf(Concatenate.prototype), \"getConfig\", this).call(this);\n\n      _extends(config, baseConfig);\n\n      return config;\n    }\n  }]);\n\n  return Concatenate;\n}(Merge);\nConcatenate.className = 'Concatenate';\nserialization.registerClass(Concatenate);\nexport function concatenate(config) {\n  if (Array.isArray(config)) {\n    var layer = new Concatenate({});\n    return layer.apply(config);\n  } else {\n    return new Concatenate(config);\n  }\n}\n\nfunction interpretAxis(axis, dim) {\n  while (axis < 0) {\n    axis += dim;\n  }\n\n  return axis;\n}\n\nfunction batchDot(x, y, axes) {\n  if (x.shape.length > 3 || y.shape.length > 3) {\n    throw new NotImplementedError('batchDot is not implemented for tensors of 4D or higher rank yet');\n  }\n\n  tfc.util.assert(x.shape.length >= 2, function () {\n    return \"batchDot requires the rank of x to be >= 2, \" + (\"but got \" + x.shape.length);\n  });\n  tfc.util.assert(x.shape.length >= 2, function () {\n    return \"batchDot requires the rank of y to be >= 2, \" + (\"but got \" + y.shape.length);\n  });\n\n  if (typeof axes === 'number') {\n    axes = [axes, axes];\n  }\n\n  if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n    throw new NotImplementedError('batchDot is not implemented for complex64-type Tensors yet.');\n  }\n\n  var xNDim = x.shape.length;\n  var yNDim = y.shape.length;\n\n  if (axes == null) {\n    axes = [xNDim - 1, yNDim - 2];\n  }\n\n  var axesArray = axes;\n  return tfc.tidy(function () {\n    var diff;\n\n    if (xNDim > yNDim) {\n      diff = xNDim - yNDim;\n      var diffShape = [];\n\n      for (var i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n\n      y = y.reshape(y.shape.concat(diffShape));\n    } else if (yNDim > xNDim) {\n      diff = yNDim - xNDim;\n      var _diffShape = [];\n\n      for (var _i = 0; _i < diff; ++_i) {\n        _diffShape.push(1);\n      }\n\n      x = x.reshape(x.shape.concat(_diffShape));\n    } else {\n      diff = 0;\n    }\n\n    var out;\n\n    if (x.shape.length === 2 && y.shape.length === 2) {\n      if (axesArray[0] === axesArray[1]) {\n        out = x.mul(y).sum(axesArray[0]);\n      } else {\n        out = x.transpose([1, 0]).mul(y).sum(axesArray[1]);\n      }\n    } else {\n      var adjX = axesArray[0] !== x.shape.length - 1;\n      var adjY = axesArray[1] === y.shape.length - 1;\n      out = x.matMul(y, adjX, adjY);\n    }\n\n    if (diff > 0) {\n      var idx;\n\n      if (xNDim > yNDim) {\n        idx = xNDim + yNDim - 3;\n      } else {\n        idx = xNDim - 1;\n      }\n\n      var squeezeAxes = [];\n\n      for (var _i2 = idx; _i2 < idx + diff; ++_i2) {\n        squeezeAxes.push(_i2);\n      }\n\n      out = out.squeeze(squeezeAxes);\n    }\n\n    if (out.shape.length === 1) {\n      out = out.expandDims(1);\n    }\n\n    return out;\n  });\n}\n\nexport var Dot = function (_Merge7) {\n  _inherits(Dot, _Merge7);\n\n  var _super8 = _createSuper(Dot);\n\n  function Dot(args) {\n    var _this6;\n\n    _classCallCheck(this, Dot);\n\n    _this6 = _super8.call(this, args);\n    _this6.axes = args.axes;\n    _this6.normalize = args.normalize == null ? false : args.normalize;\n    _this6.supportsMasking = true;\n    _this6.reshapeRequired = false;\n    return _this6;\n  }\n\n  _createClass(Dot, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), function () {\n        return 'A `Dot` layer should be called on a list of exactly 2 inputs.';\n      });\n      var shape1 = inputShape[0];\n      var shape2 = inputShape[1];\n\n      if (shape1.length > 3 || shape2.length > 3) {\n        throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n      }\n\n      var axes = this.interpretAxes(shape1, shape2);\n\n      if (shape1[axes[0]] !== shape2[axes[1]]) {\n        throw new ValueError(\"Dimension incompatibility: \" + (shape1[axes[0]] + \" !== \" + shape2[axes[1]]));\n      }\n    }\n  }, {\n    key: \"mergeFunction\",\n    value: function mergeFunction(inputs) {\n      if (inputs.length !== 2) {\n        throw new ValueError('A `Dot` layer must be called on exactly 2 inputs, ' + (\"but received \" + inputs.length + \" input(s).\"));\n      }\n\n      var x1 = inputs[0];\n      var x2 = inputs[1];\n      var axes;\n\n      if (!Array.isArray(this.axes)) {\n        axes = [interpretAxis(this.axes, x1.shape.length), interpretAxis(this.axes, x2.shape.length)];\n      } else {\n        axes = this.axes.map(function (axis, i) {\n          return interpretAxis(axis, inputs[i].shape.length);\n        });\n      }\n\n      if (this.normalize) {\n        x1 = l2Normalize(x1, axes[0]);\n        x2 = l2Normalize(x2, axes[1]);\n      }\n\n      return batchDot(x1, x2, axes);\n    }\n  }, {\n    key: \"interpretAxes\",\n    value: function interpretAxes(shape1, shape2) {\n      var axes;\n\n      if (!Array.isArray(this.axes)) {\n        axes = [interpretAxis(this.axes, shape1.length), interpretAxis(this.axes, shape2.length)];\n      } else {\n        axes = this.axes;\n      }\n\n      return axes;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), function () {\n        return 'A `Dot` layer should be called on a list of exactly 2 inputs.';\n      });\n      var shape1 = inputShape[0].slice();\n      var shape2 = inputShape[1].slice();\n\n      if (shape1.length > 3 || shape2.length > 3) {\n        throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n      }\n\n      var axes = this.interpretAxes(shape1, shape2);\n      shape1.splice(axes[0], 1);\n      shape2.splice(axes[1], 1);\n      shape2.splice(0, 1);\n      var outputShape = shape1.concat(shape2);\n\n      if (outputShape.length === 1) {\n        outputShape.push(1);\n      }\n\n      return outputShape;\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      return null;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        'axes': this.axes,\n        'normalize': this.normalize\n      };\n\n      var baseConfig = _get(_getPrototypeOf(Dot.prototype), \"getConfig\", this).call(this);\n\n      _extends(config, baseConfig);\n\n      return config;\n    }\n  }]);\n\n  return Dot;\n}(Merge);\nDot.className = 'Dot';\nserialization.registerClass(Dot);","map":{"version":3,"sources":["../../src/layers/merge.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAAA;;;;;;;;AAQG;AAMH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAQ,aAAR,EAA+B,IAA/B,EAAqC,IAArC,QAAgD,uBAAhD;AACA,OAAO,KAAK,CAAZ;AACA,SAAQ,KAAR;AACA,SAAQ,mBAAR,EAA6B,UAA7B;AAEA,SAAQ,WAAR;AAEA,OAAO,KAAK,aAAZ;AACA,OAAO,KAAK,SAAZ;AACA,SAAQ,kBAAR;AAOA,WAAsB,KAAtB;EAAA;;EAAA;;EAGE,eAAY,IAAZ,EAA4B;IAAA;;IAAA;;IAC1B,0BAAM,IAAI,IAAI,EAAd;IACA,MAAK,eAAL,GAAuB,IAAvB;IAF0B;EAG3B;;EANH;IAAA;IAAA,OAYY,uBAAc,MAAd,EAA8B;MACtC,MAAM,IAAI,mBAAJ,EAAN;IACD;EAdH;IAAA;IAAA,OA0BU,yCAAgC,MAAhC,EAA+C,MAA/C,EAA4D;MAClE,IAAI,MAAM,IAAI,IAAV,IAAkB,MAAM,IAAI,IAAhC,EAAsC;QACpC,OAAO,IAAP;MACD,CAFD,MAEO,IAAI,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAA3B,EAAmC;QACxC,OAAO,KAAK,+BAAL,CAAqC,MAArC,EAA6C,MAA7C,CAAP;MACD,CAFM,MAEA,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;QAC9B,OAAO,MAAP;MACD;;MACD,IAAM,WAAW,GAAU,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAAvC,CAA3B;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,IAAM,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAAvB,GAAgC,CAAjC,CAAhB;QACA,IAAM,CAAC,GAAG,MAAM,CAAC,CAAD,CAAhB;;QACA,IAAI,CAAC,IAAI,IAAL,IAAa,CAAC,IAAI,IAAlB,IAA0B,CAAC,GAAG,CAA9B,IAAmC,CAAC,GAAG,CAA3C,EAA8C;UAC5C,WAAW,CAAC,IAAZ,CAAiB,IAAjB;QACD,CAFD,MAEO,IAAI,CAAC,KAAK,CAAV,EAAa;UAClB,WAAW,CAAC,IAAZ,CAAiB,CAAjB;QACD,CAFM,MAEA,IAAI,CAAC,KAAK,CAAV,EAAa;UAClB,WAAW,CAAC,IAAZ,CAAiB,CAAjB;QACD,CAFM,MAEA;UACL,IAAI,CAAC,KAAK,CAAV,EAAa;YACX,MAAM,IAAI,UAAJ,CACF,0DACA,IAAI,CAAC,SAAL,CAAe,MAAf,CADA,GACyB,GADzB,GAC+B,IAAI,CAAC,SAAL,CAAe,MAAf,CAF7B,CAAN;UAGD;;UACD,WAAW,CAAC,IAAZ,CAAiB,CAAjB;QACD;MACF;;MACD,OAAO,WAAP;IACD;EAtDH;IAAA;IAAA,OAwDE,eAAM,UAAN,EAA+B;MAE7B,IAAI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,CAAC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAAlC,EAAgE;QAE9D,UAAU,GAAG,CAAC,kBAAkB,CAAC,UAAD,CAAnB,CAAb;MACD;;MACD,UAAU,GAAG,UAAb;;MACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;QACzB,MAAM,IAAI,UAAJ,CACF,gFACQ,UAAU,CAAC,MADnB,gBADE,CAAN;MAGD;;MAID,IAAI,UAAU,GAAa,EAA3B;;MACA,qDAAoB,UAApB,wCAAgC;QAAA,IAArB,KAAqB;;QAC9B,IAAI,KAAK,IAAI,IAAT,IAAiB,KAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;UACtC,UAAU,CAAC,IAAX,CAAgB,KAAK,CAAC,CAAD,CAArB;QACD;MACF;;MACD,UAAU,GAAG,aAAa,CAAC,MAAd,CAAqB,UAArB,CAAb;;MACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;QACzB,MAAM,IAAI,UAAJ,CACF,sFAC4B,IAAI,CAAC,SAAL,CAAe,UAAf,CAD5B,OADE,CAAN;MAGD;;MAED,IAAI,WAAW,GACX,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CADnC;;MAEA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;QAC1C,IAAM,MAAK,GAAG,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAA7C;;QACA,WAAW,GAAG,KAAK,+BAAL,CAAqC,WAArC,EAAkD,MAAlD,CAAd;MACD;;MAGD,IAAM,QAAQ,GAAG,UAAU,CAAC,GAAX,CAAe,UAAA,KAAK;QAAA,OAAI,KAAK,CAAC,MAAV;MAAA,CAApB,CAAjB;;MACA,IAAI,UAAU,CAAC,OAAX,CAAmB,IAAnB,MAA6B,CAAC,CAA9B,IACA,aAAa,CAAC,MAAd,CAAqB,QAArB,EAA+B,MAA/B,KAA0C,CAD9C,EACiD;QAC/C,KAAK,eAAL,GAAuB,KAAvB;MACD,CAHD,MAGO;QACL,KAAK,eAAL,GAAuB,IAAvB;MACD;IACF;EAnGH;IAAA;IAAA,OAqGE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,MAAM,GAAG,MAAT;;QACA,IAAI,MAAI,CAAC,eAAT,EAA0B;UACxB,IAAM,cAAc,GAAa,EAAjC;UACA,IAAM,SAAS,GAAG,MAAM,CAAC,GAAP,CAAW,UAAA,KAAK;YAAA,OAAI,KAAK,CAAC,IAAV;UAAA,CAAhB,CAAlB;;UACA,IAAI,SAAS,CAAC,OAAV,CAAkB,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;YAGlC,IAAM,OAAO,GAAG,SAAS,CAAC,GAAV,CAAc,SAAd,CAAhB;;YACA,sDAAc,MAAd,2CAAsB;cAAA,IAAb,CAAa;cACpB,IAAM,KAAK,GAAG,CAAC,CAAC,IAAhB;;cACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,GAAG,KAA9B,EAAqC,EAAE,CAAvC,EAA0C;gBACxC,CAAC,GAAG,CAAC,CAAC,UAAF,CAAa,CAAb,EAAgB,CAAhB,CAAJ;cACD;;cACD,cAAc,CAAC,IAAf,CAAoB,CAApB;YACD;;YACD,OAAO,MAAI,CAAC,aAAL,CAAmB,cAAnB,CAAP;UACD,CAZD,MAYO;YAGL,IAAI,UAAU,GAAG,KAAjB;;YACA,sDAAgB,MAAhB,2CAAwB;cAAA,IAAb,EAAa;cACtB,IAAM,MAAK,GAAG,EAAC,CAAC,IAAhB;;cACA,IAAI,MAAK,IAAI,IAAb,EAAmB;gBACjB,IAAM,MAAM,GAAG,EAAC,CAAC,KAAjB;gBACA,IAAM,UAAS,GAAG,MAAM,CAAC,CAAD,CAAxB;;gBACA,IAAM,SAAQ,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAhB,CAAuB,CAAC,UAAD,CAAvB,CAAjB;;gBACA,IAAI,WAAW,GAAG,EAAC,CAAC,OAAF,CACd,CAAC,UAAD,EAAY,MAAZ,CAAmB,SAAS,CAAC,SAAV,CAAoB,MAAM,CAAC,KAAP,CAAa,CAAb,CAApB,CAAnB,CADc,CAAlB;;gBAEA,WAAW,GAAG,GAAG,CAAC,SAAJ,CAAc,WAAd,EAA2B,CAAC,CAAD,EAAI,CAAJ,CAA3B,CAAd;gBACA,WAAW,GAAG,WAAW,CAAC,OAAZ,CAAoB,SAApB,CAAd;gBACA,cAAc,CAAC,IAAf,CAAoB,WAApB;gBACA,UAAU,GAAG,IAAb;cACD,CAVD,MAUO,IAAI,MAAK,GAAG,CAAZ,EAAe;gBACpB,IAAM,KAAI,GAAG,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,MAAnB,EAA0B,MAA1B,CAAiC,CAAC,CAAD,CAAjC,CAAb;;gBACA,cAAc,CAAC,IAAf,CAAoB,GAAG,CAAC,SAAJ,CAAc,EAAd,EAAiB,KAAjB,CAApB;gBACA,UAAU,GAAG,IAAb;cACD,CAJM,MAIA;gBAEL,cAAc,CAAC,IAAf,CAAoB,EAApB;cACD;YACF;;YACD,IAAI,CAAC,GAAG,MAAI,CAAC,aAAL,CAAmB,cAAnB,CAAR;;YACA,IAAM,KAAK,GAAG,CAAC,CAAC,IAAhB;;YACA,IAAI,UAAJ,EAAgB;cAGd,IAAI,KAAK,IAAI,IAAb,EAAmB;gBACjB,IAAM,MAAM,GAAG,CAAC,CAAC,KAAjB;gBACA,IAAM,MAAK,GAAG,MAAM,CAAC,MAArB;gBACA,IAAM,SAAS,GAAG,MAAM,CAAC,MAAK,GAAG,CAAT,CAAxB;gBACA,IAAM,QAAQ,GACV,CAAC,SAAD,EAAY,MAAZ,CAAmB,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAP,GAAgB,CAAhC,CAAnB,CADJ;gBAEA,CAAC,GAAG,GAAG,CAAC,SAAJ,CAAc,CAAC,CAAC,OAAF,CAAU,CAAC,CAAC,CAAF,EAAK,SAAL,CAAV,CAAd,EAA0C,CAAC,CAAD,EAAI,CAAJ,CAA1C,EACK,OADL,CACa,QADb,CAAJ;cAED,CARD,MAQO,IAAI,KAAK,GAAG,CAAZ,EAAe;gBACpB,IAAM,IAAI,GAAG,CAAC,KAAK,GAAG,CAAT,EAAY,MAAZ,CAAmB,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,KAAK,GAAG,CAA3B,CAAnB,CAAb;gBACA,CAAC,GAAG,GAAG,CAAC,SAAJ,CAAc,CAAd,EAAiB,IAAjB,CAAJ;cACD;YACF;;YACD,OAAO,CAAP;UACD;QACF,CA5DD,MA4DO;UACL,OAAO,MAAI,CAAC,aAAL,CAAmB,MAAnB,CAAP;QACD;MACF,CAjEU,CAAX;IAkED;EAxKH;IAAA;IAAA,OA0KE,4BAAmB,UAAnB,EAA4C;MAC1C,UAAU,GAAG,UAAb;MACA,IAAI,WAAJ;;MACA,IAAI,UAAU,CAAC,CAAD,CAAV,IAAiB,IAArB,EAA2B;QACzB,WAAW,GAAG,IAAd;MACD,CAFD,MAEO;QACL,WAAW,GAAG,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAAd;MACD;;MACD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;QAC1C,IAAM,KAAK,GAAG,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAA7C;QACA,WAAW,GAAG,KAAK,+BAAL,CAAqC,WAArC,EAAkD,KAAlD,CAAd;MACD;;MAED,IAAI,UAAU,GAAa,EAA3B;;MACA,sDAAoB,UAApB,2CAAgC;QAAA,IAArB,OAAqB;;QAC9B,IAAI,OAAK,IAAI,IAAT,IAAiB,OAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;UACtC,UAAU,CAAC,IAAX,CAAgB,OAAK,CAAC,CAAD,CAArB;QACD;MACF;;MACD,UAAU,GAAG,aAAa,CAAC,MAAd,CAAqB,UAArB,CAAb;;MACA,IAAI,UAAU,CAAC,MAAX,KAAsB,CAA1B,EAA6B;QAC3B,WAAW,GAAG,UAAU,CAAC,MAAX,CAAkB,WAAlB,CAAd;MACD,CAFD,MAEO;QACL,WAAW,GAAG,CAAC,IAAD,EAAO,MAAP,CAAc,WAAd,CAAd;MACD;;MACD,OAAO,WAAP;IACD;EApMH;IAAA;IAAA,OAsME,qBAAY,MAAZ,EAAqC,IAArC,EAA2D;MACzD,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;QACnB,IAAI,IAAI,IAAI,IAAZ,EAAkB;UAChB,OAAO,IAAP;QACD;;QACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAd,CAAL,EAA0B;UACxB,MAAM,IAAI,UAAJ,CAAe,2BAAf,CAAN;QACD;;QACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;UAC1B,MAAM,IAAI,UAAJ,CAAe,6BAAf,CAAN;QACD;;QACD,IAAI,IAAI,CAAC,MAAL,KAAgB,MAAM,CAAC,MAA3B,EAAmC;UACjC,MAAM,IAAI,UAAJ,CACF,gHAEI,MAAM,CAAC,MAFX,YAEwB,IAAI,CAAC,MAF7B,OADE,CAAN;QAID;;QACD,IAAI,IAAI,CAAC,KAAL,CAAW,UAAA,CAAC;UAAA,OAAI,CAAC,IAAI,IAAT;QAAA,CAAZ,CAAJ,EAAgC;UAC9B,OAAO,IAAP;QACD;;QACD,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,UAAA,CAAC;UAAA,OAAI,CAAC,IAAI,IAAL,GAAY,CAAZ,GAAgB,GAAG,CAAC,UAAJ,CAAe,CAAf,EAAkB,CAAlB,CAApB;QAAA,CAAV,CAAP;QACA,IAAI,MAAM,GAAG,IAAI,CAAC,CAAD,CAAjB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAAI,CAAC,MAAL,GAAc,CAAlC,EAAqC,EAAE,CAAvC,EAA0C;UACxC,MAAM,GAAG,GAAG,CAAC,UAAJ,CAAe,MAAf,EAAuB,IAAI,CAAC,CAAD,CAA3B,CAAT;QACD;;QACD,OAAO,MAAP;MACD,CAzBM,CAAP;IA0BD;EAjOH;;EAAA;AAAA,EAAoC,KAApC;AAoOA,WAAa,GAAb;EAAA;;EAAA;;EAGE,aAAY,IAAZ,EAA4B;IAAA;;IAAA,0BACpB,IADoB;EAE3B;;EALH;IAAA;IAAA,OAOY,uBAAc,MAAd,EAA8B;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;QACD;;QACD,OAAO,MAAP;MACD,CANU,CAAX;IAOD;EAfH;;EAAA;AAAA,EAAyB,KAAzB;AAES,GAAA,CAAA,SAAA,GAAY,KAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,GAA5B;AAgDA,OAAM,SAAU,GAAV,CAAc,MAAd,EAA0D;EAE9D,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,GAAJ,CAAQ,EAAR,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;EACD;AACF;AAED,WAAa,QAAb;EAAA;;EAAA;;EAGE,kBAAY,IAAZ,EAA4B;IAAA;;IAAA,0BACpB,IADoB;EAE3B;;EALH;IAAA;IAAA,OAOY,uBAAc,MAAd,EAA8B;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;QACD;;QACD,OAAO,MAAP;MACD,CANU,CAAX;IAOD;EAfH;;EAAA;AAAA,EAA8B,KAA9B;AAES,QAAA,CAAA,SAAA,GAAY,UAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAgDA,OAAM,SAAU,QAAV,CAAmB,MAAnB,EAA+D;EAEnE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,QAAJ,CAAa,EAAb,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,QAAJ,CAAa,MAAb,CAAP;EACD;AACF;AAED,WAAa,OAAb;EAAA;;EAAA;;EAGE,iBAAY,IAAZ,EAA4B;IAAA;;IAAA,0BACpB,IADoB;EAE3B;;EALH;IAAA;IAAA,OAOY,uBAAc,MAAd,EAA8B;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;QACD;;QACD,OAAO,GAAG,CAAC,GAAJ,CAAQ,IAAI,MAAM,CAAC,MAAnB,EAA2B,MAA3B,CAAP;MACD,CANU,CAAX;IAOD;EAfH;;EAAA;AAAA,EAA6B,KAA7B;AAES,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAiDA,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AAED,WAAa,OAAb;EAAA;;EAAA;;EAGE,iBAAY,IAAZ,EAA4B;IAAA;;IAAA,0BACpB,IADoB;EAE3B;;EALH;IAAA;IAAA,OAOY,uBAAc,MAAd,EAA8B;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAnB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,MAAM,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,EAAoB,MAAM,CAAC,CAAD,CAA1B,CAAT;QACD;;QACD,OAAO,MAAP;MACD,CANU,CAAX;IAOD;EAfH;;EAAA;AAAA,EAA6B,KAA7B;AAES,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAgDA,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AAED,WAAa,OAAb;EAAA;;EAAA;;EAGE,iBAAY,IAAZ,EAA4B;IAAA;;IAAA,0BACpB,IADoB;EAE3B;;EALH;IAAA;IAAA,OAOY,uBAAc,MAAd,EAA8B;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAnB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,MAAM,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,EAAoB,MAAM,CAAC,CAAD,CAA1B,CAAT;QACD;;QACD,OAAO,MAAP;MACD,CANU,CAAX;IAOD;EAfH;;EAAA;AAAA,EAA6B,KAA7B;AAES,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAgDA,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AASD,WAAa,WAAb;EAAA;;EAAA;;EAME,qBAAY,IAAZ,EAAuC;IAAA;;IAAA;;IACrC,4BAAM,IAAN;IAJO,OAAA,YAAA,GAAe,CAAC,CAAhB;;IAKP,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,IAAI,GAAG,EAAP;IACD;;IACD,OAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,OAAK,YAAzB,GAAwC,IAAI,CAAC,IAAzD;IACA,OAAK,eAAL,GAAuB,IAAvB;IACA,OAAK,eAAL,GAAuB,KAAvB;IAPqC;EAQtC;;EAdH;IAAA;IAAA,OAgBE,eAAM,UAAN,EAA+B;MAE7B,IAAI,EAAE,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAA/B,KACA,UAAU,CAAC,MAAX,KAAsB,CAD1B,EAC6B;QAC3B,MAAM,IAAI,UAAJ,CACF,oEACA,QAFE,CAAN;MAGD;;MACD,UAAU,GAAG,UAAb;MAEA,IAAI,YAAY,GAAG,IAAnB;;MACA,sDAAoB,UAApB,2CAAgC;QAAA,IAArB,KAAqB;;QAC9B,IAAI,KAAK,IAAI,IAAb,EAAmB;UACjB,YAAY,GAAG,KAAf;UACA;QACD;MACF;;MACD,IAAI,YAAJ,EAAkB;QAChB;MACD;;MAED,IAAM,QAAQ,GAAY,EAA1B;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;QAC1C,IAAM,sBAAsB,GAAG,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,EAA/B;QACA,sBAAsB,CAAC,MAAvB,CAA8B,KAAK,IAAnC,EAAyC,CAAzC;QACA,IAAI,MAAM,GAAG,KAAb;;QACA,sDAAoB,QAApB,2CAA8B;UAAA,IAAnB,OAAmB;;UAC5B,IAAI,IAAI,CAAC,WAAL,CAAiB,OAAjB,EAAwB,sBAAxB,CAAJ,EAAqD;YACnD,MAAM,GAAG,IAAT;YACA;UACD;QACF;;QACD,IAAI,CAAC,MAAL,EAAa;UACX,QAAQ,CAAC,IAAT,CAAc,sBAAd;QACD;MACF;;MACD,IAAI,QAAQ,CAAC,MAAT,GAAkB,CAAtB,EAAyB;QACvB,MAAM,IAAI,UAAJ,CACF,gEACA,gDADA,GAEA,IAAI,CAAC,SAAL,CAAe,UAAf,CAHE,CAAN;MAID;IACF;EA1DH;IAAA;IAAA,OA4DY,uBAAc,MAAd,EAA8B;MAAA;;MACtC,OAAO,IAAI,CAAC,YAAK;QACf,OAAO,CAAC,CAAC,WAAF,CAAc,MAAd,EAAsB,MAAI,CAAC,IAA3B,CAAP;MACD,CAFU,CAAX;IAGD;EAhEH;IAAA;IAAA,OAkEE,4BAAmB,UAAnB,EAA4C;MAC1C,IAAI,EAAE,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAA/B,CAAJ,EAAkE;QAChE,MAAM,IAAI,UAAJ,CACF,6DADE,CAAN;MAED;;MACD,IAAM,WAAW,GAAG,UAApB;MACA,IAAM,WAAW,GAAG,WAAW,CAAC,CAAD,CAAX,CAAe,KAAf,EAApB;MACA,IAAM,IAAI,GAAG,KAAK,IAAL,GAAY,CAAZ,GAAgB,WAAW,CAAC,MAAZ,GAAqB,KAAK,IAA1C,GAAiD,KAAK,IAAnE;;MAGA,sDAAoB,WAAW,CAAC,KAAZ,CAAkB,CAAlB,CAApB,2CAA0C;QAAA,IAA/B,KAA+B;;QACxC,IAAI,WAAW,CAAC,IAAD,CAAX,IAAqB,IAArB,IAA6B,KAAK,CAAC,IAAD,CAAL,IAAe,IAAhD,EAAsD;UACpD,WAAW,CAAC,IAAD,CAAX,GAAoB,IAApB;UACA;QACD;;QACD,WAAW,CAAC,IAAD,CAAX,IAAqB,KAAK,CAAC,IAAD,CAA1B;MACD;;MACD,OAAO,WAAP;IACD;EApFH;IAAA;IAAA,OAsFE,qBAAY,MAAZ,EAAqC,IAArC,EAA2D;MAAA;;MACzD,IAAI,IAAI,IAAI,IAAZ,EAAkB;QAChB,OAAO,IAAP;MACD;;MACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAd,CAAL,EAA0B;QACxB,MAAM,IAAI,UAAJ,CAAe,2CAAf,CAAN;MACD;;MACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;QAC1B,MAAM,IAAI,UAAJ,CAAe,6CAAf,CAAN;MACD;;MACD,IAAI,IAAI,CAAC,MAAL,KAAgB,MAAM,CAAC,MAA3B,EAAmC;QACjC,MAAM,IAAI,UAAJ,CACF,qCAAmC,IAAI,CAAC,MAAxC,0CAC6B,MAAM,CAAC,MADpC,OADE,CAAN;MAGD;;MACD,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;QACnB,IAAI,YAAY,GAAG,IAAnB;QACA,IAAI,CAAC,OAAL,CAAa,UAAA,CAAC,EAAG;UACf,IAAI,CAAC,IAAI,IAAT,EAAe;YACb,YAAY,GAAG,KAAf;YACA;UACD;QACF,CALD;;QAMA,IAAI,YAAJ,EAAkB;UAChB,OAAO,IAAP;QACD;;QACD,IAAM,WAAW,GAAa,EAA9B;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;UACtC,IAAI,IAAI,CAAC,CAAD,CAAJ,IAAW,IAAf,EAAqB;YAEnB,WAAW,CAAC,IAAZ,CAAiB,GAAG,CAAC,QAAJ,CAAa,MAAM,CAAC,CAAD,CAAnB,EAAwB,MAAxB,CAA+B,MAA/B,CAAjB;UACD,CAHD,MAGO,IAAI,IAAI,CAAC,CAAD,CAAJ,CAAQ,IAAR,GAAe,MAAM,CAAC,CAAD,CAAN,CAAU,IAA7B,EAAmC;YAExC,WAAW,CAAC,IAAZ,CAAiB,GAAG,CAAC,UAAJ,CAAe,IAAI,CAAC,CAAD,CAAnB,EAAwB,CAAC,CAAzB,CAAjB;UACD,CAHM,MAGA;YACL,WAAW,CAAC,IAAZ,CAAiB,IAAI,CAAC,CAAD,CAArB;UACD;QACF;;QACD,IAAM,iBAAiB,GAAG,GAAG,CAAC,MAAJ,CAAW,WAAX,EAAwB,MAAI,CAAC,IAA7B,CAA1B;QACA,OAAO,GAAG,CAAC,GAAJ,CAAQ,iBAAR,EAA2B,CAAC,CAA5B,EAA+B,KAA/B,CAAP;MACD,CAzBM,CAAP;IA0BD;EA/HH;IAAA;IAAA,OAiIE,qBAAS;MACP,IAAM,MAAM,GAA6B;QACvC,QAAQ,KAAK;MAD0B,CAAzC;;MAGA,IAAM,UAAU,6EAAhB;;MACA,SAAc,MAAd,EAAsB,UAAtB;;MACA,OAAO,MAAP;IACD;EAxIH;;EAAA;AAAA,EAAiC,KAAjC;AAES,WAAA,CAAA,SAAA,GAAY,aAAZ;AAwIT,aAAa,CAAC,aAAd,CAA4B,WAA5B;AAkDA,OAAM,SAAU,WAAV,CAAsB,MAAtB,EAC0C;EAC9C,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAM,KAAK,GAAG,IAAI,WAAJ,CAAgB,EAAhB,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,WAAJ,CAAgB,MAAhB,CAAP;EACD;AACF;;AA6BD,SAAS,aAAT,CAAuB,IAAvB,EAAqC,GAArC,EAAgD;EAC9C,OAAO,IAAI,GAAG,CAAd,EAAiB;IACf,IAAI,IAAI,GAAR;EACD;;EACD,OAAO,IAAP;AACD;;AAED,SAAS,QAAT,CAAkB,CAAlB,EAA6B,CAA7B,EAAwC,IAAxC,EAAqE;EACnE,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAAjB,IAAsB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA3C,EAA8C;IAC5C,MAAM,IAAI,mBAAJ,CACF,kEADE,CAAN;EAED;;EACD,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,CAAC,CAAC,KAAF,CAAQ,MAAR,IAAkB,CADtB,EAEI;IAAA,OAAM,+DACS,CAAC,CAAC,KAAF,CAAQ,MADjB,CAAN;EAAA,CAFJ;EAIA,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,CAAC,CAAC,KAAF,CAAQ,MAAR,IAAkB,CADtB,EAEI;IAAA,OAAM,+DACS,CAAC,CAAC,KAAF,CAAQ,MADjB,CAAN;EAAA,CAFJ;;EAKA,IAAI,OAAO,IAAP,KAAgB,QAApB,EAA8B;IAC5B,IAAI,GAAG,CAAC,IAAD,EAAO,IAAP,CAAP;EACD;;EAED,IAAI,CAAC,CAAC,KAAF,KAAY,WAAZ,IAA2B,CAAC,CAAC,KAAF,KAAY,WAA3C,EAAwD;IACtD,MAAM,IAAI,mBAAJ,CACF,6DADE,CAAN;EAED;;EAED,IAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EACA,IAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;;EACA,IAAI,IAAI,IAAI,IAAZ,EAAkB;IAEhB,IAAI,GAAG,CAAC,KAAK,GAAG,CAAT,EAAY,KAAK,GAAG,CAApB,CAAP;EACD;;EACD,IAAM,SAAS,GAAG,IAAlB;EAEA,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;IACnB,IAAI,IAAJ;;IACA,IAAI,KAAK,GAAG,KAAZ,EAAmB;MACjB,IAAI,GAAG,KAAK,GAAG,KAAf;MACA,IAAM,SAAS,GAAU,EAAzB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAApB,EAA0B,EAAE,CAA5B,EAA+B;QAC7B,SAAS,CAAC,IAAV,CAAe,CAAf;MACD;;MACD,CAAC,GAAG,CAAC,CAAC,OAAF,CAAU,CAAC,CAAC,KAAF,CAAQ,MAAR,CAAe,SAAf,CAAV,CAAJ;IACD,CAPD,MAOO,IAAI,KAAK,GAAG,KAAZ,EAAmB;MACxB,IAAI,GAAG,KAAK,GAAG,KAAf;MACA,IAAM,UAAS,GAAU,EAAzB;;MACA,KAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,IAApB,EAA0B,EAAE,EAA5B,EAA+B;QAC7B,UAAS,CAAC,IAAV,CAAe,CAAf;MACD;;MACD,CAAC,GAAG,CAAC,CAAC,OAAF,CAAU,CAAC,CAAC,KAAF,CAAQ,MAAR,CAAe,UAAf,CAAV,CAAJ;IACD,CAPM,MAOA;MACL,IAAI,GAAG,CAAP;IACD;;IAED,IAAI,GAAJ;;IACA,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAAnB,IAAwB,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAA/C,EAAkD;MAChD,IAAI,SAAS,CAAC,CAAD,CAAT,KAAiB,SAAS,CAAC,CAAD,CAA9B,EAAmC;QACjC,GAAG,GAAG,CAAC,CAAC,GAAF,CAAM,CAAN,EAAS,GAAT,CAAa,SAAS,CAAC,CAAD,CAAtB,CAAN;MACD,CAFD,MAEO;QACL,GAAG,GAAG,CAAC,CAAC,SAAF,CAAY,CAAC,CAAD,EAAI,CAAJ,CAAZ,EAAoB,GAApB,CAAwB,CAAxB,EAA2B,GAA3B,CAA+B,SAAS,CAAC,CAAD,CAAxC,CAAN;MACD;IACF,CAND,MAMO;MACL,IAAM,IAAI,GAAG,SAAS,CAAC,CAAD,CAAT,KAAiB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA/C;MACA,IAAM,IAAI,GAAG,SAAS,CAAC,CAAD,CAAT,KAAiB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA/C;MACA,GAAG,GAAG,CAAC,CAAC,MAAF,CAAS,CAAT,EAAY,IAAZ,EAAkB,IAAlB,CAAN;IACD;;IAED,IAAI,IAAI,GAAG,CAAX,EAAc;MACZ,IAAI,GAAJ;;MACA,IAAI,KAAK,GAAG,KAAZ,EAAmB;QACjB,GAAG,GAAG,KAAK,GAAG,KAAR,GAAgB,CAAtB;MACD,CAFD,MAEO;QACL,GAAG,GAAG,KAAK,GAAG,CAAd;MACD;;MACD,IAAM,WAAW,GAAa,EAA9B;;MACA,KAAK,IAAI,GAAC,GAAG,GAAb,EAAkB,GAAC,GAAG,GAAG,GAAG,IAA5B,EAAkC,EAAE,GAApC,EAAuC;QACrC,WAAW,CAAC,IAAZ,CAAiB,GAAjB;MACD;;MACD,GAAG,GAAG,GAAG,CAAC,OAAJ,CAAY,WAAZ,CAAN;IACD;;IACD,IAAI,GAAG,CAAC,KAAJ,CAAU,MAAV,KAAqB,CAAzB,EAA4B;MAC1B,GAAG,GAAG,GAAG,CAAC,UAAJ,CAAe,CAAf,CAAN;IACD;;IACD,OAAO,GAAP;EACD,CAlDM,CAAP;AAmDD;;AAED,WAAa,GAAb;EAAA;;EAAA;;EAOE,aAAY,IAAZ,EAA8B;IAAA;;IAAA;;IAC5B,4BAAM,IAAN;IACA,OAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;IACA,OAAK,SAAL,GAAiB,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,KAAzB,GAAiC,IAAI,CAAC,SAAvD;IACA,OAAK,eAAL,GAAuB,IAAvB;IACA,OAAK,eAAL,GAAuB,KAAvB;IAL4B;EAM7B;;EAbH;IAAA;IAAA,OAeE,eAAM,UAAN,EAA+B;MAC7B,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,UAAU,CAAC,MAAX,KAAsB,CAAnD,IACI,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CADJ,IACoC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAFxC,EAGI;QAAA,OAAM,+DAAN;MAAA,CAHJ;MAIA,IAAM,MAAM,GAAG,UAAU,CAAC,CAAD,CAAzB;MACA,IAAM,MAAM,GAAG,UAAU,CAAC,CAAD,CAAzB;;MACA,IAAI,MAAM,CAAC,MAAP,GAAgB,CAAhB,IAAqB,MAAM,CAAC,MAAP,GAAgB,CAAzC,EAA4C;QAC1C,MAAM,IAAI,mBAAJ,CACF,8DADE,CAAN;MAED;;MAED,IAAM,IAAI,GAAG,KAAK,aAAL,CAAmB,MAAnB,EAA2B,MAA3B,CAAb;;MACA,IAAI,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAAN,KAAoB,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAA9B,EAAyC;QACvC,MAAM,IAAI,UAAJ,CACF,iCACG,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CADT,aAC0B,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CADhC,CADE,CAAN;MAGD;IACF;EAjCH;IAAA;IAAA,OAmCY,uBAAc,MAAd,EAA8B;MACtC,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;QACvB,MAAM,IAAI,UAAJ,CACF,0EACgB,MAAM,CAAC,MADvB,gBADE,CAAN;MAGD;;MAED,IAAI,EAAE,GAAG,MAAM,CAAC,CAAD,CAAf;MACA,IAAI,EAAE,GAAG,MAAM,CAAC,CAAD,CAAf;MACA,IAAI,IAAJ;;MACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAL,EAA+B;QAC7B,IAAI,GAAG,CACL,aAAa,CAAC,KAAK,IAAN,EAAY,EAAE,CAAC,KAAH,CAAS,MAArB,CADR,EAEL,aAAa,CAAC,KAAK,IAAN,EAAY,EAAE,CAAC,KAAH,CAAS,MAArB,CAFR,CAAP;MAID,CALD,MAKO;QACL,IAAI,GAAG,KAAK,IAAL,CAAU,GAAV,CACI,UAAC,IAAD,EAAO,CAAP;UAAA,OAAa,aAAa,CACtB,IADsB,EAChB,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,MADA,CAA1B;QAAA,CADJ,CAAP;MAGD;;MACD,IAAI,KAAK,SAAT,EAAoB;QAClB,EAAE,GAAG,WAAW,CAAC,EAAD,EAAK,IAAI,CAAC,CAAD,CAAT,CAAhB;QACA,EAAE,GAAG,WAAW,CAAC,EAAD,EAAK,IAAI,CAAC,CAAD,CAAT,CAAhB;MACD;;MACD,OAAO,QAAQ,CAAC,EAAD,EAAK,EAAL,EAAS,IAAT,CAAf;IACD;EA5DH;IAAA;IAAA,OA8DU,uBAAc,MAAd,EAA6B,MAA7B,EAA0C;MAChD,IAAI,IAAJ;;MACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAL,EAA+B;QAE7B,IAAI,GAAG,CACL,aAAa,CAAC,KAAK,IAAN,EAAY,MAAM,CAAC,MAAnB,CADR,EAEL,aAAa,CAAC,KAAK,IAAN,EAAY,MAAM,CAAC,MAAnB,CAFR,CAAP;MAID,CAND,MAMO;QAEL,IAAI,GAAG,KAAK,IAAZ;MACD;;MACD,OAAO,IAAP;IACD;EA3EH;IAAA;IAAA,OA6EE,4BAAmB,UAAnB,EAA4C;MAC1C,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,UAAU,CAAC,MAAX,KAAsB,CAAnD,IACI,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CADJ,IACoC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAFxC,EAGI;QAAA,OAAM,+DAAN;MAAA,CAHJ;MAIA,IAAM,MAAM,GAAI,UAAU,CAAC,CAAD,CAAV,CAAwB,KAAxB,EAAhB;MACA,IAAM,MAAM,GAAI,UAAU,CAAC,CAAD,CAAV,CAAwB,KAAxB,EAAhB;;MACA,IAAI,MAAM,CAAC,MAAP,GAAgB,CAAhB,IAAqB,MAAM,CAAC,MAAP,GAAgB,CAAzC,EAA4C;QAC1C,MAAM,IAAI,mBAAJ,CACF,8DADE,CAAN;MAED;;MAED,IAAM,IAAI,GAAG,KAAK,aAAL,CAAmB,MAAnB,EAA2B,MAA3B,CAAb;MACA,MAAM,CAAC,MAAP,CAAc,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;MACA,MAAM,CAAC,MAAP,CAAc,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;MACA,MAAM,CAAC,MAAP,CAAc,CAAd,EAAiB,CAAjB;MACA,IAAM,WAAW,GAAG,MAAM,CAAC,MAAP,CAAc,MAAd,CAApB;;MACA,IAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;QAC5B,WAAW,CAAC,IAAZ,CAAiB,CAAjB;MACD;;MACD,OAAO,WAAP;IACD;EAlGH;IAAA;IAAA,OAoGE,qBAAY,MAAZ,EAAqC,IAArC,EAA2D;MACzD,OAAO,IAAP;IACD;EAtGH;IAAA;IAAA,OAwGE,qBAAS;MACP,IAAM,MAAM,GAA6B;QACvC,QAAQ,KAAK,IAD0B;QAEvC,aAAa,KAAK;MAFqB,CAAzC;;MAIA,IAAM,UAAU,qEAAhB;;MACA,SAAc,MAAd,EAAsB,UAAtB;;MACA,OAAO,MAAP;IACD;EAhHH;;EAAA;AAAA,EAAyB,KAAzB;AAES,GAAA,CAAA,SAAA,GAAY,KAAZ;AAgHT,aAAa,CAAC,aAAd,CAA4B,GAA5B","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Merge Layers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { l2Normalize } from '../losses';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as mathUtils from '../utils/math_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\n/**\n * Generic Merge layer for element-wise merge functions.\n *\n * Used to implement `Sum`, `Average`, `Concatenate`, etc.\n */\nexport class Merge extends Layer {\n    constructor(args) {\n        super(args || {});\n        this.supportsMasking = true;\n    }\n    /**\n     * Logic for merging multiple tensors, to be overridden by subclasses.\n     * @param inputs\n     */\n    mergeFunction(inputs) {\n        throw new NotImplementedError();\n    }\n    /**\n     * Computes the shape of the result of an elementwise operation.\n     *\n     * @param shape1: Shape of the first tensor.\n     * @param shape2: Shape of the second tensor.\n     * @returns Expected output shape when an elementwise operation is carried\n     *   out on 2 tensors with shapes `shape1` and `shape2`.\n     * @throws ValueError: If `shape1` and `shape2` are not compatible for\n     *   element-wise operations.\n     */\n    computeElementwiseOpOutputShape(shape1, shape2) {\n        if (shape1 == null || shape2 == null) {\n            return null;\n        }\n        else if (shape1.length < shape2.length) {\n            return this.computeElementwiseOpOutputShape(shape2, shape1);\n        }\n        else if (shape2.length === 0) {\n            return shape1;\n        }\n        const outputShape = shape1.slice(0, shape1.length - shape2.length);\n        for (let k = 0; k < shape2.length; ++k) {\n            const i = shape1[shape1.length - shape2.length + k];\n            const j = shape2[k];\n            if (i == null || j == null || i < 0 || j < 0) {\n                outputShape.push(null);\n            }\n            else if (i === 1) {\n                outputShape.push(j);\n            }\n            else if (j === 1) {\n                outputShape.push(i);\n            }\n            else {\n                if (i !== j) {\n                    throw new ValueError('Operands could not be broadcast together with shapes ' +\n                        JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n                }\n                outputShape.push(i);\n            }\n        }\n        return outputShape;\n    }\n    build(inputShape) {\n        // Used purely for shape validation.\n        if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n            // Make sure that inputShape is an Array of shape.\n            inputShape = [getExactlyOneShape(inputShape)];\n        }\n        inputShape = inputShape;\n        if (inputShape.length < 2) {\n            throw new ValueError('A merge layer should be called on an Array of at least 2 inputs.' +\n                ` Got ${inputShape.length} input(s).`);\n        }\n        // Make sure that there is at most one unique batch size among the input\n        // shapes.\n        let batchSizes = [];\n        for (const shape of inputShape) {\n            if (shape != null && shape[0] !== null) {\n                batchSizes.push(shape[0]);\n            }\n        }\n        batchSizes = generic_utils.unique(batchSizes);\n        if (batchSizes.length > 1) {\n            throw new ValueError(`Can not merge tensors with different batch sizes. ` +\n                `Got tensors with shapes: ${JSON.stringify(inputShape)}.`);\n        }\n        let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);\n        for (let i = 1; i < inputShape.length; ++i) {\n            const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n            outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n        }\n        // If the inputs have different ranks, we have to reshape them to make them\n        // broadcastable.\n        const allRanks = inputShape.map(shape => shape.length);\n        if (inputShape.indexOf(null) === -1 &&\n            generic_utils.unique(allRanks).length === 1) {\n            this.reshapeRequired = false;\n        }\n        else {\n            this.reshapeRequired = true;\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = inputs;\n            if (this.reshapeRequired) {\n                const reshapedInputs = [];\n                const inputDims = inputs.map(input => input.rank);\n                if (inputDims.indexOf(null) === -1) {\n                    // If ranks of all inputs are available, we simply expand each of them\n                    // at axis=1 until all of them have the same rank.\n                    const maxNDim = mathUtils.max(inputDims);\n                    for (let x of inputs) {\n                        const xNDim = x.rank;\n                        for (let k = 0; k < maxNDim - xNDim; ++k) {\n                            x = K.expandDims(x, 1);\n                        }\n                        reshapedInputs.push(x);\n                    }\n                    return this.mergeFunction(reshapedInputs);\n                }\n                else {\n                    // Transpose all inputs so that batch size is the last dimension.\n                    // [batchSize, dim1, dim2, ...] -> [dim1, dim2, ..., batchSize]\n                    let transposed = false;\n                    for (const x of inputs) {\n                        const xNDim = x.rank;\n                        if (xNDim == null) {\n                            const xShape = x.shape;\n                            const batchSize = xShape[0];\n                            const newShape = xShape.slice(1).concat([batchSize]);\n                            let xTransposed = x.reshape([batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n                            xTransposed = tfc.transpose(xTransposed, [1, 0]);\n                            xTransposed = xTransposed.reshape(newShape);\n                            reshapedInputs.push(xTransposed);\n                            transposed = true;\n                        }\n                        else if (xNDim > 1) {\n                            const dims = mathUtils.range(1, xNDim).concat([0]);\n                            reshapedInputs.push(tfc.transpose(x, dims));\n                            transposed = true;\n                        }\n                        else {\n                            // We don't transpose inputs if they are 1D vectors or scalars.\n                            reshapedInputs.push(x);\n                        }\n                    }\n                    let y = this.mergeFunction(reshapedInputs);\n                    const yNDim = y.rank;\n                    if (transposed) {\n                        // If inputs have been transposed, we have to transpose the output\n                        // too.\n                        if (yNDim == null) {\n                            const yShape = y.shape;\n                            const yNDim = yShape.length;\n                            const batchSize = yShape[yNDim - 1];\n                            const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));\n                            y = tfc.transpose(y.reshape([-1, batchSize]), [1, 0])\n                                .reshape(newShape);\n                        }\n                        else if (yNDim > 1) {\n                            const dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n                            y = tfc.transpose(y, dims);\n                        }\n                    }\n                    return y;\n                }\n            }\n            else {\n                return this.mergeFunction(inputs);\n            }\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = inputShape;\n        let outputShape;\n        if (inputShape[0] == null) {\n            outputShape = null;\n        }\n        else {\n            outputShape = inputShape[0].slice(1);\n        }\n        for (let i = 1; i < inputShape.length; ++i) {\n            const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n            outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n        }\n        let batchSizes = [];\n        for (const shape of inputShape) {\n            if (shape != null && shape[0] !== null) {\n                batchSizes.push(shape[0]);\n            }\n        }\n        batchSizes = generic_utils.unique(batchSizes);\n        if (batchSizes.length === 1) {\n            outputShape = batchSizes.concat(outputShape);\n        }\n        else {\n            outputShape = [null].concat(outputShape);\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        return tfc.tidy(() => {\n            if (mask == null) {\n                return null;\n            }\n            if (!Array.isArray(mask)) {\n                throw new ValueError('`mask` should be an Array');\n            }\n            if (!Array.isArray(inputs)) {\n                throw new ValueError('`inputs` should be an Array');\n            }\n            if (mask.length !== inputs.length) {\n                throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same ` +\n                    `length, but have different lengths ` +\n                    `(${inputs.length} vs ${mask.length})`);\n            }\n            if (mask.every(m => m == null)) {\n                return null;\n            }\n            mask = mask.map(m => m == null ? m : tfc.expandDims(m, 0));\n            let output = mask[0];\n            for (let i = 1; i < mask.length - 1; ++i) {\n                output = tfc.logicalAnd(output, mask[i]);\n            }\n            return output;\n        });\n    }\n}\nexport class Add extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.add(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nAdd.className = 'Add';\nserialization.registerClass(Add);\n/**\n * Calculate the element-wise sum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Add` layer, by using no input argument\n *    or a single configuration argument. The resultant `Add` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const addLayer = tf.layers.add();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = addLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.add([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.add([input1, input2]).print();\n * // Gives [[11, 22], [33, 44]].\n *\n */\nexport function add(config) {\n    if (Array.isArray(config)) {\n        const layer = new Add({});\n        return layer.apply(config);\n    }\n    else {\n        return new Add(config);\n    }\n}\nexport class Multiply extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.mul(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMultiply.className = 'Multiply';\nserialization.registerClass(Multiply);\n/**\n * Calculate the element-wise product of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Multiply` layer, by using no input argument\n *    or a single configuration argument. The resultant `Multiply` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const multiplyLayer = tf.layers.multiply();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = multiplyLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.multiply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.multiply([input1, input2]).print();\n * // Gives [[10, 40], [90, 160]].\n *\n */\nexport function multiply(config) {\n    if (Array.isArray(config)) {\n        const layer = new Multiply({});\n        return layer.apply(config);\n    }\n    else {\n        return new Multiply(config);\n    }\n}\nexport class Average extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.add(output, inputs[i]);\n            }\n            return tfc.mul(1 / inputs.length, output);\n        });\n    }\n}\n/** @nocollapse */\nAverage.className = 'Average';\nserialization.registerClass(Average);\n/**\n * Calculate the element-wise arithmetic mean of inputs, which all have the same\n * shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Average` layer, by using no input argument\n *    or a single configuration argument. The resultant `Average` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const averageLayer = tf.layers.average();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = averageLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.average([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.average([input1, input2]).print();\n * // Gives [[5.5, 11], [16.5, 22]].\n *\n */\nexport function average(config) {\n    if (Array.isArray(config)) {\n        const layer = new Average({});\n        return layer.apply(config);\n    }\n    else {\n        return new Average(config);\n    }\n}\nexport class Maximum extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0];\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.maximum(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMaximum.className = 'Maximum';\nserialization.registerClass(Maximum);\n/**\n * Calculate the element-wise maximum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Maximum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Maximum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const maximumLayer = tf.layers.maximum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = maximumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.maximum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.maximum([input1, input2]).print();\n * // Gives [[10, 20], [30, 40]].\n *\n */\nexport function maximum(config) {\n    if (Array.isArray(config)) {\n        const layer = new Maximum({});\n        return layer.apply(config);\n    }\n    else {\n        return new Maximum(config);\n    }\n}\nexport class Minimum extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0];\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.minimum(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMinimum.className = 'Minimum';\nserialization.registerClass(Minimum);\n/**\n * Calculate the element-wise minimum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Minimum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Minimum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const minimumLayer = tf.layers.minimum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = minimumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.minimum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.minimum([input1, input2]).print();\n * // Gives [[1, 2], [3, 4]].\n *\n */\nexport function minimum(config) {\n    if (Array.isArray(config)) {\n        const layer = new Minimum({});\n        return layer.apply(config);\n    }\n    else {\n        return new Minimum(config);\n    }\n}\nexport class Concatenate extends Merge {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_AXIS = -1;\n        if (args == null) {\n            args = {};\n        }\n        this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n        this.supportsMasking = true;\n        this.reshapeRequired = false;\n    }\n    build(inputShape) {\n        // Used purely for shape validation.]\n        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) ||\n            inputShape.length === 1) {\n            throw new ValueError('A `Concatenate` layer should be called on a list of at least 2 ' +\n                'inputs');\n        }\n        inputShape = inputShape;\n        let allNoneShape = true;\n        for (const shape of inputShape) {\n            if (shape != null) {\n                allNoneShape = false;\n                break;\n            }\n        }\n        if (allNoneShape) {\n            return;\n        }\n        const shapeSet = [];\n        for (let i = 0; i < inputShape.length; ++i) {\n            const shapeWithoutConcatAxis = inputShape[i].slice();\n            shapeWithoutConcatAxis.splice(this.axis, 1);\n            let exists = false;\n            for (const shape of shapeSet) {\n                if (util.arraysEqual(shape, shapeWithoutConcatAxis)) {\n                    exists = true;\n                    break;\n                }\n            }\n            if (!exists) {\n                shapeSet.push(shapeWithoutConcatAxis);\n            }\n        }\n        if (shapeSet.length > 1) {\n            throw new ValueError('A `Concatenate` layer requires inputs with matching shapes ' +\n                'except for the concat axis. Got input shapes: ' +\n                JSON.stringify(inputShape));\n        }\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            return K.concatenate(inputs, this.axis);\n        });\n    }\n    computeOutputShape(inputShape) {\n        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n            throw new ValueError('A `Concatenate` layer should be called on a list of inputs.');\n        }\n        const inputShapes = inputShape;\n        const outputShape = inputShapes[0].slice();\n        const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;\n        // Porting Note: the line above is because TypeScript doesn't support\n        //   negative indices.\n        for (const shape of inputShapes.slice(1)) {\n            if (outputShape[axis] == null || shape[axis] == null) {\n                outputShape[axis] = null;\n                break;\n            }\n            outputShape[axis] += shape[axis];\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        if (mask == null) {\n            return null;\n        }\n        if (!Array.isArray(mask)) {\n            throw new ValueError('`mask` should be an array for Concatenate');\n        }\n        if (!Array.isArray(inputs)) {\n            throw new ValueError('`inputs` should be an array for Concatenate');\n        }\n        if (mask.length !== inputs.length) {\n            throw new ValueError(`Mismatch in the length of mask (${mask.length}) ` +\n                `and the legnth of inputs (${inputs.length})`);\n        }\n        return tfc.tidy(() => {\n            let allNullMasks = true;\n            mask.forEach(m => {\n                if (m != null) {\n                    allNullMasks = false;\n                    return;\n                }\n            });\n            if (allNullMasks) {\n                return null;\n            }\n            const outputMasks = [];\n            for (let i = 0; i < inputs.length; ++i) {\n                if (mask[i] == null) {\n                    // Input is unmasked. Append all 1's to masks.\n                    outputMasks.push(tfc.onesLike(inputs[i]).asType('bool'));\n                }\n                else if (mask[i].rank < inputs[i].rank) {\n                    // Mask is smaller than the input, expand it.\n                    outputMasks.push(tfc.expandDims(mask[i], -1));\n                }\n                else {\n                    outputMasks.push(mask[i]);\n                }\n            }\n            const concatenatedMasks = tfc.concat(outputMasks, this.axis);\n            return tfc.all(concatenatedMasks, -1, false);\n        });\n    }\n    getConfig() {\n        const config = {\n            'axis': this.axis,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nConcatenate.className = 'Concatenate';\nserialization.registerClass(Concatenate);\n/**\n * Concatenate an `Array` of inputs.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Concatenate` layer, by using no input argument\n *    or a single configuration argument. The resultant `Concatenate` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const concatLayer = tf.layers.concatenate();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = concatLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 7], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = tf.layers.concatenate([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([[1, 2], [3, 4]], [2, 2]);\n * const input2 = tf.tensor2d([[10, 20], [30, 40]], [2, 2]);\n * tf.layers.concatenate([input1, input2]).print();\n * // Gives [[1, 2, 10, 20], [3, 4, 30, 40]].\n *\n */\nexport function concatenate(config) {\n    if (Array.isArray(config)) {\n        const layer = new Concatenate({});\n        return layer.apply(config);\n    }\n    else {\n        return new Concatenate(config);\n    }\n}\n/**\n * Interpretable potentially negative axis index.\n *\n * For example, given axis = -1, and dim = 3, this function will return 2.\n *\n * @param axis The axis index, may be a positive, zero or negative integer.\n * @param dim Total number of dimensions, a positive integer.\n * @returns A non-negative axis index equivalent to the input `axis`.\n */\nfunction interpretAxis(axis, dim) {\n    while (axis < 0) {\n        axis += dim;\n    }\n    return axis;\n}\nfunction batchDot(x, y, axes) {\n    if (x.shape.length > 3 || y.shape.length > 3) {\n        throw new NotImplementedError('batchDot is not implemented for tensors of 4D or higher rank yet');\n    }\n    tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, ` +\n        `but got ${x.shape.length}`);\n    tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, ` +\n        `but got ${y.shape.length}`);\n    if (typeof axes === 'number') {\n        axes = [axes, axes];\n    }\n    if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n        throw new NotImplementedError('batchDot is not implemented for complex64-type Tensors yet.');\n    }\n    const xNDim = x.shape.length;\n    const yNDim = y.shape.length;\n    if (axes == null) {\n        // Behave like batchMatmul by default.\n        axes = [xNDim - 1, yNDim - 2];\n    }\n    const axesArray = axes;\n    return tfc.tidy(() => {\n        let diff;\n        if (xNDim > yNDim) {\n            diff = xNDim - yNDim;\n            const diffShape = [];\n            for (let i = 0; i < diff; ++i) {\n                diffShape.push(1);\n            }\n            y = y.reshape(y.shape.concat(diffShape));\n        }\n        else if (yNDim > xNDim) {\n            diff = yNDim - xNDim;\n            const diffShape = [];\n            for (let i = 0; i < diff; ++i) {\n                diffShape.push(1);\n            }\n            x = x.reshape(x.shape.concat(diffShape));\n        }\n        else {\n            diff = 0;\n        }\n        let out;\n        if (x.shape.length === 2 && y.shape.length === 2) {\n            if (axesArray[0] === axesArray[1]) {\n                out = x.mul(y).sum(axesArray[0]);\n            }\n            else {\n                out = x.transpose([1, 0]).mul(y).sum(axesArray[1]);\n            }\n        }\n        else {\n            const adjX = axesArray[0] !== x.shape.length - 1;\n            const adjY = axesArray[1] === y.shape.length - 1;\n            out = x.matMul(y, adjX, adjY);\n        }\n        if (diff > 0) {\n            let idx;\n            if (xNDim > yNDim) {\n                idx = xNDim + yNDim - 3;\n            }\n            else {\n                idx = xNDim - 1;\n            }\n            const squeezeAxes = [];\n            for (let i = idx; i < idx + diff; ++i) {\n                squeezeAxes.push(i);\n            }\n            out = out.squeeze(squeezeAxes);\n        }\n        if (out.shape.length === 1) {\n            out = out.expandDims(1);\n        }\n        return out;\n    });\n}\nexport class Dot extends Merge {\n    constructor(args) {\n        super(args);\n        this.axes = args.axes;\n        this.normalize = args.normalize == null ? false : args.normalize;\n        this.supportsMasking = true;\n        this.reshapeRequired = false;\n    }\n    build(inputShape) {\n        tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n        const shape1 = inputShape[0];\n        const shape2 = inputShape[1];\n        if (shape1.length > 3 || shape2.length > 3) {\n            throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n        }\n        const axes = this.interpretAxes(shape1, shape2);\n        if (shape1[axes[0]] !== shape2[axes[1]]) {\n            throw new ValueError(`Dimension incompatibility: ` +\n                `${shape1[axes[0]]} !== ${shape2[axes[1]]}`);\n        }\n    }\n    mergeFunction(inputs) {\n        if (inputs.length !== 2) {\n            throw new ValueError('A `Dot` layer must be called on exactly 2 inputs, ' +\n                `but received ${inputs.length} input(s).`);\n        }\n        let x1 = inputs[0];\n        let x2 = inputs[1];\n        let axes;\n        if (!Array.isArray(this.axes)) {\n            axes = [\n                interpretAxis(this.axes, x1.shape.length),\n                interpretAxis(this.axes, x2.shape.length)\n            ];\n        }\n        else {\n            axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));\n        }\n        if (this.normalize) {\n            x1 = l2Normalize(x1, axes[0]);\n            x2 = l2Normalize(x2, axes[1]);\n        }\n        return batchDot(x1, x2, axes);\n    }\n    interpretAxes(shape1, shape2) {\n        let axes;\n        if (!Array.isArray(this.axes)) {\n            // `this.axes` is a single integer.\n            axes = [\n                interpretAxis(this.axes, shape1.length),\n                interpretAxis(this.axes, shape2.length)\n            ];\n        }\n        else {\n            // `this.axes` is an Array of integers.\n            axes = this.axes;\n        }\n        return axes;\n    }\n    computeOutputShape(inputShape) {\n        tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n        const shape1 = inputShape[0].slice();\n        const shape2 = inputShape[1].slice();\n        if (shape1.length > 3 || shape2.length > 3) {\n            throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n        }\n        const axes = this.interpretAxes(shape1, shape2);\n        shape1.splice(axes[0], 1);\n        shape2.splice(axes[1], 1);\n        shape2.splice(0, 1);\n        const outputShape = shape1.concat(shape2);\n        if (outputShape.length === 1) {\n            outputShape.push(1);\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        return null;\n    }\n    getConfig() {\n        const config = {\n            'axes': this.axes,\n            'normalize': this.normalize\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nDot.className = 'Dot';\nserialization.registerClass(Dot);\n// TODO(cais): Add functional interfaces for the merge layers.\n//# sourceMappingURL=merge.js.map"]},"metadata":{},"sourceType":"module"}