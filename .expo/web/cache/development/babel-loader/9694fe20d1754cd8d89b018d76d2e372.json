{"ast":null,"code":"import _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Add } from \"../kernel_names\";\nimport * as broadcast_util from \"../ops/broadcast_util\";\nimport { reshape } from \"../ops/reshape\";\nimport { sum } from \"../ops/sum\";\nexport var addGradConfig = {\n  kernelName: Add,\n  inputsToSave: ['a', 'b'],\n  gradFunc: function gradFunc(dy, saved) {\n    var _saved = _slicedToArray(saved, 2),\n        a = _saved[0],\n        b = _saved[1];\n\n    var outShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n\n    var derA = function derA() {\n      var res = dy;\n      var reduceAxes = broadcast_util.getReductionAxes(a.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n\n      return reshape(res, a.shape);\n    };\n\n    var derB = function derB() {\n      var res = dy;\n      var reduceAxes = broadcast_util.getReductionAxes(b.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n\n      return reshape(res, b.shape);\n    };\n\n    return {\n      a: derA,\n      b: derB\n    };\n  }\n};","map":{"version":3,"sources":["../../src/gradients/Add_grad.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,GAAR;AAEA,OAAO,KAAK,cAAZ;AACA,SAAQ,OAAR;AACA,SAAQ,GAAR;AAGA,OAAO,IAAM,aAAa,GAAe;EACvC,UAAU,EAAE,GAD2B;EAEvC,YAAY,EAAE,CAAC,GAAD,EAAM,GAAN,CAFyB;EAGvC,QAAQ,EAAE,kBAAC,EAAD,EAAa,KAAb,EAAgC;IACxC,4BAAe,KAAf;IAAA,IAAO,CAAP;IAAA,IAAU,CAAV;;IACA,IAAM,QAAQ,GACV,cAAc,CAAC,0BAAf,CAA0C,CAAC,CAAC,KAA5C,EAAmD,CAAC,CAAC,KAArD,CADJ;;IAGA,IAAM,IAAI,GAAG,SAAP,IAAO,GAAK;MAChB,IAAI,GAAG,GAAG,EAAV;MACA,IAAM,UAAU,GAAG,cAAc,CAAC,gBAAf,CAAgC,CAAC,CAAC,KAAlC,EAAyC,QAAzC,CAAnB;;MACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;QACzB,GAAG,GAAG,GAAG,CAAC,GAAD,EAAM,UAAN,CAAT;MACD;;MACD,OAAO,OAAO,CAAC,GAAD,EAAM,CAAC,CAAC,KAAR,CAAd;IACD,CAPD;;IAQA,IAAM,IAAI,GAAG,SAAP,IAAO,GAAK;MAChB,IAAI,GAAG,GAAG,EAAV;MACA,IAAM,UAAU,GAAG,cAAc,CAAC,gBAAf,CAAgC,CAAC,CAAC,KAAlC,EAAyC,QAAzC,CAAnB;;MACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;QACzB,GAAG,GAAG,GAAG,CAAC,GAAD,EAAM,UAAN,CAAT;MACD;;MACD,OAAO,OAAO,CAAC,GAAD,EAAM,CAAC,CAAC,KAAR,CAAd;IACD,CAPD;;IASA,OAAO;MAAC,CAAC,EAAE,IAAJ;MAAU,CAAC,EAAE;IAAb,CAAP;EACD;AA1BsC,CAAlC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Add } from '../kernel_names';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport { reshape } from '../ops/reshape';\nimport { sum } from '../ops/sum';\nexport const addGradConfig = {\n    kernelName: Add,\n    inputsToSave: ['a', 'b'],\n    gradFunc: (dy, saved) => {\n        const [a, b] = saved;\n        const outShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        const derA = () => {\n            let res = dy;\n            const reduceAxes = broadcast_util.getReductionAxes(a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = sum(res, reduceAxes);\n            }\n            return reshape(res, a.shape);\n        };\n        const derB = () => {\n            let res = dy;\n            const reduceAxes = broadcast_util.getReductionAxes(b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = sum(res, reduceAxes);\n            }\n            return reshape(res, b.shape);\n        };\n        return { a: derA, b: derB };\n    }\n};\n//# sourceMappingURL=Add_grad.js.map"]},"metadata":{},"sourceType":"module"}