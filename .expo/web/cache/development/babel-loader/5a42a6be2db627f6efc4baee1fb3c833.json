{"ast":null,"code":"import _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nimport _extends from \"@babel/runtime/helpers/extends\";\nimport _toConsumableArray from \"@babel/runtime/helpers/toConsumableArray\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport _get from \"@babel/runtime/helpers/get\";\nimport _inherits from \"@babel/runtime/helpers/inherits\";\nimport _possibleConstructorReturn from \"@babel/runtime/helpers/possibleConstructorReturn\";\nimport _getPrototypeOf from \"@babel/runtime/helpers/getPrototypeOf\";\n\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from \"../activations\";\nimport * as K from \"../backend/tfjs_backend\";\nimport { nameScope } from \"../common\";\nimport { getConstraint, serializeConstraint } from \"../constraints\";\nimport { InputSpec, SymbolicTensor } from \"../engine/topology\";\nimport { Layer } from \"../engine/topology\";\nimport { AttributeError, NotImplementedError, ValueError } from \"../errors\";\nimport { getInitializer, Initializer, Ones, serializeInitializer } from \"../initializers\";\nimport { getRegularizer, serializeRegularizer } from \"../regularizers\";\nimport { assertPositiveInteger } from \"../utils/generic_utils\";\nimport * as math_utils from \"../utils/math_utils\";\nimport { getExactlyOneShape, getExactlyOneTensor, isArrayOfShapes } from \"../utils/types_utils\";\nimport { batchGetValue, batchSetValue } from \"../variables\";\nimport { deserialize } from \"./serialization\";\nexport function standardizeArgs(inputs, initialState, constants, numConstants) {\n  if (Array.isArray(inputs)) {\n    if (initialState != null || constants != null) {\n      throw new ValueError('When inputs is an array, neither initialState or constants ' + 'should be provided');\n    }\n\n    if (numConstants != null) {\n      constants = inputs.slice(inputs.length - numConstants, inputs.length);\n      inputs = inputs.slice(0, inputs.length - numConstants);\n    }\n\n    if (inputs.length > 1) {\n      initialState = inputs.slice(1, inputs.length);\n    }\n\n    inputs = inputs[0];\n  }\n\n  function toListOrNull(x) {\n    if (x == null || Array.isArray(x)) {\n      return x;\n    } else {\n      return [x];\n    }\n  }\n\n  initialState = toListOrNull(initialState);\n  constants = toListOrNull(constants);\n  return {\n    inputs: inputs,\n    initialState: initialState,\n    constants: constants\n  };\n}\nexport function rnn(stepFunction, inputs, initialStates) {\n  var goBackwards = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var mask = arguments.length > 4 ? arguments[4] : undefined;\n  var constants = arguments.length > 5 ? arguments[5] : undefined;\n  var unroll = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : false;\n  var needPerStepOutputs = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : false;\n  return tfc.tidy(function () {\n    var ndim = inputs.shape.length;\n\n    if (ndim < 3) {\n      throw new ValueError(\"Input should be at least 3D, but is \" + ndim + \"D.\");\n    }\n\n    var axes = [1, 0].concat(math_utils.range(2, ndim));\n    inputs = tfc.transpose(inputs, axes);\n\n    if (constants != null) {\n      throw new NotImplementedError('The rnn() functoin of the deeplearn.js backend does not support ' + 'constants yet.');\n    }\n\n    if (unroll) {\n      console.warn('Backend rnn(): the unroll = true option is not applicable to the ' + 'imperative deeplearn.js backend.');\n    }\n\n    if (mask != null) {\n      mask = mask.asType('bool').asType('float32');\n\n      if (mask.rank === ndim - 1) {\n        mask = tfc.expandDims(mask, -1);\n      }\n\n      mask = tfc.transpose(mask, axes);\n    }\n\n    if (goBackwards) {\n      inputs = tfc.reverse(inputs, 0);\n\n      if (mask != null) {\n        mask = tfc.reverse(mask, 0);\n      }\n    }\n\n    var perStepOutputs = [];\n    var lastOutput;\n    var states = initialStates;\n    var timeSteps = inputs.shape[0];\n    var perStepInputs = tfc.unstack(inputs);\n    var perStepMasks;\n\n    if (mask != null) {\n      perStepMasks = tfc.unstack(mask);\n    }\n\n    var _loop = function _loop(t) {\n      var currentInput = perStepInputs[t];\n      var stepOutputs = tfc.tidy(function () {\n        return stepFunction(currentInput, states);\n      });\n\n      if (mask == null) {\n        lastOutput = stepOutputs[0];\n        states = stepOutputs[1];\n      } else {\n        var maskedOutputs = tfc.tidy(function () {\n          var stepMask = perStepMasks[t];\n          var negStepMask = tfc.onesLike(stepMask).sub(stepMask);\n          var output = stepOutputs[0].mul(stepMask).add(states[0].mul(negStepMask));\n          var newStates = states.map(function (state, i) {\n            return stepOutputs[1][i].mul(stepMask).add(state.mul(negStepMask));\n          });\n          return {\n            output: output,\n            newStates: newStates\n          };\n        });\n        lastOutput = maskedOutputs.output;\n        states = maskedOutputs.newStates;\n      }\n\n      if (needPerStepOutputs) {\n        perStepOutputs.push(lastOutput);\n      }\n    };\n\n    for (var t = 0; t < timeSteps; ++t) {\n      _loop(t);\n    }\n\n    var outputs;\n\n    if (needPerStepOutputs) {\n      var axis = 1;\n      outputs = tfc.stack(perStepOutputs, axis);\n    }\n\n    return [lastOutput, outputs, states];\n  });\n}\nexport var RNN = function (_Layer) {\n  _inherits(RNN, _Layer);\n\n  var _super = _createSuper(RNN);\n\n  function RNN(args) {\n    var _this;\n\n    _classCallCheck(this, RNN);\n\n    _this = _super.call(this, args);\n    var cell;\n\n    if (args.cell == null) {\n      throw new ValueError('cell property is missing for the constructor of RNN.');\n    } else if (Array.isArray(args.cell)) {\n      cell = new StackedRNNCells({\n        cells: args.cell\n      });\n    } else {\n      cell = args.cell;\n    }\n\n    if (cell.stateSize == null) {\n      throw new ValueError('The RNN cell should have an attribute `stateSize` (tuple of ' + 'integers, one integer per RNN state).');\n    }\n\n    _this.cell = cell;\n    _this.returnSequences = args.returnSequences == null ? false : args.returnSequences;\n    _this.returnState = args.returnState == null ? false : args.returnState;\n    _this.goBackwards = args.goBackwards == null ? false : args.goBackwards;\n    _this._stateful = args.stateful == null ? false : args.stateful;\n    _this.unroll = args.unroll == null ? false : args.unroll;\n    _this.supportsMasking = true;\n    _this.inputSpec = [new InputSpec({\n      ndim: 3\n    })];\n    _this.stateSpec = null;\n    _this.states_ = null;\n    _this.numConstants = null;\n    _this.keptStates = [];\n    return _this;\n  }\n\n  _createClass(RNN, [{\n    key: \"getStates\",\n    value: function getStates() {\n      if (this.states_ == null) {\n        var numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n        return math_utils.range(0, numStates).map(function (x) {\n          return null;\n        });\n      } else {\n        return this.states_;\n      }\n    }\n  }, {\n    key: \"setStates\",\n    value: function setStates(states) {\n      this.states_ = states;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      if (isArrayOfShapes(inputShape)) {\n        inputShape = inputShape[0];\n      }\n\n      inputShape = inputShape;\n      var stateSize = this.cell.stateSize;\n\n      if (!Array.isArray(stateSize)) {\n        stateSize = [stateSize];\n      }\n\n      var outputDim = stateSize[0];\n      var outputShape;\n\n      if (this.returnSequences) {\n        outputShape = [inputShape[0], inputShape[1], outputDim];\n      } else {\n        outputShape = [inputShape[0], outputDim];\n      }\n\n      if (this.returnState) {\n        var stateShape = [];\n\n        for (var _iterator = _createForOfIteratorHelperLoose(stateSize), _step; !(_step = _iterator()).done;) {\n          var dim = _step.value;\n          stateShape.push([inputShape[0], dim]);\n        }\n\n        return [outputShape].concat(stateShape);\n      } else {\n        return outputShape;\n      }\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      var _this2 = this;\n\n      return tfc.tidy(function () {\n        if (Array.isArray(mask)) {\n          mask = mask[0];\n        }\n\n        var outputMask = _this2.returnSequences ? mask : null;\n\n        if (_this2.returnState) {\n          var stateMask = _this2.states.map(function (s) {\n            return null;\n          });\n\n          return [outputMask].concat(stateMask);\n        } else {\n          return outputMask;\n        }\n      });\n    }\n  }, {\n    key: \"states\",\n    get: function get() {\n      if (this.states_ == null) {\n        var numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n        var output = [];\n\n        for (var i = 0; i < numStates; ++i) {\n          output.push(null);\n        }\n\n        return output;\n      } else {\n        return this.states_;\n      }\n    },\n    set: function set(s) {\n      this.states_ = s;\n    }\n  }, {\n    key: \"build\",\n    value: function build(inputShape) {\n      var constantShape = null;\n\n      if (this.numConstants != null) {\n        throw new NotImplementedError('Constants support is not implemented in RNN yet.');\n      }\n\n      if (isArrayOfShapes(inputShape)) {\n        inputShape = inputShape[0];\n      }\n\n      inputShape = inputShape;\n      var batchSize = this.stateful ? inputShape[0] : null;\n      var inputDim = inputShape.slice(2);\n      this.inputSpec[0] = new InputSpec({\n        shape: [batchSize, null].concat(_toConsumableArray(inputDim))\n      });\n      var stepInputShape = [inputShape[0]].concat(inputShape.slice(2));\n\n      if (constantShape != null) {\n        throw new NotImplementedError('Constants support is not implemented in RNN yet.');\n      } else {\n        this.cell.build(stepInputShape);\n      }\n\n      var stateSize;\n\n      if (Array.isArray(this.cell.stateSize)) {\n        stateSize = this.cell.stateSize;\n      } else {\n        stateSize = [this.cell.stateSize];\n      }\n\n      if (this.stateSpec != null) {\n        if (!util.arraysEqual(this.stateSpec.map(function (spec) {\n          return spec.shape[spec.shape.length - 1];\n        }), stateSize)) {\n          throw new ValueError(\"An initialState was passed that is not compatible with \" + (\"cell.stateSize. Received stateSpec=\" + this.stateSpec + \"; \") + (\"However cell.stateSize is \" + this.cell.stateSize));\n        }\n      } else {\n        this.stateSpec = stateSize.map(function (dim) {\n          return new InputSpec({\n            shape: [null, dim]\n          });\n        });\n      }\n\n      if (this.stateful) {\n        this.resetStates();\n      }\n    }\n  }, {\n    key: \"resetStates\",\n    value: function resetStates(states) {\n      var _this3 = this;\n\n      var training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      tidy(function () {\n        if (!_this3.stateful) {\n          throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n        }\n\n        var batchSize = _this3.inputSpec[0].shape[0];\n\n        if (batchSize == null) {\n          throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n        }\n\n        if (_this3.states_ == null) {\n          if (Array.isArray(_this3.cell.stateSize)) {\n            _this3.states_ = _this3.cell.stateSize.map(function (dim) {\n              return tfc.zeros([batchSize, dim]);\n            });\n          } else {\n            _this3.states_ = [tfc.zeros([batchSize, _this3.cell.stateSize])];\n          }\n        } else if (states == null) {\n          tfc.dispose(_this3.states_);\n\n          if (_this3.keptStates != null) {\n            tfc.dispose(_this3.keptStates);\n            _this3.keptStates = [];\n          }\n\n          if (Array.isArray(_this3.cell.stateSize)) {\n            _this3.states_ = _this3.cell.stateSize.map(function (dim) {\n              return tfc.zeros([batchSize, dim]);\n            });\n          } else {\n            _this3.states_[0] = tfc.zeros([batchSize, _this3.cell.stateSize]);\n          }\n        } else {\n          if (!Array.isArray(states)) {\n            states = [states];\n          }\n\n          if (states.length !== _this3.states_.length) {\n            throw new ValueError(\"Layer \" + _this3.name + \" expects \" + _this3.states_.length + \" state(s), \" + (\"but it received \" + states.length + \" state value(s). Input \") + (\"received: \" + states));\n          }\n\n          if (training === true) {\n            _this3.keptStates.push(_this3.states_.slice());\n          } else {\n            tfc.dispose(_this3.states_);\n          }\n\n          for (var index = 0; index < _this3.states_.length; ++index) {\n            var value = states[index];\n            var dim = Array.isArray(_this3.cell.stateSize) ? _this3.cell.stateSize[index] : _this3.cell.stateSize;\n            var expectedShape = [batchSize, dim];\n\n            if (!util.arraysEqual(value.shape, expectedShape)) {\n              throw new ValueError(\"State \" + index + \" is incompatible with layer \" + _this3.name + \": \" + (\"expected shape=\" + expectedShape + \", received shape=\" + value.shape));\n            }\n\n            _this3.states_[index] = value;\n          }\n        }\n\n        _this3.states_ = _this3.states_.map(function (state) {\n          return tfc.keep(state.clone());\n        });\n      });\n    }\n  }, {\n    key: \"apply\",\n    value: function apply(inputs, kwargs) {\n      var initialState = kwargs == null ? null : kwargs['initialState'];\n      var constants = kwargs == null ? null : kwargs['constants'];\n\n      if (kwargs == null) {\n        kwargs = {};\n      }\n\n      var standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);\n      inputs = standardized.inputs;\n      initialState = standardized.initialState;\n      constants = standardized.constants;\n      var additionalInputs = [];\n      var additionalSpecs = [];\n\n      if (initialState != null) {\n        kwargs['initialState'] = initialState;\n        additionalInputs = additionalInputs.concat(initialState);\n        this.stateSpec = [];\n\n        for (var _iterator2 = _createForOfIteratorHelperLoose(initialState), _step2; !(_step2 = _iterator2()).done;) {\n          var state = _step2.value;\n          this.stateSpec.push(new InputSpec({\n            shape: state.shape\n          }));\n        }\n\n        additionalSpecs = additionalSpecs.concat(this.stateSpec);\n      }\n\n      if (constants != null) {\n        kwargs['constants'] = constants;\n        additionalInputs = additionalInputs.concat(constants);\n        this.numConstants = constants.length;\n      }\n\n      var isTensor = additionalInputs[0] instanceof SymbolicTensor;\n\n      if (isTensor) {\n        var fullInput = [inputs].concat(additionalInputs);\n        var fullInputSpec = this.inputSpec.concat(additionalSpecs);\n        var originalInputSpec = this.inputSpec;\n        this.inputSpec = fullInputSpec;\n\n        var output = _get(_getPrototypeOf(RNN.prototype), \"apply\", this).call(this, fullInput, kwargs);\n\n        this.inputSpec = originalInputSpec;\n        return output;\n      } else {\n        return _get(_getPrototypeOf(RNN.prototype), \"apply\", this).call(this, inputs, kwargs);\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this4 = this;\n\n      return tidy(function () {\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        inputs = getExactlyOneTensor(inputs);\n\n        if (initialState == null) {\n          if (_this4.stateful) {\n            initialState = _this4.states_;\n          } else {\n            initialState = _this4.getInitialState(inputs);\n          }\n        }\n\n        var numStates = Array.isArray(_this4.cell.stateSize) ? _this4.cell.stateSize.length : 1;\n\n        if (initialState.length !== numStates) {\n          throw new ValueError(\"RNN Layer has \" + numStates + \" state(s) but was passed \" + (initialState.length + \" initial state(s).\"));\n        }\n\n        if (_this4.unroll) {\n          console.warn('Ignoring unroll = true for RNN layer, due to imperative backend.');\n        }\n\n        var cellCallKwargs = {\n          training: training\n        };\n\n        var step = function step(inputs, states) {\n          var outputs = _this4.cell.call([inputs].concat(states), cellCallKwargs);\n\n          return [outputs[0], outputs.slice(1)];\n        };\n\n        var rnnOutputs = rnn(step, inputs, initialState, _this4.goBackwards, mask, null, _this4.unroll, _this4.returnSequences);\n        var lastOutput = rnnOutputs[0];\n        var outputs = rnnOutputs[1];\n        var states = rnnOutputs[2];\n\n        if (_this4.stateful) {\n          _this4.resetStates(states, training);\n        }\n\n        var output = _this4.returnSequences ? outputs : lastOutput;\n\n        if (_this4.returnState) {\n          return [output].concat(states);\n        } else {\n          return output;\n        }\n      });\n    }\n  }, {\n    key: \"getInitialState\",\n    value: function getInitialState(inputs) {\n      var _this5 = this;\n\n      return tidy(function () {\n        var initialState = tfc.zeros(inputs.shape);\n        initialState = tfc.sum(initialState, [1, 2]);\n        initialState = K.expandDims(initialState);\n\n        if (Array.isArray(_this5.cell.stateSize)) {\n          return _this5.cell.stateSize.map(function (dim) {\n            return dim > 1 ? K.tile(initialState, [1, dim]) : initialState;\n          });\n        } else {\n          return _this5.cell.stateSize > 1 ? [K.tile(initialState, [1, _this5.cell.stateSize])] : [initialState];\n        }\n      });\n    }\n  }, {\n    key: \"trainableWeights\",\n    get: function get() {\n      if (!this.trainable) {\n        return [];\n      }\n\n      return this.cell.trainableWeights;\n    }\n  }, {\n    key: \"nonTrainableWeights\",\n    get: function get() {\n      if (!this.trainable) {\n        return this.cell.weights;\n      }\n\n      return this.cell.nonTrainableWeights;\n    }\n  }, {\n    key: \"setFastWeightInitDuringBuild\",\n    value: function setFastWeightInitDuringBuild(value) {\n      _get(_getPrototypeOf(RNN.prototype), \"setFastWeightInitDuringBuild\", this).call(this, value);\n\n      if (this.cell != null) {\n        this.cell.setFastWeightInitDuringBuild(value);\n      }\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(RNN.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        returnSequences: this.returnSequences,\n        returnState: this.returnState,\n        goBackwards: this.goBackwards,\n        stateful: this.stateful,\n        unroll: this.unroll\n      };\n\n      if (this.numConstants != null) {\n        config['numConstants'] = this.numConstants;\n      }\n\n      var cellConfig = this.cell.getConfig();\n\n      if (this.getClassName() === RNN.className) {\n        config['cell'] = {\n          'className': this.cell.getClassName(),\n          'config': cellConfig\n        };\n      }\n\n      return _extends({}, cellConfig, baseConfig, config);\n    }\n  }], [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      var customObjects = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n      var cellConfig = config['cell'];\n      var cell = deserialize(cellConfig, customObjects);\n      return new cls(_extends(config, {\n        cell: cell\n      }));\n    }\n  }]);\n\n  return RNN;\n}(Layer);\nRNN.className = 'RNN';\nserialization.registerClass(RNN);\nexport var RNNCell = function (_Layer2) {\n  _inherits(RNNCell, _Layer2);\n\n  var _super2 = _createSuper(RNNCell);\n\n  function RNNCell() {\n    _classCallCheck(this, RNNCell);\n\n    return _super2.apply(this, arguments);\n  }\n\n  return _createClass(RNNCell);\n}(Layer);\nexport var SimpleRNNCell = function (_RNNCell) {\n  _inherits(SimpleRNNCell, _RNNCell);\n\n  var _super3 = _createSuper(SimpleRNNCell);\n\n  function SimpleRNNCell(args) {\n    var _this6;\n\n    _classCallCheck(this, SimpleRNNCell);\n\n    _this6 = _super3.call(this, args);\n    _this6.DEFAULT_ACTIVATION = 'tanh';\n    _this6.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this6.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n    _this6.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    _this6.units = args.units;\n    assertPositiveInteger(_this6.units, \"units\");\n    _this6.activation = getActivation(args.activation == null ? _this6.DEFAULT_ACTIVATION : args.activation);\n    _this6.useBias = args.useBias == null ? true : args.useBias;\n    _this6.kernelInitializer = getInitializer(args.kernelInitializer || _this6.DEFAULT_KERNEL_INITIALIZER);\n    _this6.recurrentInitializer = getInitializer(args.recurrentInitializer || _this6.DEFAULT_RECURRENT_INITIALIZER);\n    _this6.biasInitializer = getInitializer(args.biasInitializer || _this6.DEFAULT_BIAS_INITIALIZER);\n    _this6.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    _this6.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    _this6.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this6.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this6.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    _this6.biasConstraint = getConstraint(args.biasConstraint);\n    _this6.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    _this6.recurrentDropout = math_utils.min([1, math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])]);\n    _this6.stateSize = _this6.units;\n    _this6.dropoutMask = null;\n    _this6.recurrentDropoutMask = null;\n    return _this6;\n  }\n\n  _createClass(SimpleRNNCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      this.kernel = this.addWeight('kernel', [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      } else {\n        this.bias = null;\n      }\n\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this7 = this;\n\n      return tidy(function () {\n        inputs = inputs;\n\n        if (inputs.length !== 2) {\n          throw new ValueError(\"SimpleRNNCell expects 2 input Tensors, got \" + inputs.length + \".\");\n        }\n\n        var prevOutput = inputs[1];\n        inputs = inputs[0];\n        var training = kwargs['training'] == null ? false : kwargs['training'];\n\n        if (0 < _this7.dropout && _this7.dropout < 1 && _this7.dropoutMask == null) {\n          _this7.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(inputs);\n            },\n            rate: _this7.dropout,\n            training: training\n          });\n        }\n\n        if (0 < _this7.recurrentDropout && _this7.recurrentDropout < 1 && _this7.recurrentDropoutMask == null) {\n          _this7.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(prevOutput);\n            },\n            rate: _this7.recurrentDropout,\n            training: training\n          });\n        }\n\n        var h;\n        var dpMask = _this7.dropoutMask;\n        var recDpMask = _this7.recurrentDropoutMask;\n\n        if (dpMask != null) {\n          h = K.dot(tfc.mul(inputs, dpMask), _this7.kernel.read());\n        } else {\n          h = K.dot(inputs, _this7.kernel.read());\n        }\n\n        if (_this7.bias != null) {\n          h = K.biasAdd(h, _this7.bias.read());\n        }\n\n        if (recDpMask != null) {\n          prevOutput = tfc.mul(prevOutput, recDpMask);\n        }\n\n        var output = tfc.add(h, K.dot(prevOutput, _this7.recurrentKernel.read()));\n\n        if (_this7.activation != null) {\n          output = _this7.activation.apply(output);\n        }\n\n        return [output, output];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(SimpleRNNCell.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        units: this.units,\n        activation: serializeActivation(this.activation),\n        useBias: this.useBias,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint),\n        recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n        biasConstraint: serializeConstraint(this.biasConstraint),\n        dropout: this.dropout,\n        recurrentDropout: this.recurrentDropout\n      };\n      return _extends({}, baseConfig, config);\n    }\n  }]);\n\n  return SimpleRNNCell;\n}(RNNCell);\nSimpleRNNCell.className = 'SimpleRNNCell';\nserialization.registerClass(SimpleRNNCell);\nexport var SimpleRNN = function (_RNN) {\n  _inherits(SimpleRNN, _RNN);\n\n  var _super4 = _createSuper(SimpleRNN);\n\n  function SimpleRNN(args) {\n    _classCallCheck(this, SimpleRNN);\n\n    args.cell = new SimpleRNNCell(args);\n    return _super4.call(this, args);\n  }\n\n  _createClass(SimpleRNN, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this8 = this;\n\n      return tidy(function () {\n        if (_this8.cell.dropoutMask != null) {\n          tfc.dispose(_this8.cell.dropoutMask);\n          _this8.cell.dropoutMask = null;\n        }\n\n        if (_this8.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this8.cell.recurrentDropoutMask);\n          _this8.cell.recurrentDropoutMask = null;\n        }\n\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(SimpleRNN.prototype), \"call\", _this8).call(_this8, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }], [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config);\n    }\n  }]);\n\n  return SimpleRNN;\n}(RNN);\nSimpleRNN.className = 'SimpleRNN';\nserialization.registerClass(SimpleRNN);\nexport var GRUCell = function (_RNNCell2) {\n  _inherits(GRUCell, _RNNCell2);\n\n  var _super5 = _createSuper(GRUCell);\n\n  function GRUCell(args) {\n    var _this9;\n\n    _classCallCheck(this, GRUCell);\n\n    _this9 = _super5.call(this, args);\n    _this9.DEFAULT_ACTIVATION = 'tanh';\n    _this9.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n    _this9.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this9.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n    _this9.DEFAULT_BIAS_INITIALIZER = 'zeros';\n\n    if (args.resetAfter) {\n      throw new ValueError(\"GRUCell does not support reset_after parameter set to true.\");\n    }\n\n    _this9.units = args.units;\n    assertPositiveInteger(_this9.units, 'units');\n    _this9.activation = getActivation(args.activation === undefined ? _this9.DEFAULT_ACTIVATION : args.activation);\n    _this9.recurrentActivation = getActivation(args.recurrentActivation === undefined ? _this9.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);\n    _this9.useBias = args.useBias == null ? true : args.useBias;\n    _this9.kernelInitializer = getInitializer(args.kernelInitializer || _this9.DEFAULT_KERNEL_INITIALIZER);\n    _this9.recurrentInitializer = getInitializer(args.recurrentInitializer || _this9.DEFAULT_RECURRENT_INITIALIZER);\n    _this9.biasInitializer = getInitializer(args.biasInitializer || _this9.DEFAULT_BIAS_INITIALIZER);\n    _this9.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    _this9.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    _this9.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this9.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this9.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    _this9.biasConstraint = getConstraint(args.biasConstraint);\n    _this9.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    _this9.recurrentDropout = math_utils.min([1, math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])]);\n    _this9.implementation = args.implementation;\n    _this9.stateSize = _this9.units;\n    _this9.dropoutMask = null;\n    _this9.recurrentDropoutMask = null;\n    return _this9;\n  }\n\n  _createClass(GRUCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var inputDim = inputShape[inputShape.length - 1];\n      this.kernel = this.addWeight('kernel', [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      } else {\n        this.bias = null;\n      }\n\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this10 = this;\n\n      return tidy(function () {\n        inputs = inputs;\n\n        if (inputs.length !== 2) {\n          throw new ValueError(\"GRUCell expects 2 input Tensors (inputs, h, c), got \" + (inputs.length + \".\"));\n        }\n\n        var training = kwargs['training'] == null ? false : kwargs['training'];\n        var hTMinus1 = inputs[1];\n        inputs = inputs[0];\n\n        if (0 < _this10.dropout && _this10.dropout < 1 && _this10.dropoutMask == null) {\n          _this10.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(inputs);\n            },\n            rate: _this10.dropout,\n            training: training,\n            count: 3\n          });\n        }\n\n        if (0 < _this10.recurrentDropout && _this10.recurrentDropout < 1 && _this10.recurrentDropoutMask == null) {\n          _this10.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(hTMinus1);\n            },\n            rate: _this10.recurrentDropout,\n            training: training,\n            count: 3\n          });\n        }\n\n        var dpMask = _this10.dropoutMask;\n        var recDpMask = _this10.recurrentDropoutMask;\n        var z;\n        var r;\n        var hh;\n\n        if (0 < _this10.dropout && _this10.dropout < 1) {\n          inputs = tfc.mul(inputs, dpMask[0]);\n        }\n\n        var matrixX = K.dot(inputs, _this10.kernel.read());\n\n        if (_this10.useBias) {\n          matrixX = K.biasAdd(matrixX, _this10.bias.read());\n        }\n\n        if (0 < _this10.recurrentDropout && _this10.recurrentDropout < 1) {\n          hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n        }\n\n        var recurrentKernelValue = _this10.recurrentKernel.read();\n\n        var _tfc$split = tfc.split(recurrentKernelValue, [2 * _this10.units, _this10.units], recurrentKernelValue.rank - 1),\n            _tfc$split2 = _slicedToArray(_tfc$split, 2),\n            rk1 = _tfc$split2[0],\n            rk2 = _tfc$split2[1];\n\n        var matrixInner = K.dot(hTMinus1, rk1);\n\n        var _tfc$split3 = tfc.split(matrixX, 3, matrixX.rank - 1),\n            _tfc$split4 = _slicedToArray(_tfc$split3, 3),\n            xZ = _tfc$split4[0],\n            xR = _tfc$split4[1],\n            xH = _tfc$split4[2];\n\n        var _tfc$split5 = tfc.split(matrixInner, 2, matrixInner.rank - 1),\n            _tfc$split6 = _slicedToArray(_tfc$split5, 2),\n            recurrentZ = _tfc$split6[0],\n            recurrentR = _tfc$split6[1];\n\n        z = _this10.recurrentActivation.apply(tfc.add(xZ, recurrentZ));\n        r = _this10.recurrentActivation.apply(tfc.add(xR, recurrentR));\n        var recurrentH = K.dot(tfc.mul(r, hTMinus1), rk2);\n        hh = _this10.activation.apply(tfc.add(xH, recurrentH));\n        var h = tfc.add(tfc.mul(z, hTMinus1), tfc.mul(tfc.add(1, tfc.neg(z)), hh));\n        return [h, h];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(GRUCell.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        units: this.units,\n        activation: serializeActivation(this.activation),\n        recurrentActivation: serializeActivation(this.recurrentActivation),\n        useBias: this.useBias,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint),\n        recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n        biasConstraint: serializeConstraint(this.biasConstraint),\n        dropout: this.dropout,\n        recurrentDropout: this.recurrentDropout,\n        implementation: this.implementation,\n        resetAfter: false\n      };\n      return _extends({}, baseConfig, config);\n    }\n  }]);\n\n  return GRUCell;\n}(RNNCell);\nGRUCell.className = 'GRUCell';\nserialization.registerClass(GRUCell);\nexport var GRU = function (_RNN2) {\n  _inherits(GRU, _RNN2);\n\n  var _super6 = _createSuper(GRU);\n\n  function GRU(args) {\n    _classCallCheck(this, GRU);\n\n    if (args.implementation === 0) {\n      console.warn('`implementation=0` has been deprecated, and now defaults to ' + '`implementation=1`. Please update your layer call.');\n    }\n\n    args.cell = new GRUCell(args);\n    return _super6.call(this, args);\n  }\n\n  _createClass(GRU, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this11 = this;\n\n      return tidy(function () {\n        if (_this11.cell.dropoutMask != null) {\n          tfc.dispose(_this11.cell.dropoutMask);\n          _this11.cell.dropoutMask = null;\n        }\n\n        if (_this11.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this11.cell.recurrentDropoutMask);\n          _this11.cell.recurrentDropoutMask = null;\n        }\n\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(GRU.prototype), \"call\", _this11).call(_this11, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }], [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      if (config['implmentation'] === 0) {\n        config['implementation'] = 1;\n      }\n\n      return new cls(config);\n    }\n  }]);\n\n  return GRU;\n}(RNN);\nGRU.className = 'GRU';\nserialization.registerClass(GRU);\nexport var LSTMCell = function (_RNNCell3) {\n  _inherits(LSTMCell, _RNNCell3);\n\n  var _super7 = _createSuper(LSTMCell);\n\n  function LSTMCell(args) {\n    var _this12;\n\n    _classCallCheck(this, LSTMCell);\n\n    _this12 = _super7.call(this, args);\n    _this12.DEFAULT_ACTIVATION = 'tanh';\n    _this12.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n    _this12.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this12.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n    _this12.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    _this12.units = args.units;\n    assertPositiveInteger(_this12.units, 'units');\n    _this12.activation = getActivation(args.activation === undefined ? _this12.DEFAULT_ACTIVATION : args.activation);\n    _this12.recurrentActivation = getActivation(args.recurrentActivation === undefined ? _this12.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);\n    _this12.useBias = args.useBias == null ? true : args.useBias;\n    _this12.kernelInitializer = getInitializer(args.kernelInitializer || _this12.DEFAULT_KERNEL_INITIALIZER);\n    _this12.recurrentInitializer = getInitializer(args.recurrentInitializer || _this12.DEFAULT_RECURRENT_INITIALIZER);\n    _this12.biasInitializer = getInitializer(args.biasInitializer || _this12.DEFAULT_BIAS_INITIALIZER);\n    _this12.unitForgetBias = args.unitForgetBias;\n    _this12.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    _this12.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    _this12.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this12.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this12.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    _this12.biasConstraint = getConstraint(args.biasConstraint);\n    _this12.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    _this12.recurrentDropout = math_utils.min([1, math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])]);\n    _this12.implementation = args.implementation;\n    _this12.stateSize = [_this12.units, _this12.units];\n    _this12.dropoutMask = null;\n    _this12.recurrentDropoutMask = null;\n    return _this12;\n  }\n\n  _createClass(LSTMCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      var _a;\n\n      inputShape = getExactlyOneShape(inputShape);\n      var inputDim = inputShape[inputShape.length - 1];\n      this.kernel = this.addWeight('kernel', [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n      var biasInitializer;\n\n      if (this.useBias) {\n        if (this.unitForgetBias) {\n          var capturedBiasInit = this.biasInitializer;\n          var capturedUnits = this.units;\n          biasInitializer = new (_a = function (_Initializer) {\n            _inherits(CustomInit, _Initializer);\n\n            var _super8 = _createSuper(CustomInit);\n\n            function CustomInit() {\n              _classCallCheck(this, CustomInit);\n\n              return _super8.apply(this, arguments);\n            }\n\n            _createClass(CustomInit, [{\n              key: \"apply\",\n              value: function apply(shape, dtype) {\n                var bI = capturedBiasInit.apply([capturedUnits]);\n                var bF = new Ones().apply([capturedUnits]);\n                var bCAndH = capturedBiasInit.apply([capturedUnits * 2]);\n                return K.concatAlongFirstAxis(K.concatAlongFirstAxis(bI, bF), bCAndH);\n              }\n            }]);\n\n            return CustomInit;\n          }(Initializer), _a.className = 'CustomInit', _a)();\n        } else {\n          biasInitializer = this.biasInitializer;\n        }\n\n        this.bias = this.addWeight('bias', [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      } else {\n        this.bias = null;\n      }\n\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this13 = this;\n\n      return tidy(function () {\n        var training = kwargs['training'] == null ? false : kwargs['training'];\n        inputs = inputs;\n\n        if (inputs.length !== 3) {\n          throw new ValueError(\"LSTMCell expects 3 input Tensors (inputs, h, c), got \" + (inputs.length + \".\"));\n        }\n\n        var hTMinus1 = inputs[1];\n        var cTMinus1 = inputs[2];\n        inputs = inputs[0];\n\n        if (0 < _this13.dropout && _this13.dropout < 1 && _this13.dropoutMask == null) {\n          _this13.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(inputs);\n            },\n            rate: _this13.dropout,\n            training: training,\n            count: 4\n          });\n        }\n\n        if (0 < _this13.recurrentDropout && _this13.recurrentDropout < 1 && _this13.recurrentDropoutMask == null) {\n          _this13.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(hTMinus1);\n            },\n            rate: _this13.recurrentDropout,\n            training: training,\n            count: 4\n          });\n        }\n\n        var dpMask = _this13.dropoutMask;\n        var recDpMask = _this13.recurrentDropoutMask;\n        var i;\n        var f;\n        var c;\n        var o;\n\n        if (0 < _this13.dropout && _this13.dropout < 1) {\n          inputs = tfc.mul(inputs, dpMask[0]);\n        }\n\n        var z = K.dot(inputs, _this13.kernel.read());\n\n        if (0 < _this13.recurrentDropout && _this13.recurrentDropout < 1) {\n          hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n        }\n\n        z = tfc.add(z, K.dot(hTMinus1, _this13.recurrentKernel.read()));\n\n        if (_this13.useBias) {\n          z = K.biasAdd(z, _this13.bias.read());\n        }\n\n        var _tfc$split7 = tfc.split(z, 4, z.rank - 1),\n            _tfc$split8 = _slicedToArray(_tfc$split7, 4),\n            z0 = _tfc$split8[0],\n            z1 = _tfc$split8[1],\n            z2 = _tfc$split8[2],\n            z3 = _tfc$split8[3];\n\n        i = _this13.recurrentActivation.apply(z0);\n        f = _this13.recurrentActivation.apply(z1);\n        c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, _this13.activation.apply(z2)));\n        o = _this13.recurrentActivation.apply(z3);\n        var h = tfc.mul(o, _this13.activation.apply(c));\n        return [h, h, c];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(LSTMCell.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        units: this.units,\n        activation: serializeActivation(this.activation),\n        recurrentActivation: serializeActivation(this.recurrentActivation),\n        useBias: this.useBias,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        unitForgetBias: this.unitForgetBias,\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint),\n        recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n        biasConstraint: serializeConstraint(this.biasConstraint),\n        dropout: this.dropout,\n        recurrentDropout: this.recurrentDropout,\n        implementation: this.implementation\n      };\n      return _extends({}, baseConfig, config);\n    }\n  }]);\n\n  return LSTMCell;\n}(RNNCell);\nLSTMCell.className = 'LSTMCell';\nserialization.registerClass(LSTMCell);\nexport var LSTM = function (_RNN3) {\n  _inherits(LSTM, _RNN3);\n\n  var _super9 = _createSuper(LSTM);\n\n  function LSTM(args) {\n    _classCallCheck(this, LSTM);\n\n    if (args.implementation === 0) {\n      console.warn('`implementation=0` has been deprecated, and now defaults to ' + '`implementation=1`. Please update your layer call.');\n    }\n\n    args.cell = new LSTMCell(args);\n    return _super9.call(this, args);\n  }\n\n  _createClass(LSTM, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this14 = this;\n\n      return tidy(function () {\n        if (_this14.cell.dropoutMask != null) {\n          tfc.dispose(_this14.cell.dropoutMask);\n          _this14.cell.dropoutMask = null;\n        }\n\n        if (_this14.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this14.cell.recurrentDropoutMask);\n          _this14.cell.recurrentDropoutMask = null;\n        }\n\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(LSTM.prototype), \"call\", _this14).call(_this14, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }], [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      if (config['implmentation'] === 0) {\n        config['implementation'] = 1;\n      }\n\n      return new cls(config);\n    }\n  }]);\n\n  return LSTM;\n}(RNN);\nLSTM.className = 'LSTM';\nserialization.registerClass(LSTM);\nexport var StackedRNNCells = function (_RNNCell4) {\n  _inherits(StackedRNNCells, _RNNCell4);\n\n  var _super10 = _createSuper(StackedRNNCells);\n\n  function StackedRNNCells(args) {\n    var _this15;\n\n    _classCallCheck(this, StackedRNNCells);\n\n    _this15 = _super10.call(this, args);\n    _this15.cells = args.cells;\n    return _this15;\n  }\n\n  _createClass(StackedRNNCells, [{\n    key: \"stateSize\",\n    get: function get() {\n      var stateSize = [];\n\n      for (var _iterator3 = _createForOfIteratorHelperLoose(this.cells.slice().reverse()), _step3; !(_step3 = _iterator3()).done;) {\n        var cell = _step3.value;\n\n        if (Array.isArray(cell.stateSize)) {\n          stateSize.push.apply(stateSize, _toConsumableArray(cell.stateSize));\n        } else {\n          stateSize.push(cell.stateSize);\n        }\n      }\n\n      return stateSize;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this16 = this;\n\n      return tidy(function () {\n        inputs = inputs;\n        var states = inputs.slice(1);\n        var nestedStates = [];\n\n        for (var _iterator4 = _createForOfIteratorHelperLoose(_this16.cells.slice().reverse()), _step4; !(_step4 = _iterator4()).done;) {\n          var cell = _step4.value;\n\n          if (Array.isArray(cell.stateSize)) {\n            nestedStates.push(states.splice(0, cell.stateSize.length));\n          } else {\n            nestedStates.push(states.splice(0, 1));\n          }\n        }\n\n        nestedStates.reverse();\n        var newNestedStates = [];\n        var callInputs;\n\n        for (var i = 0; i < _this16.cells.length; ++i) {\n          var _cell = _this16.cells[i];\n          states = nestedStates[i];\n\n          if (i === 0) {\n            callInputs = [inputs[0]].concat(states);\n          } else {\n            callInputs = [callInputs[0]].concat(states);\n          }\n\n          callInputs = _cell.call(callInputs, kwargs);\n          newNestedStates.push(callInputs.slice(1));\n        }\n\n        states = [];\n\n        for (var _iterator5 = _createForOfIteratorHelperLoose(newNestedStates.slice().reverse()), _step5; !(_step5 = _iterator5()).done;) {\n          var _states;\n\n          var cellStates = _step5.value;\n\n          (_states = states).push.apply(_states, _toConsumableArray(cellStates));\n        }\n\n        return [callInputs[0]].concat(states);\n      });\n    }\n  }, {\n    key: \"build\",\n    value: function build(inputShape) {\n      if (isArrayOfShapes(inputShape)) {\n        inputShape = inputShape[0];\n      }\n\n      inputShape = inputShape;\n      var outputDim;\n      this.cells.forEach(function (cell, i) {\n        nameScope(\"RNNCell_\" + i, function () {\n          cell.build(inputShape);\n\n          if (Array.isArray(cell.stateSize)) {\n            outputDim = cell.stateSize[0];\n          } else {\n            outputDim = cell.stateSize;\n          }\n\n          inputShape = [inputShape[0], outputDim];\n        });\n      });\n      this.built = true;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(StackedRNNCells.prototype), \"getConfig\", this).call(this);\n\n      var getCellConfig = function getCellConfig(cell) {\n        return {\n          'className': cell.getClassName(),\n          'config': cell.getConfig()\n        };\n      };\n\n      var cellConfigs = this.cells.map(getCellConfig);\n      var config = {\n        'cells': cellConfigs\n      };\n      return _extends({}, baseConfig, config);\n    }\n  }, {\n    key: \"trainableWeights\",\n    get: function get() {\n      if (!this.trainable) {\n        return [];\n      }\n\n      var weights = [];\n\n      for (var _iterator6 = _createForOfIteratorHelperLoose(this.cells), _step6; !(_step6 = _iterator6()).done;) {\n        var cell = _step6.value;\n        weights.push.apply(weights, _toConsumableArray(cell.trainableWeights));\n      }\n\n      return weights;\n    }\n  }, {\n    key: \"nonTrainableWeights\",\n    get: function get() {\n      var weights = [];\n\n      for (var _iterator7 = _createForOfIteratorHelperLoose(this.cells), _step7; !(_step7 = _iterator7()).done;) {\n        var cell = _step7.value;\n        weights.push.apply(weights, _toConsumableArray(cell.nonTrainableWeights));\n      }\n\n      if (!this.trainable) {\n        var trainableWeights = [];\n\n        for (var _iterator8 = _createForOfIteratorHelperLoose(this.cells), _step8; !(_step8 = _iterator8()).done;) {\n          var _cell2 = _step8.value;\n          trainableWeights.push.apply(trainableWeights, _toConsumableArray(_cell2.trainableWeights));\n        }\n\n        return trainableWeights.concat(weights);\n      }\n\n      return weights;\n    }\n  }, {\n    key: \"getWeights\",\n    value: function getWeights() {\n      var weights = [];\n\n      for (var _iterator9 = _createForOfIteratorHelperLoose(this.cells), _step9; !(_step9 = _iterator9()).done;) {\n        var cell = _step9.value;\n        weights.push.apply(weights, _toConsumableArray(cell.weights));\n      }\n\n      return batchGetValue(weights);\n    }\n  }, {\n    key: \"setWeights\",\n    value: function setWeights(weights) {\n      var tuples = [];\n\n      for (var _iterator10 = _createForOfIteratorHelperLoose(this.cells), _step10; !(_step10 = _iterator10()).done;) {\n        var cell = _step10.value;\n        var numParams = cell.weights.length;\n        var inputWeights = weights.splice(numParams);\n\n        for (var i = 0; i < cell.weights.length; ++i) {\n          tuples.push([cell.weights[i], inputWeights[i]]);\n        }\n      }\n\n      batchSetValue(tuples);\n    }\n  }], [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      var customObjects = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n      var cells = [];\n\n      for (var _iterator11 = _createForOfIteratorHelperLoose(config['cells']), _step11; !(_step11 = _iterator11()).done;) {\n        var cellConfig = _step11.value;\n        cells.push(deserialize(cellConfig, customObjects));\n      }\n\n      return new cls({\n        cells: cells\n      });\n    }\n  }]);\n\n  return StackedRNNCells;\n}(RNNCell);\nStackedRNNCells.className = 'StackedRNNCells';\nserialization.registerClass(StackedRNNCells);\nexport function generateDropoutMask(args) {\n  var ones = args.ones,\n      rate = args.rate,\n      _args$training = args.training,\n      training = _args$training === void 0 ? false : _args$training,\n      _args$count = args.count,\n      count = _args$count === void 0 ? 1 : _args$count;\n\n  var droppedInputs = function droppedInputs() {\n    return K.dropout(ones(), rate);\n  };\n\n  var createMask = function createMask() {\n    return K.inTrainPhase(droppedInputs, ones, training);\n  };\n\n  if (!count || count <= 1) {\n    return tfc.keep(createMask().clone());\n  }\n\n  var masks = Array(count).fill(undefined).map(createMask);\n  return masks.map(function (m) {\n    return tfc.keep(m.clone());\n  });\n}","map":{"version":3,"sources":["../../src/layers/recurrent.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;AAQG;AAMH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAkB,aAAlB,EAAyC,IAAzC,EAA+C,IAA/C,QAA0D,uBAA1D;AAEA,SAAoB,aAApB,EAAmC,mBAAnC;AACA,OAAO,KAAK,CAAZ;AACA,SAAQ,SAAR;AACA,SAA0C,aAA1C,EAAyD,mBAAzD;AACA,SAAQ,SAAR,EAAmB,cAAnB;AACA,SAAQ,KAAR;AACA,SAAQ,cAAR,EAAwB,mBAAxB,EAA6C,UAA7C;AACA,SAAQ,cAAR,EAAwB,WAAxB,EAA4D,IAA5D,EAAkE,oBAAlE;AAGA,SAAQ,cAAR,EAA4D,oBAA5D;AAEA,SAAQ,qBAAR;AACA,OAAO,KAAK,UAAZ;AACA,SAAQ,kBAAR,EAA4B,mBAA5B,EAAiD,eAAjD;AACA,SAAQ,aAAR,EAAuB,aAAvB;AACA,SAAQ,WAAR;AAwBA,OAAM,SAAU,eAAV,CACF,MADE,EAEF,YAFE,EAGF,SAHE,EAIF,YAJE,EAImB;EAKvB,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,IAAI,YAAY,IAAI,IAAhB,IAAwB,SAAS,IAAI,IAAzC,EAA+C;MAC7C,MAAM,IAAI,UAAJ,CACF,gEACA,oBAFE,CAAN;IAGD;;IACD,IAAI,YAAY,IAAI,IAApB,EAA0B;MACxB,SAAS,GAAG,MAAM,CAAC,KAAP,CAAa,MAAM,CAAC,MAAP,GAAgB,YAA7B,EAA2C,MAAM,CAAC,MAAlD,CAAZ;MACA,MAAM,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAP,GAAgB,YAAhC,CAAT;IACD;;IACD,IAAI,MAAM,CAAC,MAAP,GAAgB,CAApB,EAAuB;MACrB,YAAY,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAvB,CAAf;IACD;;IACD,MAAM,GAAG,MAAM,CAAC,CAAD,CAAf;EACD;;EAED,SAAS,YAAT,CAAsB,CAAtB,EACsC;IACpC,IAAI,CAAC,IAAI,IAAL,IAAa,KAAK,CAAC,OAAN,CAAc,CAAd,CAAjB,EAAmC;MACjC,OAAO,CAAP;IACD,CAFD,MAEO;MACL,OAAO,CAAC,CAAD,CAAP;IACD;EACF;;EAED,YAAY,GAAG,YAAY,CAAC,YAAD,CAA3B;EACA,SAAS,GAAG,YAAY,CAAC,SAAD,CAAxB;EAEA,OAAO;IAAC,MAAM,EAAN,MAAD;IAAS,YAAY,EAAZ,YAAT;IAAuB,SAAS,EAAT;EAAvB,CAAP;AACD;AA6CD,OAAM,SAAU,GAAV,CACF,YADE,EAC6B,MAD7B,EAC6C,aAD7C,EAGwB;EAAA,IAD1B,WAC0B,uEADZ,KACY;EAAA,IADL,IACK;EAAA,IADU,SACV;EAAA,IADgC,MAChC,uEADyC,KACzC;EAAA,IAA1B,kBAA0B,uEAAL,KAAK;EAC5B,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;IACnB,IAAM,IAAI,GAAG,MAAM,CAAC,KAAP,CAAa,MAA1B;;IACA,IAAI,IAAI,GAAG,CAAX,EAAc;MACZ,MAAM,IAAI,UAAJ,0CAAsD,IAAtD,QAAN;IACD;;IAID,IAAM,IAAI,GAAG,CAAC,CAAD,EAAI,CAAJ,EAAO,MAAP,CAAc,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,IAApB,CAAd,CAAb;IACA,MAAM,GAAG,GAAG,CAAC,SAAJ,CAAc,MAAd,EAAsB,IAAtB,CAAT;;IAEA,IAAI,SAAS,IAAI,IAAjB,EAAuB;MACrB,MAAM,IAAI,mBAAJ,CACF,qEACA,gBAFE,CAAN;IAGD;;IAGD,IAAI,MAAJ,EAAY;MACV,OAAO,CAAC,IAAR,CACI,sEACA,kCAFJ;IAGD;;IAED,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,IAAI,GAAG,IAAI,CAAC,MAAL,CAAY,MAAZ,EAAoB,MAApB,CAA2B,SAA3B,CAAP;;MACA,IAAI,IAAI,CAAC,IAAL,KAAc,IAAI,GAAG,CAAzB,EAA4B;QAC1B,IAAI,GAAG,GAAG,CAAC,UAAJ,CAAe,IAAf,EAAqB,CAAC,CAAtB,CAAP;MACD;;MACD,IAAI,GAAG,GAAG,CAAC,SAAJ,CAAc,IAAd,EAAoB,IAApB,CAAP;IACD;;IAED,IAAI,WAAJ,EAAiB;MACf,MAAM,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,EAAoB,CAApB,CAAT;;MACA,IAAI,IAAI,IAAI,IAAZ,EAAkB;QAChB,IAAI,GAAG,GAAG,CAAC,OAAJ,CAAY,IAAZ,EAAkB,CAAlB,CAAP;MACD;IACF;;IAYD,IAAM,cAAc,GAAa,EAAjC;IACA,IAAI,UAAJ;IACA,IAAI,MAAM,GAAG,aAAb;IACA,IAAM,SAAS,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,CAAlB;IACA,IAAM,aAAa,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,CAAtB;IACA,IAAI,YAAJ;;IACA,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,YAAY,GAAG,GAAG,CAAC,OAAJ,CAAY,IAAZ,CAAf;IACD;;IAzDkB,2BA2DV,CA3DU;MA4DjB,IAAM,YAAY,GAAG,aAAa,CAAC,CAAD,CAAlC;MACA,IAAM,WAAW,GAAG,GAAG,CAAC,IAAJ,CAAS;QAAA,OAAM,YAAY,CAAC,YAAD,EAAe,MAAf,CAAlB;MAAA,CAAT,CAApB;;MAEA,IAAI,IAAI,IAAI,IAAZ,EAAkB;QAChB,UAAU,GAAG,WAAW,CAAC,CAAD,CAAxB;QACA,MAAM,GAAG,WAAW,CAAC,CAAD,CAApB;MACD,CAHD,MAGO;QACL,IAAM,aAAa,GAAG,GAAG,CAAC,IAAJ,CAAS,YAAK;UAClC,IAAM,QAAQ,GAAG,YAAY,CAAC,CAAD,CAA7B;UACA,IAAM,WAAW,GAAG,GAAG,CAAC,QAAJ,CAAa,QAAb,EAAuB,GAAvB,CAA2B,QAA3B,CAApB;UAEA,IAAM,MAAM,GACR,WAAW,CAAC,CAAD,CAAX,CAAe,GAAf,CAAmB,QAAnB,EAA6B,GAA7B,CAAiC,MAAM,CAAC,CAAD,CAAN,CAAU,GAAV,CAAc,WAAd,CAAjC,CADJ;UAEA,IAAM,SAAS,GAAG,MAAM,CAAC,GAAP,CAAW,UAAC,KAAD,EAAQ,CAAR,EAAa;YACxC,OAAO,WAAW,CAAC,CAAD,CAAX,CAAe,CAAf,EAAkB,GAAlB,CAAsB,QAAtB,EAAgC,GAAhC,CAAoC,KAAK,CAAC,GAAN,CAAU,WAAV,CAApC,CAAP;UACD,CAFiB,CAAlB;UAGA,OAAO;YAAC,MAAM,EAAN,MAAD;YAAS,SAAS,EAAT;UAAT,CAAP;QACD,CAVqB,CAAtB;QAWA,UAAU,GAAG,aAAa,CAAC,MAA3B;QACA,MAAM,GAAG,aAAa,CAAC,SAAvB;MACD;;MAED,IAAI,kBAAJ,EAAwB;QACtB,cAAc,CAAC,IAAf,CAAoB,UAApB;MACD;IApFgB;;IA2DnB,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAApB,EAA+B,EAAE,CAAjC,EAAoC;MAAA,MAA3B,CAA2B;IA0BnC;;IACD,IAAI,OAAJ;;IACA,IAAI,kBAAJ,EAAwB;MACtB,IAAM,IAAI,GAAG,CAAb;MACA,OAAO,GAAG,GAAG,CAAC,KAAJ,CAAU,cAAV,EAA0B,IAA1B,CAAV;IACD;;IACD,OAAO,CAAC,UAAD,EAAa,OAAb,EAAsB,MAAtB,CAAP;EACD,CA5FM,CAAP;AA6FD;AAuGD,WAAa,GAAb;EAAA;;EAAA;;EAqBE,aAAY,IAAZ,EAA8B;IAAA;;IAAA;;IAC5B,0BAAM,IAAN;IACA,IAAI,IAAJ;;IACA,IAAI,IAAI,CAAC,IAAL,IAAa,IAAjB,EAAuB;MACrB,MAAM,IAAI,UAAJ,CACF,sDADE,CAAN;IAED,CAHD,MAGO,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAJ,EAA8B;MACnC,IAAI,GAAG,IAAI,eAAJ,CAAoB;QAAC,KAAK,EAAE,IAAI,CAAC;MAAb,CAApB,CAAP;IACD,CAFM,MAEA;MACL,IAAI,GAAG,IAAI,CAAC,IAAZ;IACD;;IACD,IAAI,IAAI,CAAC,SAAL,IAAkB,IAAtB,EAA4B;MAC1B,MAAM,IAAI,UAAJ,CACF,iEACA,uCAFE,CAAN;IAGD;;IACD,MAAK,IAAL,GAAY,IAAZ;IACA,MAAK,eAAL,GACI,IAAI,CAAC,eAAL,IAAwB,IAAxB,GAA+B,KAA/B,GAAuC,IAAI,CAAC,eADhD;IAEA,MAAK,WAAL,GAAmB,IAAI,CAAC,WAAL,IAAoB,IAApB,GAA2B,KAA3B,GAAmC,IAAI,CAAC,WAA3D;IACA,MAAK,WAAL,GAAmB,IAAI,CAAC,WAAL,IAAoB,IAApB,GAA2B,KAA3B,GAAmC,IAAI,CAAC,WAA3D;IACA,MAAK,SAAL,GAAiB,IAAI,CAAC,QAAL,IAAiB,IAAjB,GAAwB,KAAxB,GAAgC,IAAI,CAAC,QAAtD;IACA,MAAK,MAAL,GAAc,IAAI,CAAC,MAAL,IAAe,IAAf,GAAsB,KAAtB,GAA8B,IAAI,CAAC,MAAjD;IAEA,MAAK,eAAL,GAAuB,IAAvB;IACA,MAAK,SAAL,GAAiB,CAAC,IAAI,SAAJ,CAAc;MAAC,IAAI,EAAE;IAAP,CAAd,CAAD,CAAjB;IACA,MAAK,SAAL,GAAiB,IAAjB;IACA,MAAK,OAAL,GAAe,IAAf;IAEA,MAAK,YAAL,GAAoB,IAApB;IAIA,MAAK,UAAL,GAAkB,EAAlB;IAjC4B;EAkC7B;;EAvDH;IAAA;IAAA,OA2DE,qBAAS;MACP,IAAI,KAAK,OAAL,IAAgB,IAApB,EAA0B;QACxB,IAAM,SAAS,GACX,KAAK,CAAC,OAAN,CAAc,KAAK,IAAL,CAAU,SAAxB,IAAqC,KAAK,IAAL,CAAU,SAAV,CAAoB,MAAzD,GAAkE,CADtE;QAEA,OAAO,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,SAApB,EAA+B,GAA/B,CAAmC,UAAA,CAAC;UAAA,OAAI,IAAJ;QAAA,CAApC,CAAP;MACD,CAJD,MAIO;QACL,OAAO,KAAK,OAAZ;MACD;IACF;EAnEH;IAAA;IAAA,OAuEE,mBAAU,MAAV,EAA0B;MACxB,KAAK,OAAL,GAAe,MAAf;IACD;EAzEH;IAAA;IAAA,OA2EE,4BAAmB,UAAnB,EAA4C;MAC1C,IAAI,eAAe,CAAC,UAAD,CAAnB,EAAiC;QAC/B,UAAU,GAAI,UAAsB,CAAC,CAAD,CAApC;MACD;;MACD,UAAU,GAAG,UAAb;MAGA,IAAI,SAAS,GAAG,KAAK,IAAL,CAAU,SAA1B;;MACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,SAAd,CAAL,EAA+B;QAC7B,SAAS,GAAG,CAAC,SAAD,CAAZ;MACD;;MACD,IAAM,SAAS,GAAG,SAAS,CAAC,CAAD,CAA3B;MACA,IAAI,WAAJ;;MACA,IAAI,KAAK,eAAT,EAA0B;QACxB,WAAW,GAAG,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,UAAU,CAAC,CAAD,CAA1B,EAA+B,SAA/B,CAAd;MACD,CAFD,MAEO;QACL,WAAW,GAAG,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,SAAhB,CAAd;MACD;;MAED,IAAI,KAAK,WAAT,EAAsB;QACpB,IAAM,UAAU,GAAY,EAA5B;;QACA,qDAAkB,SAAlB,wCAA6B;UAAA,IAAlB,GAAkB;UAC3B,UAAU,CAAC,IAAX,CAAgB,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,GAAhB,CAAhB;QACD;;QACD,OAAO,CAAC,WAAD,EAAc,MAAd,CAAqB,UAArB,CAAP;MACD,CAND,MAMO;QACL,OAAO,WAAP;MACD;IACF;EAvGH;IAAA;IAAA,OAyGE,qBAAY,MAAZ,EAAqC,IAArC,EAA2D;MAAA;;MAEzD,OAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;QACnB,IAAI,KAAK,CAAC,OAAN,CAAc,IAAd,CAAJ,EAAyB;UACvB,IAAI,GAAG,IAAI,CAAC,CAAD,CAAX;QACD;;QACD,IAAM,UAAU,GAAG,MAAI,CAAC,eAAL,GAAuB,IAAvB,GAA8B,IAAjD;;QAEA,IAAI,MAAI,CAAC,WAAT,EAAsB;UACpB,IAAM,SAAS,GAAG,MAAI,CAAC,MAAL,CAAY,GAAZ,CAAgB,UAAA,CAAC;YAAA,OAAI,IAAJ;UAAA,CAAjB,CAAlB;;UACA,OAAO,CAAC,UAAD,EAAa,MAAb,CAAoB,SAApB,CAAP;QACD,CAHD,MAGO;UACL,OAAO,UAAP;QACD;MACF,CAZM,CAAP;IAaD;EAxHH;IAAA;IAAA,KAgIE,eAAU;MACR,IAAI,KAAK,OAAL,IAAgB,IAApB,EAA0B;QACxB,IAAM,SAAS,GACX,KAAK,CAAC,OAAN,CAAc,KAAK,IAAL,CAAU,SAAxB,IAAqC,KAAK,IAAL,CAAU,SAAV,CAAoB,MAAzD,GAAkE,CADtE;QAEA,IAAM,MAAM,GAAa,EAAzB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAApB,EAA+B,EAAE,CAAjC,EAAoC;UAClC,MAAM,CAAC,IAAP,CAAY,IAAZ;QACD;;QACD,OAAO,MAAP;MACD,CARD,MAQO;QACL,OAAO,KAAK,OAAZ;MACD;IACF,CA5IH;IAAA,KA8IE,aAAW,CAAX,EAAsB;MACpB,KAAK,OAAL,GAAe,CAAf;IACD;EAhJH;IAAA;IAAA,OAkJS,eAAM,UAAN,EAA+B;MAGpC,IAAM,aAAa,GAAY,IAA/B;;MACA,IAAI,KAAK,YAAL,IAAqB,IAAzB,EAA+B;QAC7B,MAAM,IAAI,mBAAJ,CACF,kDADE,CAAN;MAED;;MAED,IAAI,eAAe,CAAC,UAAD,CAAnB,EAAiC;QAC/B,UAAU,GAAI,UAAsB,CAAC,CAAD,CAApC;MACD;;MACD,UAAU,GAAG,UAAb;MAEA,IAAM,SAAS,GAAW,KAAK,QAAL,GAAgB,UAAU,CAAC,CAAD,CAA1B,GAAgC,IAA1D;MACA,IAAM,QAAQ,GAAG,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAjB;MACA,KAAK,SAAL,CAAe,CAAf,IAAoB,IAAI,SAAJ,CAAc;QAAC,KAAK,GAAG,SAAH,EAAc,IAAd,4BAAuB,QAAvB;MAAN,CAAd,CAApB;MAIA,IAAM,cAAc,GAAG,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,MAAhB,CAAuB,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAvB,CAAvB;;MACA,IAAI,aAAa,IAAI,IAArB,EAA2B;QACzB,MAAM,IAAI,mBAAJ,CACF,kDADE,CAAN;MAED,CAHD,MAGO;QACL,KAAK,IAAL,CAAU,KAAV,CAAgB,cAAhB;MACD;;MAGD,IAAI,SAAJ;;MACA,IAAI,KAAK,CAAC,OAAN,CAAc,KAAK,IAAL,CAAU,SAAxB,CAAJ,EAAwC;QACtC,SAAS,GAAG,KAAK,IAAL,CAAU,SAAtB;MACD,CAFD,MAEO;QACL,SAAS,GAAG,CAAC,KAAK,IAAL,CAAU,SAAX,CAAZ;MACD;;MAED,IAAI,KAAK,SAAL,IAAkB,IAAtB,EAA4B;QAC1B,IAAI,CAAC,IAAI,CAAC,WAAL,CACG,KAAK,SAAL,CAAe,GAAf,CAAmB,UAAA,IAAI;UAAA,OAAI,IAAI,CAAC,KAAL,CAAW,IAAI,CAAC,KAAL,CAAW,MAAX,GAAoB,CAA/B,CAAJ;QAAA,CAAvB,CADH,EAEG,SAFH,CAAL,EAEoB;UAClB,MAAM,IAAI,UAAJ,CACF,qGACsC,KAAK,SAD3C,2CAE6B,KAAK,IAAL,CAAU,SAFvC,CADE,CAAN;QAID;MACF,CATD,MASO;QACL,KAAK,SAAL,GACI,SAAS,CAAC,GAAV,CAAc,UAAA,GAAG;UAAA,OAAI,IAAI,SAAJ,CAAc;YAAC,KAAK,EAAE,CAAC,IAAD,EAAO,GAAP;UAAR,CAAd,CAAJ;QAAA,CAAjB,CADJ;MAED;;MACD,IAAI,KAAK,QAAT,EAAmB;QACjB,KAAK,WAAL;MACD;IACF;EAtMH;IAAA;IAAA,OAyNE,qBAAY,MAAZ,EAAsD;MAAA;;MAAA,IAAhB,QAAgB,uEAAL,KAAK;MACpD,IAAI,CAAC,YAAK;QACR,IAAI,CAAC,MAAI,CAAC,QAAV,EAAoB;UAClB,MAAM,IAAI,cAAJ,CACF,iEADE,CAAN;QAED;;QACD,IAAM,SAAS,GAAG,MAAI,CAAC,SAAL,CAAe,CAAf,EAAkB,KAAlB,CAAwB,CAAxB,CAAlB;;QACA,IAAI,SAAS,IAAI,IAAjB,EAAuB;UACrB,MAAM,IAAI,UAAJ,CACF,qEACA,0CADA,GAEA,2DAFA,GAGA,2DAHA,GAIA,2DAJA,GAKA,oDANE,CAAN;QAOD;;QAED,IAAI,MAAI,CAAC,OAAL,IAAgB,IAApB,EAA0B;UACxB,IAAI,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,CAAJ,EAAwC;YACtC,MAAI,CAAC,OAAL,GACI,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,GAApB,CAAwB,UAAA,GAAG;cAAA,OAAI,GAAG,CAAC,KAAJ,CAAU,CAAC,SAAD,EAAY,GAAZ,CAAV,CAAJ;YAAA,CAA3B,CADJ;UAED,CAHD,MAGO;YACL,MAAI,CAAC,OAAL,GAAe,CAAC,GAAG,CAAC,KAAJ,CAAU,CAAC,SAAD,EAAY,MAAI,CAAC,IAAL,CAAU,SAAtB,CAAV,CAAD,CAAf;UACD;QACF,CAPD,MAOO,IAAI,MAAM,IAAI,IAAd,EAAoB;UAEzB,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,OAAjB;;UAEA,IAAI,MAAI,CAAC,UAAL,IAAmB,IAAvB,EAA6B;YAC3B,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,UAAjB;YACA,MAAI,CAAC,UAAL,GAAkB,EAAlB;UACD;;UAED,IAAI,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,CAAJ,EAAwC;YACtC,MAAI,CAAC,OAAL,GACI,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,GAApB,CAAwB,UAAA,GAAG;cAAA,OAAI,GAAG,CAAC,KAAJ,CAAU,CAAC,SAAD,EAAY,GAAZ,CAAV,CAAJ;YAAA,CAA3B,CADJ;UAED,CAHD,MAGO;YACL,MAAI,CAAC,OAAL,CAAa,CAAb,IAAkB,GAAG,CAAC,KAAJ,CAAU,CAAC,SAAD,EAAY,MAAI,CAAC,IAAL,CAAU,SAAtB,CAAV,CAAlB;UACD;QACF,CAfM,MAeA;UACL,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;YAC1B,MAAM,GAAG,CAAC,MAAD,CAAT;UACD;;UACD,IAAI,MAAM,CAAC,MAAP,KAAkB,MAAI,CAAC,OAAL,CAAa,MAAnC,EAA2C;YACzC,MAAM,IAAI,UAAJ,CACF,WAAS,MAAI,CAAC,IAAd,iBAA8B,MAAI,CAAC,OAAL,CAAa,MAA3C,yCACmB,MAAM,CAAC,MAD1B,gDAEa,MAFb,CADE,CAAN;UAID;;UAED,IAAI,QAAQ,KAAK,IAAjB,EAAuB;YAKrB,MAAI,CAAC,UAAL,CAAgB,IAAhB,CAAqB,MAAI,CAAC,OAAL,CAAa,KAAb,EAArB;UACD,CAND,MAMO;YACL,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,OAAjB;UACD;;UAED,KAAK,IAAI,KAAK,GAAG,CAAjB,EAAoB,KAAK,GAAG,MAAI,CAAC,OAAL,CAAa,MAAzC,EAAiD,EAAE,KAAnD,EAA0D;YACxD,IAAM,KAAK,GAAG,MAAM,CAAC,KAAD,CAApB;YACA,IAAM,GAAG,GAAG,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,IACR,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,KAApB,CADQ,GAER,MAAI,CAAC,IAAL,CAAU,SAFd;YAGA,IAAM,aAAa,GAAG,CAAC,SAAD,EAAY,GAAZ,CAAtB;;YACA,IAAI,CAAC,IAAI,CAAC,WAAL,CAAiB,KAAK,CAAC,KAAvB,EAA8B,aAA9B,CAAL,EAAmD;cACjD,MAAM,IAAI,UAAJ,CACF,WAAS,KAAT,oCAA6C,MAAI,CAAC,IAAlD,+BACkB,aADlB,yBAEI,KAAK,CAAC,KAFV,CADE,CAAN;YAID;;YACD,MAAI,CAAC,OAAL,CAAa,KAAb,IAAsB,KAAtB;UACD;QACF;;QACD,MAAI,CAAC,OAAL,GAAe,MAAI,CAAC,OAAL,CAAa,GAAb,CAAiB,UAAA,KAAK;UAAA,OAAI,GAAG,CAAC,IAAJ,CAAS,KAAK,CAAC,KAAN,EAAT,CAAJ;QAAA,CAAtB,CAAf;MACD,CA3EG,CAAJ;IA4ED;EAtSH;IAAA;IAAA,OAwSE,eACI,MADJ,EAEI,MAFJ,EAEmB;MAEjB,IAAI,YAAY,GACZ,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;MAEA,IAAI,SAAS,GACT,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,WAAD,CADlC;;MAEA,IAAI,MAAM,IAAI,IAAd,EAAoB;QAClB,MAAM,GAAG,EAAT;MACD;;MAED,IAAM,YAAY,GACd,eAAe,CAAC,MAAD,EAAS,YAAT,EAAuB,SAAvB,EAAkC,KAAK,YAAvC,CADnB;MAEA,MAAM,GAAG,YAAY,CAAC,MAAtB;MACA,YAAY,GAAG,YAAY,CAAC,YAA5B;MACA,SAAS,GAAG,YAAY,CAAC,SAAzB;MAMA,IAAI,gBAAgB,GAAiC,EAArD;MACA,IAAI,eAAe,GAAgB,EAAnC;;MACA,IAAI,YAAY,IAAI,IAApB,EAA0B;QACxB,MAAM,CAAC,cAAD,CAAN,GAAyB,YAAzB;QACA,gBAAgB,GAAG,gBAAgB,CAAC,MAAjB,CAAwB,YAAxB,CAAnB;QACA,KAAK,SAAL,GAAiB,EAAjB;;QACA,sDAAoB,YAApB,2CAAkC;UAAA,IAAvB,KAAuB;UAChC,KAAK,SAAL,CAAe,IAAf,CAAoB,IAAI,SAAJ,CAAc;YAAC,KAAK,EAAE,KAAK,CAAC;UAAd,CAAd,CAApB;QACD;;QAID,eAAe,GAAG,eAAe,CAAC,MAAhB,CAAuB,KAAK,SAA5B,CAAlB;MACD;;MACD,IAAI,SAAS,IAAI,IAAjB,EAAuB;QACrB,MAAM,CAAC,WAAD,CAAN,GAAsB,SAAtB;QACA,gBAAgB,GAAG,gBAAgB,CAAC,MAAjB,CAAwB,SAAxB,CAAnB;QAEA,KAAK,YAAL,GAAoB,SAAS,CAAC,MAA9B;MACD;;MAED,IAAM,QAAQ,GAAG,gBAAgB,CAAC,CAAD,CAAhB,YAA+B,cAAhD;;MACA,IAAI,QAAJ,EAAc;QAEZ,IAAM,SAAS,GACX,CAAC,MAAD,EAAS,MAAT,CAAgB,gBAAhB,CADJ;QAEA,IAAM,aAAa,GAAG,KAAK,SAAL,CAAe,MAAf,CAAsB,eAAtB,CAAtB;QAEA,IAAM,iBAAiB,GAAG,KAAK,SAA/B;QACA,KAAK,SAAL,GAAiB,aAAjB;;QACA,IAAM,MAAM,kEAAe,SAAf,EAA0B,MAA1B,CAAZ;;QACA,KAAK,SAAL,GAAiB,iBAAjB;QACA,OAAO,MAAP;MACD,CAXD,MAWO;QACL,sEAAmB,MAAnB,EAA2B,MAA3B;MACD;IACF;EAlWH;IAAA;IAAA,OAqWE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAI1C,OAAO,IAAI,CAAC,YAAK;QACf,IAAM,IAAI,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,MAAD,CAA3C;QACA,IAAM,QAAQ,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,UAAD,CAA/C;QACA,IAAI,YAAY,GACZ,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;QAGA,MAAM,GAAG,mBAAmB,CAAC,MAAD,CAA5B;;QACA,IAAI,YAAY,IAAI,IAApB,EAA0B;UACxB,IAAI,MAAI,CAAC,QAAT,EAAmB;YACjB,YAAY,GAAG,MAAI,CAAC,OAApB;UACD,CAFD,MAEO;YACL,YAAY,GAAG,MAAI,CAAC,eAAL,CAAqB,MAArB,CAAf;UACD;QACF;;QAED,IAAM,SAAS,GACX,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,IAAqC,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,MAAzD,GAAkE,CADtE;;QAEA,IAAI,YAAY,CAAC,MAAb,KAAwB,SAA5B,EAAuC;UACrC,MAAM,IAAI,UAAJ,CACF,mBAAiB,SAAjB,kCACG,YAAY,CAAC,MADhB,wBADE,CAAN;QAGD;;QACD,IAAI,MAAI,CAAC,MAAT,EAAiB;UACf,OAAO,CAAC,IAAR,CACI,kEADJ;QAED;;QAED,IAAM,cAAc,GAAW;UAAC,QAAQ,EAAR;QAAD,CAA/B;;QAGA,IAAM,IAAI,GAAG,SAAP,IAAO,CAAC,MAAD,EAAiB,MAAjB,EAAqC;UAGhD,IAAM,OAAO,GACT,MAAI,CAAC,IAAL,CAAU,IAAV,CAAe,CAAC,MAAD,EAAS,MAAT,CAAgB,MAAhB,CAAf,EAAwC,cAAxC,CADJ;;UAGA,OAAO,CAAC,OAAO,CAAC,CAAD,CAAR,EAAa,OAAO,CAAC,KAAR,CAAc,CAAd,CAAb,CAAP;QACD,CAPD;;QAWA,IAAM,UAAU,GACZ,GAAG,CAAC,IAAD,EAAO,MAAP,EAAe,YAAf,EAA6B,MAAI,CAAC,WAAlC,EAA+C,IAA/C,EAAqD,IAArD,EACC,MAAI,CAAC,MADN,EACc,MAAI,CAAC,eADnB,CADP;QAGA,IAAM,UAAU,GAAG,UAAU,CAAC,CAAD,CAA7B;QACA,IAAM,OAAO,GAAG,UAAU,CAAC,CAAD,CAA1B;QACA,IAAM,MAAM,GAAG,UAAU,CAAC,CAAD,CAAzB;;QAEA,IAAI,MAAI,CAAC,QAAT,EAAmB;UACjB,MAAI,CAAC,WAAL,CAAiB,MAAjB,EAAyB,QAAzB;QACD;;QAED,IAAM,MAAM,GAAG,MAAI,CAAC,eAAL,GAAuB,OAAvB,GAAiC,UAAhD;;QAIA,IAAI,MAAI,CAAC,WAAT,EAAsB;UACpB,OAAO,CAAC,MAAD,EAAS,MAAT,CAAgB,MAAhB,CAAP;QACD,CAFD,MAEO;UACL,OAAO,MAAP;QACD;MACF,CA7DU,CAAX;IA8DD;EAvaH;IAAA;IAAA,OAyaE,yBAAgB,MAAhB,EAA8B;MAAA;;MAC5B,OAAO,IAAI,CAAC,YAAK;QAGf,IAAI,YAAY,GAAG,GAAG,CAAC,KAAJ,CAAU,MAAM,CAAC,KAAjB,CAAnB;QAEA,YAAY,GAAG,GAAG,CAAC,GAAJ,CAAQ,YAAR,EAAsB,CAAC,CAAD,EAAI,CAAJ,CAAtB,CAAf;QACA,YAAY,GAAG,CAAC,CAAC,UAAF,CAAa,YAAb,CAAf;;QAEA,IAAI,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,CAAJ,EAAwC;UACtC,OAAO,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,GAApB,CACH,UAAA,GAAG;YAAA,OAAI,GAAG,GAAG,CAAN,GAAU,CAAC,CAAC,IAAF,CAAO,YAAP,EAAqB,CAAC,CAAD,EAAI,GAAJ,CAArB,CAAV,GAA2C,YAA/C;UAAA,CADA,CAAP;QAED,CAHD,MAGO;UACL,OAAO,MAAI,CAAC,IAAL,CAAU,SAAV,GAAsB,CAAtB,GACH,CAAC,CAAC,CAAC,IAAF,CAAO,YAAP,EAAqB,CAAC,CAAD,EAAI,MAAI,CAAC,IAAL,CAAU,SAAd,CAArB,CAAD,CADG,GAEH,CAAC,YAAD,CAFJ;QAGD;MACF,CAhBU,CAAX;IAiBD;EA3bH;IAAA;IAAA,KA6bE,eAAoB;MAClB,IAAI,CAAC,KAAK,SAAV,EAAqB;QACnB,OAAO,EAAP;MACD;;MAED,OAAO,KAAK,IAAL,CAAU,gBAAjB;IACD;EAncH;IAAA;IAAA,KAqcE,eAAuB;MAErB,IAAI,CAAC,KAAK,SAAV,EAAqB;QACnB,OAAO,KAAK,IAAL,CAAU,OAAjB;MACD;;MACD,OAAO,KAAK,IAAL,CAAU,mBAAjB;IACD;EA3cH;IAAA;IAAA,OA6cE,sCAA6B,KAA7B,EAA2C;MACzC,sFAAmC,KAAnC;;MACA,IAAI,KAAK,IAAL,IAAa,IAAjB,EAAuB;QACrB,KAAK,IAAL,CAAU,4BAAV,CAAuC,KAAvC;MACD;IACF;EAldH;IAAA;IAAA,OAodE,qBAAS;MACP,IAAM,UAAU,qEAAhB;;MAEA,IAAM,MAAM,GAA6B;QACvC,eAAe,EAAE,KAAK,eADiB;QAEvC,WAAW,EAAE,KAAK,WAFqB;QAGvC,WAAW,EAAE,KAAK,WAHqB;QAIvC,QAAQ,EAAE,KAAK,QAJwB;QAKvC,MAAM,EAAE,KAAK;MAL0B,CAAzC;;MAQA,IAAI,KAAK,YAAL,IAAqB,IAAzB,EAA+B;QAC7B,MAAM,CAAC,cAAD,CAAN,GAAyB,KAAK,YAA9B;MACD;;MAED,IAAM,UAAU,GAAG,KAAK,IAAL,CAAU,SAAV,EAAnB;;MAEA,IAAI,KAAK,YAAL,OAAwB,GAAG,CAAC,SAAhC,EAA2C;QACzC,MAAM,CAAC,MAAD,CAAN,GAAiB;UACf,aAAa,KAAK,IAAL,CAAU,YAAV,EADE;UAEf,UAAU;QAFK,CAAjB;MAID;;MAGD,OAAA,SAAA,EAAA,EAAW,UAAX,EAA0B,UAA1B,EAAyC,MAAzC,CAAA;IACD;EA9eH;IAAA;IAAA,OAifE,oBACI,GADJ,EAEI,MAFJ,EAGkD;MAAA,IAA9C,aAA8C,uEAA9B,EAA8B;MAChD,IAAM,UAAU,GAAG,MAAM,CAAC,MAAD,CAAzB;MACA,IAAM,IAAI,GAAG,WAAW,CAAC,UAAD,EAAa,aAAb,CAAxB;MACA,OAAO,IAAI,GAAJ,CAAQ,SAAc,MAAd,EAAsB;QAAC,IAAI,EAAJ;MAAD,CAAtB,CAAR,CAAP;IACD;EAxfH;;EAAA;AAAA,EAAyB,KAAzB;AAES,GAAA,CAAA,SAAA,GAAY,KAAZ;AAwfT,aAAa,CAAC,aAAd,CAA4B,GAA5B;AAUA,WAAsB,OAAtB;EAAA;;EAAA;;EAAA;IAAA;;IAAA;EAAA;;EAAA;AAAA,EAAsC,KAAtC;AA0FA,WAAa,aAAb;EAAA;;EAAA;;EAiCE,uBAAY,IAAZ,EAAwC;IAAA;;IAAA;;IACtC,4BAAM,IAAN;IANO,OAAA,kBAAA,GAAqB,MAArB;IACA,OAAA,0BAAA,GAA6B,cAA7B;IACA,OAAA,6BAAA,GAAgC,YAAhC;IACA,OAAA,wBAAA,GAAkD,OAAlD;IAIP,OAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;IACA,qBAAqB,CAAC,OAAK,KAAN,UAArB;IACA,OAAK,UAAL,GAAkB,aAAa,CAC3B,IAAI,CAAC,UAAL,IAAmB,IAAnB,GAA0B,OAAK,kBAA/B,GAAoD,IAAI,CAAC,UAD9B,CAA/B;IAEA,OAAK,OAAL,GAAe,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,IAAvB,GAA8B,IAAI,CAAC,OAAlD;IAEA,OAAK,iBAAL,GAAyB,cAAc,CACnC,IAAI,CAAC,iBAAL,IAA0B,OAAK,0BADI,CAAvC;IAEA,OAAK,oBAAL,GAA4B,cAAc,CACtC,IAAI,CAAC,oBAAL,IAA6B,OAAK,6BADI,CAA1C;IAGA,OAAK,eAAL,GACI,cAAc,CAAC,IAAI,CAAC,eAAL,IAAwB,OAAK,wBAA9B,CADlB;IAGA,OAAK,iBAAL,GAAyB,cAAc,CAAC,IAAI,CAAC,iBAAN,CAAvC;IACA,OAAK,oBAAL,GAA4B,cAAc,CAAC,IAAI,CAAC,oBAAN,CAA1C;IACA,OAAK,eAAL,GAAuB,cAAc,CAAC,IAAI,CAAC,eAAN,CAArC;IAEA,OAAK,gBAAL,GAAwB,aAAa,CAAC,IAAI,CAAC,gBAAN,CAArC;IACA,OAAK,mBAAL,GAA2B,aAAa,CAAC,IAAI,CAAC,mBAAN,CAAxC;IACA,OAAK,cAAL,GAAsB,aAAa,CAAC,IAAI,CAAC,cAAN,CAAnC;IAEA,OAAK,OAAL,GAAe,UAAU,CAAC,GAAX,CACX,CAAC,CAAD,EAAI,UAAU,CAAC,GAAX,CAAe,CAAC,CAAD,EAAI,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,CAAvB,GAA2B,IAAI,CAAC,OAApC,CAAf,CAAJ,CADW,CAAf;IAEA,OAAK,gBAAL,GAAwB,UAAU,CAAC,GAAX,CAAe,CACrC,CADqC,EAErC,UAAU,CAAC,GAAX,CACI,CAAC,CAAD,EAAI,IAAI,CAAC,gBAAL,IAAyB,IAAzB,GAAgC,CAAhC,GAAoC,IAAI,CAAC,gBAA7C,CADJ,CAFqC,CAAf,CAAxB;IAKA,OAAK,SAAL,GAAiB,OAAK,KAAtB;IACA,OAAK,WAAL,GAAmB,IAAnB;IACA,OAAK,oBAAL,GAA4B,IAA5B;IAjCsC;EAkCvC;;EAnEH;IAAA;IAAA,OAqEE,eAAM,UAAN,EAA+B;MAC7B,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;MAEA,KAAK,MAAL,GAAc,KAAK,SAAL,CACV,QADU,EACA,CAAC,UAAU,CAAC,UAAU,CAAC,MAAX,GAAoB,CAArB,CAAX,EAAoC,KAAK,KAAzC,CADA,EACiD,IADjD,EAEV,KAAK,iBAFK,EAEc,KAAK,iBAFnB,EAEsC,IAFtC,EAGV,KAAK,gBAHK,CAAd;MAIA,KAAK,eAAL,GAAuB,KAAK,SAAL,CACnB,kBADmB,EACC,CAAC,KAAK,KAAN,EAAa,KAAK,KAAlB,CADD,EAC2B,IAD3B,EAEnB,KAAK,oBAFc,EAEQ,KAAK,oBAFb,EAEmC,IAFnC,EAGnB,KAAK,mBAHc,CAAvB;;MAIA,IAAI,KAAK,OAAT,EAAkB;QAChB,KAAK,IAAL,GAAY,KAAK,SAAL,CACR,MADQ,EACA,CAAC,KAAK,KAAN,CADA,EACc,IADd,EACoB,KAAK,eADzB,EAER,KAAK,eAFG,EAEc,IAFd,EAEoB,KAAK,cAFzB,CAAZ;MAGD,CAJD,MAIO;QACL,KAAK,IAAL,GAAY,IAAZ;MACD;;MACD,KAAK,KAAL,GAAa,IAAb;IACD;EAxFH;IAAA;IAAA,OAgGE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,MAAM,GAAG,MAAT;;QACA,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;UACvB,MAAM,IAAI,UAAJ,iDAC4C,MAAM,CAAC,MADnD,OAAN;QAED;;QACD,IAAI,UAAU,GAAG,MAAM,CAAC,CAAD,CAAvB;QACA,MAAM,GAAG,MAAM,CAAC,CAAD,CAAf;QACA,IAAM,QAAQ,GAAG,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqC,MAAM,CAAC,UAAD,CAA5D;;QAEA,IAAI,IAAI,MAAI,CAAC,OAAT,IAAoB,MAAI,CAAC,OAAL,GAAe,CAAnC,IAAwC,MAAI,CAAC,WAAL,IAAoB,IAAhE,EAAsE;UACpE,MAAI,CAAC,WAAL,GAAmB,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,MAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,MAAI,CAAC,OAFO;YAGlB,QAAQ,EAAR;UAHkB,CAAD,CAAtC;QAKD;;QACD,IAAI,IAAI,MAAI,CAAC,gBAAT,IAA6B,MAAI,CAAC,gBAAL,GAAwB,CAArD,IACA,MAAI,CAAC,oBAAL,IAA6B,IADjC,EACuC;UACrC,MAAI,CAAC,oBAAL,GAA4B,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,UAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,MAAI,CAAC,gBAFO;YAGlB,QAAQ,EAAR;UAHkB,CAAD,CAA/C;QAKD;;QACD,IAAI,CAAJ;QACA,IAAM,MAAM,GAAW,MAAI,CAAC,WAA5B;QACA,IAAM,SAAS,GAAW,MAAI,CAAC,oBAA/B;;QACA,IAAI,MAAM,IAAI,IAAd,EAAoB;UAClB,CAAC,GAAG,CAAC,CAAC,GAAF,CAAM,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAhB,CAAN,EAA+B,MAAI,CAAC,MAAL,CAAY,IAAZ,EAA/B,CAAJ;QACD,CAFD,MAEO;UACL,CAAC,GAAG,CAAC,CAAC,GAAF,CAAM,MAAN,EAAc,MAAI,CAAC,MAAL,CAAY,IAAZ,EAAd,CAAJ;QACD;;QACD,IAAI,MAAI,CAAC,IAAL,IAAa,IAAjB,EAAuB;UACrB,CAAC,GAAG,CAAC,CAAC,OAAF,CAAU,CAAV,EAAa,MAAI,CAAC,IAAL,CAAU,IAAV,EAAb,CAAJ;QACD;;QACD,IAAI,SAAS,IAAI,IAAjB,EAAuB;UACrB,UAAU,GAAG,GAAG,CAAC,GAAJ,CAAQ,UAAR,EAAoB,SAApB,CAAb;QACD;;QACD,IAAI,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,CAAC,CAAC,GAAF,CAAM,UAAN,EAAkB,MAAI,CAAC,eAAL,CAAqB,IAArB,EAAlB,CAAX,CAAb;;QACA,IAAI,MAAI,CAAC,UAAL,IAAmB,IAAvB,EAA6B;UAC3B,MAAM,GAAG,MAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,MAAtB,CAAT;QACD;;QAGD,OAAO,CAAC,MAAD,EAAS,MAAT,CAAP;MACD,CA9CU,CAAX;IA+CD;EAhJH;IAAA;IAAA,OAkJE,qBAAS;MACP,IAAM,UAAU,+EAAhB;;MAEA,IAAM,MAAM,GAA6B;QACvC,KAAK,EAAE,KAAK,KAD2B;QAEvC,UAAU,EAAE,mBAAmB,CAAC,KAAK,UAAN,CAFQ;QAGvC,OAAO,EAAE,KAAK,OAHyB;QAIvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CAJA;QAKvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CALH;QAMvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CANE;QAOvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CAPA;QAQvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CARH;QASvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CATE;QAUvC,mBAAmB,EAAE,oBAAoB,CAAC,KAAK,mBAAN,CAVF;QAWvC,gBAAgB,EAAE,mBAAmB,CAAC,KAAK,gBAAN,CAXE;QAYvC,mBAAmB,EAAE,mBAAmB,CAAC,KAAK,mBAAN,CAZD;QAavC,cAAc,EAAE,mBAAmB,CAAC,KAAK,cAAN,CAbI;QAcvC,OAAO,EAAE,KAAK,OAdyB;QAevC,gBAAgB,EAAE,KAAK;MAfgB,CAAzC;MAkBA,OAAA,SAAA,EAAA,EAAW,UAAX,EAA0B,MAA1B,CAAA;IACD;EAxKH;;EAAA;AAAA,EAAmC,OAAnC;AAES,aAAA,CAAA,SAAA,GAAY,eAAZ;AAwKT,aAAa,CAAC,aAAd,CAA4B,aAA5B;AA2FA,WAAa,SAAb;EAAA;;EAAA;;EAGE,mBAAY,IAAZ,EAAoC;IAAA;;IAClC,IAAI,CAAC,IAAL,GAAY,IAAI,aAAJ,CAAkB,IAAlB,CAAZ;IADkC,0BAE5B,IAF4B;EAInC;;EAPH;IAAA;IAAA,OASE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,MAAI,CAAC,IAAL,CAAU,WAAV,IAAyB,IAA7B,EAAmC;UACjC,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,IAAL,CAAU,WAAtB;UACA,MAAI,CAAC,IAAL,CAAU,WAAV,GAAwB,IAAxB;QACD;;QACD,IAAI,MAAI,CAAC,IAAL,CAAU,oBAAV,IAAkC,IAAtC,EAA4C;UAC1C,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,IAAL,CAAU,oBAAtB;UACA,MAAI,CAAC,IAAL,CAAU,oBAAV,GAAiC,IAAjC;QACD;;QACD,IAAM,IAAI,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,MAAD,CAA3C;QACA,IAAM,QAAQ,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,UAAD,CAA/C;QACA,IAAM,YAAY,GACd,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;QAEA,+EAAkB,MAAlB,EAA0B;UAAC,IAAI,EAAJ,IAAD;UAAO,QAAQ,EAAR,QAAP;UAAiB,YAAY,EAAZ;QAAjB,CAA1B;MACD,CAdU,CAAX;IAeD;EAzBH;IAAA;IAAA,OA4BE,oBACI,GADJ,EAEI,MAFJ,EAEoC;MAClC,OAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;IACD;EAhCH;;EAAA;AAAA,EAA+B,GAA/B;AAES,SAAA,CAAA,SAAA,GAAY,WAAZ;AAgCT,aAAa,CAAC,aAAd,CAA4B,SAA5B;AAqCA,WAAa,OAAb;EAAA;;EAAA;;EAqCE,iBAAY,IAAZ,EAAkC;IAAA;;IAAA;;IAChC,4BAAM,IAAN;IAZO,OAAA,kBAAA,GAAqB,MAArB;IACA,OAAA,4BAAA,GAAqD,aAArD;IAEA,OAAA,0BAAA,GAA6B,cAA7B;IACA,OAAA,6BAAA,GAAgC,YAAhC;IACA,OAAA,wBAAA,GAAkD,OAAlD;;IAQP,IAAI,IAAI,CAAC,UAAT,EAAqB;MACnB,MAAM,IAAI,UAAJ,+DAAN;IAED;;IACD,OAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;IACA,qBAAqB,CAAC,OAAK,KAAN,EAAa,OAAb,CAArB;IACA,OAAK,UAAL,GAAkB,aAAa,CAC3B,IAAI,CAAC,UAAL,KAAoB,SAApB,GAAgC,OAAK,kBAArC,GACgC,IAAI,CAAC,UAFV,CAA/B;IAGA,OAAK,mBAAL,GAA2B,aAAa,CACpC,IAAI,CAAC,mBAAL,KAA6B,SAA7B,GACI,OAAK,4BADT,GAEI,IAAI,CAAC,mBAH2B,CAAxC;IAIA,OAAK,OAAL,GAAe,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,IAAvB,GAA8B,IAAI,CAAC,OAAlD;IAEA,OAAK,iBAAL,GAAyB,cAAc,CACnC,IAAI,CAAC,iBAAL,IAA0B,OAAK,0BADI,CAAvC;IAEA,OAAK,oBAAL,GAA4B,cAAc,CACtC,IAAI,CAAC,oBAAL,IAA6B,OAAK,6BADI,CAA1C;IAGA,OAAK,eAAL,GACI,cAAc,CAAC,IAAI,CAAC,eAAL,IAAwB,OAAK,wBAA9B,CADlB;IAGA,OAAK,iBAAL,GAAyB,cAAc,CAAC,IAAI,CAAC,iBAAN,CAAvC;IACA,OAAK,oBAAL,GAA4B,cAAc,CAAC,IAAI,CAAC,oBAAN,CAA1C;IACA,OAAK,eAAL,GAAuB,cAAc,CAAC,IAAI,CAAC,eAAN,CAArC;IAEA,OAAK,gBAAL,GAAwB,aAAa,CAAC,IAAI,CAAC,gBAAN,CAArC;IACA,OAAK,mBAAL,GAA2B,aAAa,CAAC,IAAI,CAAC,mBAAN,CAAxC;IACA,OAAK,cAAL,GAAsB,aAAa,CAAC,IAAI,CAAC,cAAN,CAAnC;IAEA,OAAK,OAAL,GAAe,UAAU,CAAC,GAAX,CACX,CAAC,CAAD,EAAI,UAAU,CAAC,GAAX,CAAe,CAAC,CAAD,EAAI,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,CAAvB,GAA2B,IAAI,CAAC,OAApC,CAAf,CAAJ,CADW,CAAf;IAEA,OAAK,gBAAL,GAAwB,UAAU,CAAC,GAAX,CAAe,CACrC,CADqC,EAErC,UAAU,CAAC,GAAX,CACI,CAAC,CAAD,EAAI,IAAI,CAAC,gBAAL,IAAyB,IAAzB,GAAgC,CAAhC,GAAoC,IAAI,CAAC,gBAA7C,CADJ,CAFqC,CAAf,CAAxB;IAKA,OAAK,cAAL,GAAsB,IAAI,CAAC,cAA3B;IACA,OAAK,SAAL,GAAiB,OAAK,KAAtB;IACA,OAAK,WAAL,GAAmB,IAAnB;IACA,OAAK,oBAAL,GAA4B,IAA5B;IA3CgC;EA4CjC;;EAjFH;IAAA;IAAA,OAmFS,eAAM,UAAN,EAA+B;MACpC,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;MACA,IAAM,QAAQ,GAAG,UAAU,CAAC,UAAU,CAAC,MAAX,GAAoB,CAArB,CAA3B;MACA,KAAK,MAAL,GAAc,KAAK,SAAL,CACV,QADU,EACA,CAAC,QAAD,EAAW,KAAK,KAAL,GAAa,CAAxB,CADA,EAC4B,IAD5B,EACkC,KAAK,iBADvC,EAEV,KAAK,iBAFK,EAEc,IAFd,EAEoB,KAAK,gBAFzB,CAAd;MAGA,KAAK,eAAL,GAAuB,KAAK,SAAL,CACnB,kBADmB,EACC,CAAC,KAAK,KAAN,EAAa,KAAK,KAAL,GAAa,CAA1B,CADD,EAC+B,IAD/B,EAEnB,KAAK,oBAFc,EAEQ,KAAK,oBAFb,EAEmC,IAFnC,EAGnB,KAAK,mBAHc,CAAvB;;MAIA,IAAI,KAAK,OAAT,EAAkB;QAChB,KAAK,IAAL,GAAY,KAAK,SAAL,CACR,MADQ,EACA,CAAC,KAAK,KAAL,GAAa,CAAd,CADA,EACkB,IADlB,EACwB,KAAK,eAD7B,EAER,KAAK,eAFG,EAEc,IAFd,EAEoB,KAAK,cAFzB,CAAZ;MAGD,CAJD,MAIO;QACL,KAAK,IAAL,GAAY,IAAZ;MACD;;MAGD,KAAK,KAAL,GAAa,IAAb;IACD;EAvGH;IAAA;IAAA,OAyGE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,MAAM,GAAG,MAAT;;QACA,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;UACvB,MAAM,IAAI,UAAJ,CACF,0DACG,MAAM,CAAC,MADV,OADE,CAAN;QAGD;;QAED,IAAM,QAAQ,GAAG,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqC,MAAM,CAAC,UAAD,CAA5D;QACA,IAAI,QAAQ,GAAG,MAAM,CAAC,CAAD,CAArB;QACA,MAAM,GAAG,MAAM,CAAC,CAAD,CAAf;;QAKA,IAAI,IAAI,OAAI,CAAC,OAAT,IAAoB,OAAI,CAAC,OAAL,GAAe,CAAnC,IAAwC,OAAI,CAAC,WAAL,IAAoB,IAAhE,EAAsE;UACpE,OAAI,CAAC,WAAL,GAAmB,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,MAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,OAAI,CAAC,OAFO;YAGlB,QAAQ,EAAR,QAHkB;YAIlB,KAAK,EAAE;UAJW,CAAD,CAAtC;QAMD;;QACD,IAAI,IAAI,OAAI,CAAC,gBAAT,IAA6B,OAAI,CAAC,gBAAL,GAAwB,CAArD,IACA,OAAI,CAAC,oBAAL,IAA6B,IADjC,EACuC;UACrC,OAAI,CAAC,oBAAL,GAA4B,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,QAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,OAAI,CAAC,gBAFO;YAGlB,QAAQ,EAAR,QAHkB;YAIlB,KAAK,EAAE;UAJW,CAAD,CAA/C;QAMD;;QACD,IAAM,MAAM,GAAG,OAAI,CAAC,WAApB;QACA,IAAM,SAAS,GAAG,OAAI,CAAC,oBAAvB;QACA,IAAI,CAAJ;QACA,IAAI,CAAJ;QACA,IAAI,EAAJ;;QAEA,IAAI,IAAI,OAAI,CAAC,OAAT,IAAoB,OAAI,CAAC,OAAL,GAAe,CAAvC,EAA0C;UACxC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;QACD;;QACD,IAAI,OAAO,GAAG,CAAC,CAAC,GAAF,CAAM,MAAN,EAAc,OAAI,CAAC,MAAL,CAAY,IAAZ,EAAd,CAAd;;QACA,IAAI,OAAI,CAAC,OAAT,EAAkB;UAChB,OAAO,GAAG,CAAC,CAAC,OAAF,CAAU,OAAV,EAAmB,OAAI,CAAC,IAAL,CAAU,IAAV,EAAnB,CAAV;QACD;;QACD,IAAI,IAAI,OAAI,CAAC,gBAAT,IAA6B,OAAI,CAAC,gBAAL,GAAwB,CAAzD,EAA4D;UAC1D,QAAQ,GAAG,GAAG,CAAC,GAAJ,CAAQ,QAAR,EAAkB,SAAS,CAAC,CAAD,CAA3B,CAAX;QACD;;QAED,IAAM,oBAAoB,GAAG,OAAI,CAAC,eAAL,CAAqB,IAArB,EAA7B;;QACA,iBAAmB,GAAG,CAAC,KAAJ,CACf,oBADe,EACO,CAAC,IAAI,OAAI,CAAC,KAAV,EAAiB,OAAI,CAAC,KAAtB,CADP,EAEf,oBAAoB,CAAC,IAArB,GAA4B,CAFb,CAAnB;QAAA;QAAA,IAAO,GAAP;QAAA,IAAY,GAAZ;;QAGA,IAAM,WAAW,GAAG,CAAC,CAAC,GAAF,CAAM,QAAN,EAAgB,GAAhB,CAApB;;QAEA,kBAAqB,GAAG,CAAC,KAAJ,CAAU,OAAV,EAAmB,CAAnB,EAAsB,OAAO,CAAC,IAAR,GAAe,CAArC,CAArB;QAAA;QAAA,IAAO,EAAP;QAAA,IAAW,EAAX;QAAA,IAAe,EAAf;;QACA,kBACI,GAAG,CAAC,KAAJ,CAAU,WAAV,EAAuB,CAAvB,EAA0B,WAAW,CAAC,IAAZ,GAAmB,CAA7C,CADJ;QAAA;QAAA,IAAO,UAAP;QAAA,IAAmB,UAAnB;;QAEA,CAAC,GAAG,OAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,UAAZ,CAA/B,CAAJ;QACA,CAAC,GAAG,OAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,UAAZ,CAA/B,CAAJ;QAEA,IAAM,UAAU,GAAG,CAAC,CAAC,GAAF,CAAM,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,QAAX,CAAN,EAA4B,GAA5B,CAAnB;QACA,EAAE,GAAG,OAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,UAAZ,CAAtB,CAAL;QAEA,IAAM,CAAC,GACH,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,QAAX,CAAR,EAA8B,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,GAAG,CAAC,GAAJ,CAAQ,CAAR,CAAX,CAAR,EAAgC,EAAhC,CAA9B,CADJ;QAGA,OAAO,CAAC,CAAD,EAAI,CAAJ,CAAP;MACD,CApEU,CAAX;IAqED;EA/KH;IAAA;IAAA,OAiLE,qBAAS;MACP,IAAM,UAAU,yEAAhB;;MAEA,IAAM,MAAM,GAA6B;QACvC,KAAK,EAAE,KAAK,KAD2B;QAEvC,UAAU,EAAE,mBAAmB,CAAC,KAAK,UAAN,CAFQ;QAGvC,mBAAmB,EAAE,mBAAmB,CAAC,KAAK,mBAAN,CAHD;QAIvC,OAAO,EAAE,KAAK,OAJyB;QAKvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CALA;QAMvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CANH;QAOvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CAPE;QAQvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CARA;QASvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CATH;QAUvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CAVE;QAWvC,mBAAmB,EAAE,oBAAoB,CAAC,KAAK,mBAAN,CAXF;QAYvC,gBAAgB,EAAE,mBAAmB,CAAC,KAAK,gBAAN,CAZE;QAavC,mBAAmB,EAAE,mBAAmB,CAAC,KAAK,mBAAN,CAbD;QAcvC,cAAc,EAAE,mBAAmB,CAAC,KAAK,cAAN,CAdI;QAevC,OAAO,EAAE,KAAK,OAfyB;QAgBvC,gBAAgB,EAAE,KAAK,gBAhBgB;QAiBvC,cAAc,EAAE,KAAK,cAjBkB;QAkBvC,UAAU,EAAE;MAlB2B,CAAzC;MAqBA,OAAA,SAAA,EAAA,EAAW,UAAX,EAA0B,MAA1B,CAAA;IACD;EA1MH;;EAAA;AAAA,EAA6B,OAA7B;AAES,OAAA,CAAA,SAAA,GAAY,SAAZ;AA0MT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AA8BA,WAAa,GAAb;EAAA;;EAAA;;EAGE,aAAY,IAAZ,EAA8B;IAAA;;IAC5B,IAAI,IAAI,CAAC,cAAL,KAAwB,CAA5B,EAA+B;MAC7B,OAAO,CAAC,IAAR,CACI,iEACA,oDAFJ;IAGD;;IACD,IAAI,CAAC,IAAL,GAAY,IAAI,OAAJ,CAAY,IAAZ,CAAZ;IAN4B,0BAOtB,IAPsB;EAS7B;;EAZH;IAAA;IAAA,OAcE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,OAAI,CAAC,IAAL,CAAU,WAAV,IAAyB,IAA7B,EAAmC;UACjC,GAAG,CAAC,OAAJ,CAAY,OAAI,CAAC,IAAL,CAAU,WAAtB;UACA,OAAI,CAAC,IAAL,CAAU,WAAV,GAAwB,IAAxB;QACD;;QACD,IAAI,OAAI,CAAC,IAAL,CAAU,oBAAV,IAAkC,IAAtC,EAA4C;UAC1C,GAAG,CAAC,OAAJ,CAAY,OAAI,CAAC,IAAL,CAAU,oBAAtB;UACA,OAAI,CAAC,IAAL,CAAU,oBAAV,GAAiC,IAAjC;QACD;;QACD,IAAM,IAAI,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,MAAD,CAA3C;QACA,IAAM,QAAQ,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,UAAD,CAA/C;QACA,IAAM,YAAY,GACd,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;QAEA,2EAAkB,MAAlB,EAA0B;UAAC,IAAI,EAAJ,IAAD;UAAO,QAAQ,EAAR,QAAP;UAAiB,YAAY,EAAZ;QAAjB,CAA1B;MACD,CAdU,CAAX;IAeD;EA9BH;IAAA;IAAA,OAiCE,oBACI,GADJ,EAEI,MAFJ,EAEoC;MAClC,IAAI,MAAM,CAAC,eAAD,CAAN,KAA4B,CAAhC,EAAmC;QACjC,MAAM,CAAC,gBAAD,CAAN,GAA2B,CAA3B;MACD;;MACD,OAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;IACD;EAxCH;;EAAA;AAAA,EAAyB,GAAzB;AAES,GAAA,CAAA,SAAA,GAAY,KAAZ;AAwCT,aAAa,CAAC,aAAd,CAA4B,GAA5B;AAuCA,WAAa,QAAb;EAAA;;EAAA;;EAsCE,kBAAY,IAAZ,EAAmC;IAAA;;IAAA;;IACjC,6BAAM,IAAN;IAZO,QAAA,kBAAA,GAAqB,MAArB;IACA,QAAA,4BAAA,GAA+B,aAA/B;IACA,QAAA,0BAAA,GAA6B,cAA7B;IACA,QAAA,6BAAA,GAAgC,YAAhC;IAEA,QAAA,wBAAA,GAA2B,OAA3B;IASP,QAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;IACA,qBAAqB,CAAC,QAAK,KAAN,EAAa,OAAb,CAArB;IACA,QAAK,UAAL,GAAkB,aAAa,CAC3B,IAAI,CAAC,UAAL,KAAoB,SAApB,GAAgC,QAAK,kBAArC,GACgC,IAAI,CAAC,UAFV,CAA/B;IAGA,QAAK,mBAAL,GAA2B,aAAa,CACpC,IAAI,CAAC,mBAAL,KAA6B,SAA7B,GACI,QAAK,4BADT,GAEI,IAAI,CAAC,mBAH2B,CAAxC;IAIA,QAAK,OAAL,GAAe,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,IAAvB,GAA8B,IAAI,CAAC,OAAlD;IAEA,QAAK,iBAAL,GAAyB,cAAc,CACnC,IAAI,CAAC,iBAAL,IAA0B,QAAK,0BADI,CAAvC;IAEA,QAAK,oBAAL,GAA4B,cAAc,CACtC,IAAI,CAAC,oBAAL,IAA6B,QAAK,6BADI,CAA1C;IAGA,QAAK,eAAL,GACI,cAAc,CAAC,IAAI,CAAC,eAAL,IAAwB,QAAK,wBAA9B,CADlB;IAEA,QAAK,cAAL,GAAsB,IAAI,CAAC,cAA3B;IAEA,QAAK,iBAAL,GAAyB,cAAc,CAAC,IAAI,CAAC,iBAAN,CAAvC;IACA,QAAK,oBAAL,GAA4B,cAAc,CAAC,IAAI,CAAC,oBAAN,CAA1C;IACA,QAAK,eAAL,GAAuB,cAAc,CAAC,IAAI,CAAC,eAAN,CAArC;IAEA,QAAK,gBAAL,GAAwB,aAAa,CAAC,IAAI,CAAC,gBAAN,CAArC;IACA,QAAK,mBAAL,GAA2B,aAAa,CAAC,IAAI,CAAC,mBAAN,CAAxC;IACA,QAAK,cAAL,GAAsB,aAAa,CAAC,IAAI,CAAC,cAAN,CAAnC;IAEA,QAAK,OAAL,GAAe,UAAU,CAAC,GAAX,CACX,CAAC,CAAD,EAAI,UAAU,CAAC,GAAX,CAAe,CAAC,CAAD,EAAI,IAAI,CAAC,OAAL,IAAgB,IAAhB,GAAuB,CAAvB,GAA2B,IAAI,CAAC,OAApC,CAAf,CAAJ,CADW,CAAf;IAEA,QAAK,gBAAL,GAAwB,UAAU,CAAC,GAAX,CAAe,CACrC,CADqC,EAErC,UAAU,CAAC,GAAX,CACI,CAAC,CAAD,EAAI,IAAI,CAAC,gBAAL,IAAyB,IAAzB,GAAgC,CAAhC,GAAoC,IAAI,CAAC,gBAA7C,CADJ,CAFqC,CAAf,CAAxB;IAKA,QAAK,cAAL,GAAsB,IAAI,CAAC,cAA3B;IACA,QAAK,SAAL,GAAiB,CAAC,QAAK,KAAN,EAAa,QAAK,KAAlB,CAAjB;IACA,QAAK,WAAL,GAAmB,IAAnB;IACA,QAAK,oBAAL,GAA4B,IAA5B;IAzCiC;EA0ClC;;EAhFH;IAAA;IAAA,OAkFS,eAAM,UAAN,EAA+B;;;MACpC,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;MACA,IAAM,QAAQ,GAAG,UAAU,CAAC,UAAU,CAAC,MAAX,GAAoB,CAArB,CAA3B;MACA,KAAK,MAAL,GAAc,KAAK,SAAL,CACV,QADU,EACA,CAAC,QAAD,EAAW,KAAK,KAAL,GAAa,CAAxB,CADA,EAC4B,IAD5B,EACkC,KAAK,iBADvC,EAEV,KAAK,iBAFK,EAEc,IAFd,EAEoB,KAAK,gBAFzB,CAAd;MAGA,KAAK,eAAL,GAAuB,KAAK,SAAL,CACnB,kBADmB,EACC,CAAC,KAAK,KAAN,EAAa,KAAK,KAAL,GAAa,CAA1B,CADD,EAC+B,IAD/B,EAEnB,KAAK,oBAFc,EAEQ,KAAK,oBAFb,EAEmC,IAFnC,EAGnB,KAAK,mBAHc,CAAvB;MAIA,IAAI,eAAJ;;MACA,IAAI,KAAK,OAAT,EAAkB;QAChB,IAAI,KAAK,cAAT,EAAyB;UACvB,IAAM,gBAAgB,GAAG,KAAK,eAA9B;UACA,IAAM,aAAa,GAAG,KAAK,KAA3B;UACA,eAAe,GAAG,KAAI,EAAA;YAAA;;YAAA;;YAAA;cAAA;;cAAA;YAAA;;YAAA;cAAA;cAAA,OAIpB,eAAM,KAAN,EAAoB,KAApB,EAAoC;gBAElC,IAAM,EAAE,GAAG,gBAAgB,CAAC,KAAjB,CAAuB,CAAC,aAAD,CAAvB,CAAX;gBACA,IAAM,EAAE,GAAI,IAAI,IAAJ,EAAD,CAAa,KAAb,CAAmB,CAAC,aAAD,CAAnB,CAAX;gBACA,IAAM,MAAM,GAAG,gBAAgB,CAAC,KAAjB,CAAuB,CAAC,aAAa,GAAG,CAAjB,CAAvB,CAAf;gBACA,OAAO,CAAC,CAAC,oBAAF,CACH,CAAC,CAAC,oBAAF,CAAuB,EAAvB,EAA2B,EAA3B,CADG,EAC6B,MAD7B,CAAP;cAED;YAXmB;;YAAA;UAAA,EAA0B,WAA1B,CAAA,EAEb,EAAA,CAAA,SAAA,GAAY,YAFC,EAYpB,EAZgB,GAAlB;QAaD,CAhBD,MAgBO;UACL,eAAe,GAAG,KAAK,eAAvB;QACD;;QACD,KAAK,IAAL,GAAY,KAAK,SAAL,CACR,MADQ,EACA,CAAC,KAAK,KAAL,GAAa,CAAd,CADA,EACkB,IADlB,EACwB,eADxB,EACyC,KAAK,eAD9C,EAER,IAFQ,EAEF,KAAK,cAFH,CAAZ;MAGD,CAvBD,MAuBO;QACL,KAAK,IAAL,GAAY,IAAZ;MACD;;MAGD,KAAK,KAAL,GAAa,IAAb;IACD;EA1HH;IAAA;IAAA,OA4HE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,IAAM,QAAQ,GAAG,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqC,MAAM,CAAC,UAAD,CAA5D;QACA,MAAM,GAAG,MAAT;;QACA,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;UACvB,MAAM,IAAI,UAAJ,CACF,2DACG,MAAM,CAAC,MADV,OADE,CAAN;QAGD;;QACD,IAAI,QAAQ,GAAG,MAAM,CAAC,CAAD,CAArB;QACA,IAAM,QAAQ,GAAG,MAAM,CAAC,CAAD,CAAvB;QACA,MAAM,GAAG,MAAM,CAAC,CAAD,CAAf;;QACA,IAAI,IAAI,OAAI,CAAC,OAAT,IAAoB,OAAI,CAAC,OAAL,GAAe,CAAnC,IAAwC,OAAI,CAAC,WAAL,IAAoB,IAAhE,EAAsE;UACpE,OAAI,CAAC,WAAL,GAAmB,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,MAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,OAAI,CAAC,OAFO;YAGlB,QAAQ,EAAR,QAHkB;YAIlB,KAAK,EAAE;UAJW,CAAD,CAAtC;QAMD;;QACD,IAAI,IAAI,OAAI,CAAC,gBAAT,IAA6B,OAAI,CAAC,gBAAL,GAAwB,CAArD,IACA,OAAI,CAAC,oBAAL,IAA6B,IADjC,EACuC;UACrC,OAAI,CAAC,oBAAL,GAA4B,mBAAmB,CAAC;YAClB,IAAI,EAAE;cAAA,OAAM,GAAG,CAAC,QAAJ,CAAa,QAAb,CAAN;YAAA,CADY;YAElB,IAAI,EAAE,OAAI,CAAC,gBAFO;YAGlB,QAAQ,EAAR,QAHkB;YAIlB,KAAK,EAAE;UAJW,CAAD,CAA/C;QAMD;;QACD,IAAM,MAAM,GAAG,OAAI,CAAC,WAApB;QACA,IAAM,SAAS,GACX,OAAI,CAAC,oBADT;QAMA,IAAI,CAAJ;QACA,IAAI,CAAJ;QACA,IAAI,CAAJ;QACA,IAAI,CAAJ;;QACA,IAAI,IAAI,OAAI,CAAC,OAAT,IAAoB,OAAI,CAAC,OAAL,GAAe,CAAvC,EAA0C;UACxC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;QACD;;QACD,IAAI,CAAC,GAAG,CAAC,CAAC,GAAF,CAAM,MAAN,EAAc,OAAI,CAAC,MAAL,CAAY,IAAZ,EAAd,CAAR;;QACA,IAAI,IAAI,OAAI,CAAC,gBAAT,IAA6B,OAAI,CAAC,gBAAL,GAAwB,CAAzD,EAA4D;UAC1D,QAAQ,GAAG,GAAG,CAAC,GAAJ,CAAQ,QAAR,EAAkB,SAAS,CAAC,CAAD,CAA3B,CAAX;QACD;;QACD,CAAC,GAAG,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,CAAC,CAAC,GAAF,CAAM,QAAN,EAAgB,OAAI,CAAC,eAAL,CAAqB,IAArB,EAAhB,CAAX,CAAJ;;QACA,IAAI,OAAI,CAAC,OAAT,EAAkB;UAChB,CAAC,GAAG,CAAC,CAAC,OAAF,CAAU,CAAV,EAAa,OAAI,CAAC,IAAL,CAAU,IAAV,EAAb,CAAJ;QACD;;QAED,kBAAyB,GAAG,CAAC,KAAJ,CAAU,CAAV,EAAa,CAAb,EAAgB,CAAC,CAAC,IAAF,GAAS,CAAzB,CAAzB;QAAA;QAAA,IAAO,EAAP;QAAA,IAAW,EAAX;QAAA,IAAe,EAAf;QAAA,IAAmB,EAAnB;;QAEA,CAAC,GAAG,OAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,EAA/B,CAAJ;QACA,CAAC,GAAG,OAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,EAA/B,CAAJ;QACA,CAAC,GAAG,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,QAAX,CAAR,EAA8B,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,OAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,EAAtB,CAAX,CAA9B,CAAJ;QACA,CAAC,GAAG,OAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,EAA/B,CAAJ;QAEA,IAAM,CAAC,GAAG,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,OAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,CAAtB,CAAX,CAAV;QAEA,OAAO,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,CAAP;MACD,CA7DU,CAAX;IA8DD;EA3LH;IAAA;IAAA,OA6LE,qBAAS;MACP,IAAM,UAAU,0EAAhB;;MAEA,IAAM,MAAM,GAA6B;QACvC,KAAK,EAAE,KAAK,KAD2B;QAEvC,UAAU,EAAE,mBAAmB,CAAC,KAAK,UAAN,CAFQ;QAGvC,mBAAmB,EAAE,mBAAmB,CAAC,KAAK,mBAAN,CAHD;QAIvC,OAAO,EAAE,KAAK,OAJyB;QAKvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CALA;QAMvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CANH;QAOvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CAPE;QAQvC,cAAc,EAAE,KAAK,cARkB;QASvC,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CATA;QAUvC,oBAAoB,EAAE,oBAAoB,CAAC,KAAK,oBAAN,CAVH;QAWvC,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CAXE;QAYvC,mBAAmB,EAAE,oBAAoB,CAAC,KAAK,mBAAN,CAZF;QAavC,gBAAgB,EAAE,mBAAmB,CAAC,KAAK,gBAAN,CAbE;QAcvC,mBAAmB,EAAE,mBAAmB,CAAC,KAAK,mBAAN,CAdD;QAevC,cAAc,EAAE,mBAAmB,CAAC,KAAK,cAAN,CAfI;QAgBvC,OAAO,EAAE,KAAK,OAhByB;QAiBvC,gBAAgB,EAAE,KAAK,gBAjBgB;QAkBvC,cAAc,EAAE,KAAK;MAlBkB,CAAzC;MAqBA,OAAA,SAAA,EAAA,EAAW,UAAX,EAA0B,MAA1B,CAAA;IACD;EAtNH;;EAAA;AAAA,EAA8B,OAA9B;AAES,QAAA,CAAA,SAAA,GAAY,UAAZ;AAsNT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAqCA,WAAa,IAAb;EAAA;;EAAA;;EAGE,cAAY,IAAZ,EAA+B;IAAA;;IAC7B,IAAI,IAAI,CAAC,cAAL,KAAwB,CAA5B,EAA+B;MAC7B,OAAO,CAAC,IAAR,CACI,iEACA,oDAFJ;IAGD;;IACD,IAAI,CAAC,IAAL,GAAY,IAAI,QAAJ,CAAa,IAAb,CAAZ;IAN6B,0BAOvB,IAPuB;EAS9B;;EAZH;IAAA;IAAA,OAcE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,IAAI,OAAI,CAAC,IAAL,CAAU,WAAV,IAAyB,IAA7B,EAAmC;UACjC,GAAG,CAAC,OAAJ,CAAY,OAAI,CAAC,IAAL,CAAU,WAAtB;UACA,OAAI,CAAC,IAAL,CAAU,WAAV,GAAwB,IAAxB;QACD;;QACD,IAAI,OAAI,CAAC,IAAL,CAAU,oBAAV,IAAkC,IAAtC,EAA4C;UAC1C,GAAG,CAAC,OAAJ,CAAY,OAAI,CAAC,IAAL,CAAU,oBAAtB;UACA,OAAI,CAAC,IAAL,CAAU,oBAAV,GAAiC,IAAjC;QACD;;QACD,IAAM,IAAI,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,MAAD,CAA3C;QACA,IAAM,QAAQ,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,UAAD,CAA/C;QACA,IAAM,YAAY,GACd,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;QAEA,4EAAkB,MAAlB,EAA0B;UAAC,IAAI,EAAJ,IAAD;UAAO,QAAQ,EAAR,QAAP;UAAiB,YAAY,EAAZ;QAAjB,CAA1B;MACD,CAdU,CAAX;IAeD;EA9BH;IAAA;IAAA,OAiCE,oBACI,GADJ,EAEI,MAFJ,EAEoC;MAClC,IAAI,MAAM,CAAC,eAAD,CAAN,KAA4B,CAAhC,EAAmC;QACjC,MAAM,CAAC,gBAAD,CAAN,GAA2B,CAA3B;MACD;;MACD,OAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;IACD;EAxCH;;EAAA;AAAA,EAA0B,GAA1B;AAES,IAAA,CAAA,SAAA,GAAY,MAAZ;AAwCT,aAAa,CAAC,aAAd,CAA4B,IAA5B;AASA,WAAa,eAAb;EAAA;;EAAA;;EAKE,yBAAY,IAAZ,EAAqC;IAAA;;IAAA;;IACnC,8BAAM,IAAN;IACA,QAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;IAFmC;EAGpC;;EARH;IAAA;IAAA,KAUE,eAAa;MAKX,IAAM,SAAS,GAAa,EAA5B;;MACA,sDAAmB,KAAK,KAAL,CAAW,KAAX,GAAmB,OAAnB,EAAnB,2CAAiD;QAAA,IAAtC,IAAsC;;QAC/C,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,SAAnB,CAAJ,EAAmC;UACjC,SAAS,CAAC,IAAV,OAAA,SAAS,qBAAS,IAAI,CAAC,SAAd,EAAT;QACD,CAFD,MAEO;UACL,SAAS,CAAC,IAAV,CAAe,IAAI,CAAC,SAApB;QACD;MACF;;MACD,OAAO,SAAP;IACD;EAxBH;IAAA;IAAA,OA0BE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;MAAA;;MAC1C,OAAO,IAAI,CAAC,YAAK;QACf,MAAM,GAAG,MAAT;QACA,IAAI,MAAM,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,CAAb;QAGA,IAAM,YAAY,GAAe,EAAjC;;QACA,sDAAmB,OAAI,CAAC,KAAL,CAAW,KAAX,GAAmB,OAAnB,EAAnB,2CAAiD;UAAA,IAAtC,IAAsC;;UAC/C,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,SAAnB,CAAJ,EAAmC;YACjC,YAAY,CAAC,IAAb,CAAkB,MAAM,CAAC,MAAP,CAAc,CAAd,EAAiB,IAAI,CAAC,SAAL,CAAe,MAAhC,CAAlB;UACD,CAFD,MAEO;YACL,YAAY,CAAC,IAAb,CAAkB,MAAM,CAAC,MAAP,CAAc,CAAd,EAAiB,CAAjB,CAAlB;UACD;QACF;;QACD,YAAY,CAAC,OAAb;QAGA,IAAM,eAAe,GAAe,EAApC;QACA,IAAI,UAAJ;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAI,CAAC,KAAL,CAAW,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;UAC1C,IAAM,KAAI,GAAG,OAAI,CAAC,KAAL,CAAW,CAAX,CAAb;UACA,MAAM,GAAG,YAAY,CAAC,CAAD,CAArB;;UAEA,IAAI,CAAC,KAAK,CAAV,EAAa;YACX,UAAU,GAAG,CAAC,MAAM,CAAC,CAAD,CAAP,EAAY,MAAZ,CAAmB,MAAnB,CAAb;UACD,CAFD,MAEO;YACL,UAAU,GAAG,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,MAAhB,CAAuB,MAAvB,CAAb;UACD;;UACD,UAAU,GAAG,KAAI,CAAC,IAAL,CAAU,UAAV,EAAsB,MAAtB,CAAb;UACA,eAAe,CAAC,IAAhB,CAAqB,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAArB;QACD;;QAGD,MAAM,GAAG,EAAT;;QACA,sDAAyB,eAAe,CAAC,KAAhB,GAAwB,OAAxB,EAAzB,2CAA4D;UAAA;;UAAA,IAAjD,UAAiD;;UAC1D,WAAA,MAAM,EAAC,IAAP,mCAAe,UAAf;QACD;;QACD,OAAO,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,MAAhB,CAAuB,MAAvB,CAAP;MACD,CArCU,CAAX;IAsCD;EAjEH;IAAA;IAAA,OAmES,eAAM,UAAN,EAA+B;MACpC,IAAI,eAAe,CAAC,UAAD,CAAnB,EAAiC;QAG/B,UAAU,GAAI,UAAsB,CAAC,CAAD,CAApC;MACD;;MACD,UAAU,GAAG,UAAb;MACA,IAAI,SAAJ;MACA,KAAK,KAAL,CAAW,OAAX,CAAmB,UAAC,IAAD,EAAO,CAAP,EAAY;QAC7B,SAAS,cAAY,CAAZ,EAAiB,YAAK;UAG7B,IAAI,CAAC,KAAL,CAAW,UAAX;;UACA,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,SAAnB,CAAJ,EAAmC;YACjC,SAAS,GAAG,IAAI,CAAC,SAAL,CAAe,CAAf,CAAZ;UACD,CAFD,MAEO;YACL,SAAS,GAAG,IAAI,CAAC,SAAjB;UACD;;UACD,UAAU,GAAG,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,SAAhB,CAAb;QACD,CAVQ,CAAT;MAWD,CAZD;MAaA,KAAK,KAAL,GAAa,IAAb;IACD;EAzFH;IAAA;IAAA,OA2FE,qBAAS;MACP,IAAM,UAAU,iFAAhB;;MAEA,IAAM,aAAa,GAAG,SAAhB,aAAgB,CAAC,IAAD,EAAkB;QACtC,OAAO;UACL,aAAa,IAAI,CAAC,YAAL,EADR;UAEL,UAAU,IAAI,CAAC,SAAL;QAFL,CAAP;MAID,CALD;;MAOA,IAAM,WAAW,GAAG,KAAK,KAAL,CAAW,GAAX,CAAe,aAAf,CAApB;MAEA,IAAM,MAAM,GAAG;QAAC,SAAS;MAAV,CAAf;MAEA,OAAA,SAAA,EAAA,EAAW,UAAX,EAA0B,MAA1B,CAAA;IACD;EA1GH;IAAA;IAAA,KAwHE,eAAoB;MAClB,IAAI,CAAC,KAAK,SAAV,EAAqB;QACnB,OAAO,EAAP;MACD;;MACD,IAAM,OAAO,GAAoB,EAAjC;;MACA,sDAAmB,KAAK,KAAxB,2CAA+B;QAAA,IAApB,IAAoB;QAC7B,OAAO,CAAC,IAAR,OAAA,OAAO,qBAAS,IAAI,CAAC,gBAAd,EAAP;MACD;;MACD,OAAO,OAAP;IACD;EAjIH;IAAA;IAAA,KAmIE,eAAuB;MACrB,IAAM,OAAO,GAAoB,EAAjC;;MACA,sDAAmB,KAAK,KAAxB,2CAA+B;QAAA,IAApB,IAAoB;QAC7B,OAAO,CAAC,IAAR,OAAA,OAAO,qBAAS,IAAI,CAAC,mBAAd,EAAP;MACD;;MACD,IAAI,CAAC,KAAK,SAAV,EAAqB;QACnB,IAAM,gBAAgB,GAAoB,EAA1C;;QACA,sDAAmB,KAAK,KAAxB,2CAA+B;UAAA,IAApB,MAAoB;UAC7B,gBAAgB,CAAC,IAAjB,OAAA,gBAAgB,qBAAS,MAAI,CAAC,gBAAd,EAAhB;QACD;;QACD,OAAO,gBAAgB,CAAC,MAAjB,CAAwB,OAAxB,CAAP;MACD;;MACD,OAAO,OAAP;IACD;EAhJH;IAAA;IAAA,OAuJE,sBAAU;MACR,IAAM,OAAO,GAAoB,EAAjC;;MACA,sDAAmB,KAAK,KAAxB,2CAA+B;QAAA,IAApB,IAAoB;QAC7B,OAAO,CAAC,IAAR,OAAA,OAAO,qBAAS,IAAI,CAAC,OAAd,EAAP;MACD;;MACD,OAAO,aAAa,CAAC,OAAD,CAApB;IACD;EA7JH;IAAA;IAAA,OAqKE,oBAAW,OAAX,EAA4B;MAC1B,IAAM,MAAM,GAAmC,EAA/C;;MACA,uDAAmB,KAAK,KAAxB,8CAA+B;QAAA,IAApB,IAAoB;QAC7B,IAAM,SAAS,GAAG,IAAI,CAAC,OAAL,CAAa,MAA/B;QACA,IAAM,YAAY,GAAG,OAAO,CAAC,MAAR,CAAe,SAAf,CAArB;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAAI,CAAC,OAAL,CAAa,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;UAC5C,MAAM,CAAC,IAAP,CAAY,CAAC,IAAI,CAAC,OAAL,CAAa,CAAb,CAAD,EAAkB,YAAY,CAAC,CAAD,CAA9B,CAAZ;QACD;MACF;;MACD,aAAa,CAAC,MAAD,CAAb;IACD;EA/KH;IAAA;IAAA,OA6GE,oBACI,GADJ,EAEI,MAFJ,EAGkD;MAAA,IAA9C,aAA8C,uEAA9B,EAA8B;MAChD,IAAM,KAAK,GAAc,EAAzB;;MACA,uDAA0B,MAAM,CAAC,OAAD,CAAhC,8CAA0E;QAAA,IAA/D,UAA+D;QACxE,KAAK,CAAC,IAAN,CAAW,WAAW,CAAC,UAAD,EAAa,aAAb,CAAtB;MACD;;MACD,OAAO,IAAI,GAAJ,CAAQ;QAAC,KAAK,EAAL;MAAD,CAAR,CAAP;IACD;EAtHH;;EAAA;AAAA,EAAqC,OAArC;AAES,eAAA,CAAA,SAAA,GAAY,iBAAZ;AAiLT,aAAa,CAAC,aAAd,CAA4B,eAA5B;AAEA,OAAM,SAAU,mBAAV,CAA8B,IAA9B,EAKL;EACC,IAAO,IAAP,GAAkD,IAAlD,CAAO,IAAP;EAAA,IAAa,IAAb,GAAkD,IAAlD,CAAa,IAAb;EAAA,qBAAkD,IAAlD,CAAmB,QAAnB;EAAA,IAAmB,QAAnB,+BAA8B,KAA9B;EAAA,kBAAkD,IAAlD,CAAqC,KAArC;EAAA,IAAqC,KAArC,4BAA6C,CAA7C;;EAEA,IAAM,aAAa,GAAG,SAAhB,aAAgB;IAAA,OAAM,CAAC,CAAC,OAAF,CAAU,IAAI,EAAd,EAAkB,IAAlB,CAAN;EAAA,CAAtB;;EAEA,IAAM,UAAU,GAAG,SAAb,UAAa;IAAA,OAAM,CAAC,CAAC,YAAF,CAAe,aAAf,EAA8B,IAA9B,EAAoC,QAApC,CAAN;EAAA,CAAnB;;EAGA,IAAI,CAAC,KAAD,IAAU,KAAK,IAAI,CAAvB,EAA0B;IACxB,OAAO,GAAG,CAAC,IAAJ,CAAS,UAAU,GAAG,KAAb,EAAT,CAAP;EACD;;EAED,IAAM,KAAK,GAAG,KAAK,CAAC,KAAD,CAAL,CAAa,IAAb,CAAkB,SAAlB,EAA6B,GAA7B,CAAiC,UAAjC,CAAd;EAEA,OAAO,KAAK,CAAC,GAAN,CAAU,UAAA,CAAC;IAAA,OAAI,GAAG,CAAC,IAAJ,CAAS,CAAC,CAAC,KAAF,EAAT,CAAJ;EAAA,CAAX,CAAP;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Recurrent Neural Network Layers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, SymbolicTensor } from '../engine/topology';\nimport { Layer } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { getInitializer, Initializer, Ones, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport * as math_utils from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor, isArrayOfShapes } from '../utils/types_utils';\nimport { batchGetValue, batchSetValue } from '../variables';\nimport { deserialize } from './serialization';\n/**\n * Standardize `apply()` args to a single list of tensor inputs.\n *\n * When running a model loaded from file, the input tensors `initialState` and\n * `constants` are passed to `RNN.apply()` as part of `inputs` instead of the\n * dedicated kwargs fields. `inputs` consists of\n * `[inputs, initialState0, initialState1, ..., constant0, constant1]` in this\n * case.\n * This method makes sure that arguments are\n * separated and that `initialState` and `constants` are `Array`s of tensors\n * (or None).\n *\n * @param inputs Tensor or `Array` of  tensors.\n * @param initialState Tensor or `Array` of tensors or `null`/`undefined`.\n * @param constants Tensor or `Array` of tensors or `null`/`undefined`.\n * @returns An object consisting of\n *   inputs: A tensor.\n *   initialState: `Array` of tensors or `null`.\n *   constants: `Array` of tensors or `null`.\n * @throws ValueError, if `inputs` is an `Array` but either `initialState` or\n *   `constants` is provided.\n */\nexport function standardizeArgs(inputs, initialState, constants, numConstants) {\n    if (Array.isArray(inputs)) {\n        if (initialState != null || constants != null) {\n            throw new ValueError('When inputs is an array, neither initialState or constants ' +\n                'should be provided');\n        }\n        if (numConstants != null) {\n            constants = inputs.slice(inputs.length - numConstants, inputs.length);\n            inputs = inputs.slice(0, inputs.length - numConstants);\n        }\n        if (inputs.length > 1) {\n            initialState = inputs.slice(1, inputs.length);\n        }\n        inputs = inputs[0];\n    }\n    function toListOrNull(x) {\n        if (x == null || Array.isArray(x)) {\n            return x;\n        }\n        else {\n            return [x];\n        }\n    }\n    initialState = toListOrNull(initialState);\n    constants = toListOrNull(constants);\n    return { inputs, initialState, constants };\n}\n/**\n * Iterates over the time dimension of a tensor.\n *\n * @param stepFunction RNN step function.\n *   Parameters:\n *     inputs: tensor with shape `[samples, ...]` (no time dimension),\n *       representing input for the batch of samples at a certain time step.\n *     states: an Array of tensors.\n *   Returns:\n *     outputs: tensor with shape `[samples, outputDim]` (no time dimension).\n *     newStates: list of tensors, same length and shapes as `states`. The first\n *       state in the list must be the output tensor at the previous timestep.\n * @param inputs Tensor of temporal data of shape `[samples, time, ...]` (at\n *   least 3D).\n * @param initialStates Tensor with shape `[samples, outputDim]` (no time\n *   dimension), containing the initial values of the states used in the step\n *   function.\n * @param goBackwards If `true`, do the iteration over the time dimension in\n *   reverse order and return the reversed sequence.\n * @param mask Binary tensor with shape `[sample, time, 1]`, with a zero for\n *   every element that is masked.\n * @param constants An Array of constant values passed at each step.\n * @param unroll Whether to unroll the RNN or to use a symbolic loop. *Not*\n *   applicable to this imperative deeplearn.js backend. Its value is ignored.\n * @param needPerStepOutputs Whether the per-step outputs are to be\n *   concatenated into a single tensor and returned (as the second return\n *   value). Default: `false`. This arg is included so that the relatively\n *   expensive concatenation of the stepwise outputs can be omitted unless\n *   the stepwise outputs need to be kept (e.g., for an LSTM layer of which\n *   `returnSequence` is `true`.)\n * @returns An Array: `[lastOutput, outputs, newStates]`.\n *   lastOutput: the lastest output of the RNN, of shape `[samples, ...]`.\n *   outputs: tensor with shape `[samples, time, ...]` where each entry\n *     `output[s, t]` is the output of the step function at time `t` for sample\n *     `s`. This return value is provided if and only if the\n *     `needPerStepOutputs` is set as `true`. If it is set as `false`, this\n *     return value will be `undefined`.\n *   newStates: Array of tensors, latest states returned by the step function,\n *      of shape `(samples, ...)`.\n * @throws ValueError If input dimension is less than 3.\n *\n * TODO(nielsene): This needs to be tidy-ed.\n */\nexport function rnn(stepFunction, inputs, initialStates, goBackwards = false, mask, constants, unroll = false, needPerStepOutputs = false) {\n    return tfc.tidy(() => {\n        const ndim = inputs.shape.length;\n        if (ndim < 3) {\n            throw new ValueError(`Input should be at least 3D, but is ${ndim}D.`);\n        }\n        // Transpose to time-major, i.e., from [batch, time, ...] to [time, batch,\n        // ...].\n        const axes = [1, 0].concat(math_utils.range(2, ndim));\n        inputs = tfc.transpose(inputs, axes);\n        if (constants != null) {\n            throw new NotImplementedError('The rnn() functoin of the deeplearn.js backend does not support ' +\n                'constants yet.');\n        }\n        // Porting Note: the unroll option is ignored by the imperative backend.\n        if (unroll) {\n            console.warn('Backend rnn(): the unroll = true option is not applicable to the ' +\n                'imperative deeplearn.js backend.');\n        }\n        if (mask != null) {\n            mask = mask.asType('bool').asType('float32');\n            if (mask.rank === ndim - 1) {\n                mask = tfc.expandDims(mask, -1);\n            }\n            mask = tfc.transpose(mask, axes);\n        }\n        if (goBackwards) {\n            inputs = tfc.reverse(inputs, 0);\n            if (mask != null) {\n                mask = tfc.reverse(mask, 0);\n            }\n        }\n        // Porting Note: PyKeras with TensorFlow backend uses a symbolic loop\n        //   (tf.while_loop). But for the imperative deeplearn.js backend, we just\n        //   use the usual TypeScript control flow to iterate over the time steps in\n        //   the inputs.\n        // Porting Note: PyKeras patches a \"_use_learning_phase\" attribute to\n        // outputs.\n        //   This is not idiomatic in TypeScript. The info regarding whether we are\n        //   in a learning (i.e., training) phase for RNN is passed in a different\n        //   way.\n        const perStepOutputs = [];\n        let lastOutput;\n        let states = initialStates;\n        const timeSteps = inputs.shape[0];\n        const perStepInputs = tfc.unstack(inputs);\n        let perStepMasks;\n        if (mask != null) {\n            perStepMasks = tfc.unstack(mask);\n        }\n        for (let t = 0; t < timeSteps; ++t) {\n            const currentInput = perStepInputs[t];\n            const stepOutputs = tfc.tidy(() => stepFunction(currentInput, states));\n            if (mask == null) {\n                lastOutput = stepOutputs[0];\n                states = stepOutputs[1];\n            }\n            else {\n                const maskedOutputs = tfc.tidy(() => {\n                    const stepMask = perStepMasks[t];\n                    const negStepMask = tfc.onesLike(stepMask).sub(stepMask);\n                    // TODO(cais): Would tfc.where() be better for performance?\n                    const output = stepOutputs[0].mul(stepMask).add(states[0].mul(negStepMask));\n                    const newStates = states.map((state, i) => {\n                        return stepOutputs[1][i].mul(stepMask).add(state.mul(negStepMask));\n                    });\n                    return { output, newStates };\n                });\n                lastOutput = maskedOutputs.output;\n                states = maskedOutputs.newStates;\n            }\n            if (needPerStepOutputs) {\n                perStepOutputs.push(lastOutput);\n            }\n        }\n        let outputs;\n        if (needPerStepOutputs) {\n            const axis = 1;\n            outputs = tfc.stack(perStepOutputs, axis);\n        }\n        return [lastOutput, outputs, states];\n    });\n}\nexport class RNN extends Layer {\n    constructor(args) {\n        super(args);\n        let cell;\n        if (args.cell == null) {\n            throw new ValueError('cell property is missing for the constructor of RNN.');\n        }\n        else if (Array.isArray(args.cell)) {\n            cell = new StackedRNNCells({ cells: args.cell });\n        }\n        else {\n            cell = args.cell;\n        }\n        if (cell.stateSize == null) {\n            throw new ValueError('The RNN cell should have an attribute `stateSize` (tuple of ' +\n                'integers, one integer per RNN state).');\n        }\n        this.cell = cell;\n        this.returnSequences =\n            args.returnSequences == null ? false : args.returnSequences;\n        this.returnState = args.returnState == null ? false : args.returnState;\n        this.goBackwards = args.goBackwards == null ? false : args.goBackwards;\n        this._stateful = args.stateful == null ? false : args.stateful;\n        this.unroll = args.unroll == null ? false : args.unroll;\n        this.supportsMasking = true;\n        this.inputSpec = [new InputSpec({ ndim: 3 })];\n        this.stateSpec = null;\n        this.states_ = null;\n        // TODO(cais): Add constantsSpec and numConstants.\n        this.numConstants = null;\n        // TODO(cais): Look into the use of initial_state in the kwargs of the\n        //   constructor.\n        this.keptStates = [];\n    }\n    // Porting Note: This is the equivalent of `RNN.states` property getter in\n    //   PyKeras.\n    getStates() {\n        if (this.states_ == null) {\n            const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n            return math_utils.range(0, numStates).map(x => null);\n        }\n        else {\n            return this.states_;\n        }\n    }\n    // Porting Note: This is the equivalent of the `RNN.states` property setter in\n    //   PyKeras.\n    setStates(states) {\n        this.states_ = states;\n    }\n    computeOutputShape(inputShape) {\n        if (isArrayOfShapes(inputShape)) {\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        // TODO(cais): Remove the casting once stacked RNN cells become supported.\n        let stateSize = this.cell.stateSize;\n        if (!Array.isArray(stateSize)) {\n            stateSize = [stateSize];\n        }\n        const outputDim = stateSize[0];\n        let outputShape;\n        if (this.returnSequences) {\n            outputShape = [inputShape[0], inputShape[1], outputDim];\n        }\n        else {\n            outputShape = [inputShape[0], outputDim];\n        }\n        if (this.returnState) {\n            const stateShape = [];\n            for (const dim of stateSize) {\n                stateShape.push([inputShape[0], dim]);\n            }\n            return [outputShape].concat(stateShape);\n        }\n        else {\n            return outputShape;\n        }\n    }\n    computeMask(inputs, mask) {\n        return tfc.tidy(() => {\n            if (Array.isArray(mask)) {\n                mask = mask[0];\n            }\n            const outputMask = this.returnSequences ? mask : null;\n            if (this.returnState) {\n                const stateMask = this.states.map(s => null);\n                return [outputMask].concat(stateMask);\n            }\n            else {\n                return outputMask;\n            }\n        });\n    }\n    /**\n     * Get the current state tensors of the RNN.\n     *\n     * If the state hasn't been set, return an array of `null`s of the correct\n     * length.\n     */\n    get states() {\n        if (this.states_ == null) {\n            const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n            const output = [];\n            for (let i = 0; i < numStates; ++i) {\n                output.push(null);\n            }\n            return output;\n        }\n        else {\n            return this.states_;\n        }\n    }\n    set states(s) {\n        this.states_ = s;\n    }\n    build(inputShape) {\n        // Note inputShape will be an Array of Shapes of initial states and\n        // constants if these are passed in apply().\n        const constantShape = null;\n        if (this.numConstants != null) {\n            throw new NotImplementedError('Constants support is not implemented in RNN yet.');\n        }\n        if (isArrayOfShapes(inputShape)) {\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        const batchSize = this.stateful ? inputShape[0] : null;\n        const inputDim = inputShape.slice(2);\n        this.inputSpec[0] = new InputSpec({ shape: [batchSize, null, ...inputDim] });\n        // Allow cell (if RNNCell Layer) to build before we set or validate\n        // stateSpec.\n        const stepInputShape = [inputShape[0]].concat(inputShape.slice(2));\n        if (constantShape != null) {\n            throw new NotImplementedError('Constants support is not implemented in RNN yet.');\n        }\n        else {\n            this.cell.build(stepInputShape);\n        }\n        // Set or validate stateSpec.\n        let stateSize;\n        if (Array.isArray(this.cell.stateSize)) {\n            stateSize = this.cell.stateSize;\n        }\n        else {\n            stateSize = [this.cell.stateSize];\n        }\n        if (this.stateSpec != null) {\n            if (!util.arraysEqual(this.stateSpec.map(spec => spec.shape[spec.shape.length - 1]), stateSize)) {\n                throw new ValueError(`An initialState was passed that is not compatible with ` +\n                    `cell.stateSize. Received stateSpec=${this.stateSpec}; ` +\n                    `However cell.stateSize is ${this.cell.stateSize}`);\n            }\n        }\n        else {\n            this.stateSpec =\n                stateSize.map(dim => new InputSpec({ shape: [null, dim] }));\n        }\n        if (this.stateful) {\n            this.resetStates();\n        }\n    }\n    /**\n     * Reset the state tensors of the RNN.\n     *\n     * If the `states` argument is `undefined` or `null`, will set the\n     * state tensor(s) of the RNN to all-zero tensors of the appropriate\n     * shape(s).\n     *\n     * If `states` is provided, will set the state tensors of the RNN to its\n     * value.\n     *\n     * @param states Optional externally-provided initial states.\n     * @param training Whether this call is done during training. For stateful\n     *   RNNs, this affects whether the old states are kept or discarded. In\n     *   particular, if `training` is `true`, the old states will be kept so\n     *   that subsequent backpropgataion through time (BPTT) may work properly.\n     *   Else, the old states will be discarded.\n     */\n    resetStates(states, training = false) {\n        tidy(() => {\n            if (!this.stateful) {\n                throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n            }\n            const batchSize = this.inputSpec[0].shape[0];\n            if (batchSize == null) {\n                throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' +\n                    'the batch size of your input tensors: \\n' +\n                    '- If using a Sequential model, specify the batch size by ' +\n                    'passing a `batchInputShape` option to your first layer.\\n' +\n                    '- If using the functional API, specify the batch size by ' +\n                    'passing a `batchShape` option to your Input layer.');\n            }\n            // Initialize state if null.\n            if (this.states_ == null) {\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ =\n                        this.cell.stateSize.map(dim => tfc.zeros([batchSize, dim]));\n                }\n                else {\n                    this.states_ = [tfc.zeros([batchSize, this.cell.stateSize])];\n                }\n            }\n            else if (states == null) {\n                // Dispose old state tensors.\n                tfc.dispose(this.states_);\n                // For stateful RNNs, fully dispose kept old states.\n                if (this.keptStates != null) {\n                    tfc.dispose(this.keptStates);\n                    this.keptStates = [];\n                }\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ =\n                        this.cell.stateSize.map(dim => tfc.zeros([batchSize, dim]));\n                }\n                else {\n                    this.states_[0] = tfc.zeros([batchSize, this.cell.stateSize]);\n                }\n            }\n            else {\n                if (!Array.isArray(states)) {\n                    states = [states];\n                }\n                if (states.length !== this.states_.length) {\n                    throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), ` +\n                        `but it received ${states.length} state value(s). Input ` +\n                        `received: ${states}`);\n                }\n                if (training === true) {\n                    // Store old state tensors for complete disposal later, i.e., during\n                    // the next no-arg call to this method. We do not dispose the old\n                    // states immediately because that BPTT (among other things) require\n                    // them.\n                    this.keptStates.push(this.states_.slice());\n                }\n                else {\n                    tfc.dispose(this.states_);\n                }\n                for (let index = 0; index < this.states_.length; ++index) {\n                    const value = states[index];\n                    const dim = Array.isArray(this.cell.stateSize) ?\n                        this.cell.stateSize[index] :\n                        this.cell.stateSize;\n                    const expectedShape = [batchSize, dim];\n                    if (!util.arraysEqual(value.shape, expectedShape)) {\n                        throw new ValueError(`State ${index} is incompatible with layer ${this.name}: ` +\n                            `expected shape=${expectedShape}, received shape=${value.shape}`);\n                    }\n                    this.states_[index] = value;\n                }\n            }\n            this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n        });\n    }\n    apply(inputs, kwargs) {\n        // TODO(cais): Figure out whether initialState is in kwargs or inputs.\n        let initialState = kwargs == null ? null : kwargs['initialState'];\n        let constants = kwargs == null ? null : kwargs['constants'];\n        if (kwargs == null) {\n            kwargs = {};\n        }\n        const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);\n        inputs = standardized.inputs;\n        initialState = standardized.initialState;\n        constants = standardized.constants;\n        // If any of `initial_state` or `constants` are specified and are\n        // `tf.SymbolicTensor`s, then add them to the inputs and temporarily modify\n        // the input_spec to include them.\n        let additionalInputs = [];\n        let additionalSpecs = [];\n        if (initialState != null) {\n            kwargs['initialState'] = initialState;\n            additionalInputs = additionalInputs.concat(initialState);\n            this.stateSpec = [];\n            for (const state of initialState) {\n                this.stateSpec.push(new InputSpec({ shape: state.shape }));\n            }\n            // TODO(cais): Use the following instead.\n            // this.stateSpec = initialState.map(state => new InputSpec({shape:\n            // state.shape}));\n            additionalSpecs = additionalSpecs.concat(this.stateSpec);\n        }\n        if (constants != null) {\n            kwargs['constants'] = constants;\n            additionalInputs = additionalInputs.concat(constants);\n            // TODO(cais): Add this.constantsSpec.\n            this.numConstants = constants.length;\n        }\n        const isTensor = additionalInputs[0] instanceof SymbolicTensor;\n        if (isTensor) {\n            // Compute full input spec, including state and constants.\n            const fullInput = [inputs].concat(additionalInputs);\n            const fullInputSpec = this.inputSpec.concat(additionalSpecs);\n            // Perform the call with temporarily replaced inputSpec.\n            const originalInputSpec = this.inputSpec;\n            this.inputSpec = fullInputSpec;\n            const output = super.apply(fullInput, kwargs);\n            this.inputSpec = originalInputSpec;\n            return output;\n        }\n        else {\n            return super.apply(inputs, kwargs);\n        }\n    }\n    // tslint:disable-next-line:no-any\n    call(inputs, kwargs) {\n        // Input shape: `[samples, time (padded with zeros), input_dim]`.\n        // Note that the .build() method of subclasses **must** define\n        // this.inputSpec and this.stateSpec owith complete input shapes.\n        return tidy(() => {\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            let initialState = kwargs == null ? null : kwargs['initialState'];\n            inputs = getExactlyOneTensor(inputs);\n            if (initialState == null) {\n                if (this.stateful) {\n                    initialState = this.states_;\n                }\n                else {\n                    initialState = this.getInitialState(inputs);\n                }\n            }\n            const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n            if (initialState.length !== numStates) {\n                throw new ValueError(`RNN Layer has ${numStates} state(s) but was passed ` +\n                    `${initialState.length} initial state(s).`);\n            }\n            if (this.unroll) {\n                console.warn('Ignoring unroll = true for RNN layer, due to imperative backend.');\n            }\n            const cellCallKwargs = { training };\n            // TODO(cais): Add support for constants.\n            const step = (inputs, states) => {\n                // `inputs` and `states` are concatenated to form a single `Array` of\n                // `tf.Tensor`s as the input to `cell.call()`.\n                const outputs = this.cell.call([inputs].concat(states), cellCallKwargs);\n                // Marshall the return value into output and new states.\n                return [outputs[0], outputs.slice(1)];\n            };\n            // TODO(cais): Add support for constants.\n            const rnnOutputs = rnn(step, inputs, initialState, this.goBackwards, mask, null, this.unroll, this.returnSequences);\n            const lastOutput = rnnOutputs[0];\n            const outputs = rnnOutputs[1];\n            const states = rnnOutputs[2];\n            if (this.stateful) {\n                this.resetStates(states, training);\n            }\n            const output = this.returnSequences ? outputs : lastOutput;\n            // TODO(cais): Porperty set learning phase flag.\n            if (this.returnState) {\n                return [output].concat(states);\n            }\n            else {\n                return output;\n            }\n        });\n    }\n    getInitialState(inputs) {\n        return tidy(() => {\n            // Build an all-zero tensor of shape [samples, outputDim].\n            // [Samples, timeSteps, inputDim].\n            let initialState = tfc.zeros(inputs.shape);\n            // [Samples].\n            initialState = tfc.sum(initialState, [1, 2]);\n            initialState = K.expandDims(initialState); // [Samples, 1].\n            if (Array.isArray(this.cell.stateSize)) {\n                return this.cell.stateSize.map(dim => dim > 1 ? K.tile(initialState, [1, dim]) : initialState);\n            }\n            else {\n                return this.cell.stateSize > 1 ?\n                    [K.tile(initialState, [1, this.cell.stateSize])] :\n                    [initialState];\n            }\n        });\n    }\n    get trainableWeights() {\n        if (!this.trainable) {\n            return [];\n        }\n        // Porting Note: In TypeScript, `this` is always an instance of `Layer`.\n        return this.cell.trainableWeights;\n    }\n    get nonTrainableWeights() {\n        // Porting Note: In TypeScript, `this` is always an instance of `Layer`.\n        if (!this.trainable) {\n            return this.cell.weights;\n        }\n        return this.cell.nonTrainableWeights;\n    }\n    setFastWeightInitDuringBuild(value) {\n        super.setFastWeightInitDuringBuild(value);\n        if (this.cell != null) {\n            this.cell.setFastWeightInitDuringBuild(value);\n        }\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = {\n            returnSequences: this.returnSequences,\n            returnState: this.returnState,\n            goBackwards: this.goBackwards,\n            stateful: this.stateful,\n            unroll: this.unroll,\n        };\n        if (this.numConstants != null) {\n            config['numConstants'] = this.numConstants;\n        }\n        const cellConfig = this.cell.getConfig();\n        if (this.getClassName() === RNN.className) {\n            config['cell'] = {\n                'className': this.cell.getClassName(),\n                'config': cellConfig,\n            };\n        }\n        // this order is necessary, to prevent cell name from replacing layer name\n        return Object.assign({}, cellConfig, baseConfig, config);\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config, customObjects = {}) {\n        const cellConfig = config['cell'];\n        const cell = deserialize(cellConfig, customObjects);\n        return new cls(Object.assign(config, { cell }));\n    }\n}\n/** @nocollapse */\nRNN.className = 'RNN';\nserialization.registerClass(RNN);\n// Porting Note: This is a common parent class for RNN cells. There is no\n// equivalent of this in PyKeras. Having a common parent class forgoes the\n//  need for `has_attr(cell, ...)` checks or its TypeScript equivalent.\n/**\n * An RNNCell layer.\n *\n * @doc {heading: 'Layers', subheading: 'Classes'}\n */\nexport class RNNCell extends Layer {\n}\nexport class SimpleRNNCell extends RNNCell {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_ACTIVATION = 'tanh';\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        this.units = args.units;\n        assertPositiveInteger(this.units, `units`);\n        this.activation = getActivation(args.activation == null ? this.DEFAULT_ACTIVATION : args.activation);\n        this.useBias = args.useBias == null ? true : args.useBias;\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n        this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n        ]);\n        this.stateSize = this.units;\n        this.dropoutMask = null;\n        this.recurrentDropoutMask = null;\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        // TODO(cais): Use regularizer.\n        this.kernel = this.addWeight('kernel', [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.built = true;\n    }\n    // Porting Note: PyKeras' equivalent of this method takes two tensor inputs:\n    //   `inputs` and `states`. Here, the two tensors are combined into an\n    //   `Tensor[]` Array as the first input argument.\n    //   Similarly, PyKeras' equivalent of this method returns two values:\n    //    `output` and `[output]`. Here the two are combined into one length-2\n    //    `Tensor[]`, consisting of `output` repeated.\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = inputs;\n            if (inputs.length !== 2) {\n                throw new ValueError(`SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);\n            }\n            let prevOutput = inputs[1];\n            inputs = inputs[0];\n            const training = kwargs['training'] == null ? false : kwargs['training'];\n            if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n                this.dropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(inputs),\n                    rate: this.dropout,\n                    training\n                });\n            }\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n                this.recurrentDropoutMask == null) {\n                this.recurrentDropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(prevOutput),\n                    rate: this.recurrentDropout,\n                    training\n                });\n            }\n            let h;\n            const dpMask = this.dropoutMask;\n            const recDpMask = this.recurrentDropoutMask;\n            if (dpMask != null) {\n                h = K.dot(tfc.mul(inputs, dpMask), this.kernel.read());\n            }\n            else {\n                h = K.dot(inputs, this.kernel.read());\n            }\n            if (this.bias != null) {\n                h = K.biasAdd(h, this.bias.read());\n            }\n            if (recDpMask != null) {\n                prevOutput = tfc.mul(prevOutput, recDpMask);\n            }\n            let output = tfc.add(h, K.dot(prevOutput, this.recurrentKernel.read()));\n            if (this.activation != null) {\n                output = this.activation.apply(output);\n            }\n            // TODO(cais): Properly set learning phase on output tensor?\n            return [output, output];\n        });\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n        };\n        return Object.assign({}, baseConfig, config);\n    }\n}\n/** @nocollapse */\nSimpleRNNCell.className = 'SimpleRNNCell';\nserialization.registerClass(SimpleRNNCell);\nexport class SimpleRNN extends RNN {\n    constructor(args) {\n        args.cell = new SimpleRNNCell(args);\n        super(args);\n        // TODO(cais): Add activityRegularizer.\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            if (this.cell.dropoutMask != null) {\n                tfc.dispose(this.cell.dropoutMask);\n                this.cell.dropoutMask = null;\n            }\n            if (this.cell.recurrentDropoutMask != null) {\n                tfc.dispose(this.cell.recurrentDropoutMask);\n                this.cell.recurrentDropoutMask = null;\n            }\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            const initialState = kwargs == null ? null : kwargs['initialState'];\n            return super.call(inputs, { mask, training, initialState });\n        });\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config);\n    }\n}\n/** @nocollapse */\nSimpleRNN.className = 'SimpleRNN';\nserialization.registerClass(SimpleRNN);\nexport class GRUCell extends RNNCell {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_ACTIVATION = 'tanh';\n        this.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        if (args.resetAfter) {\n            throw new ValueError(`GRUCell does not support reset_after parameter set to true.`);\n        }\n        this.units = args.units;\n        assertPositiveInteger(this.units, 'units');\n        this.activation = getActivation(args.activation === undefined ? this.DEFAULT_ACTIVATION :\n            args.activation);\n        this.recurrentActivation = getActivation(args.recurrentActivation === undefined ?\n            this.DEFAULT_RECURRENT_ACTIVATION :\n            args.recurrentActivation);\n        this.useBias = args.useBias == null ? true : args.useBias;\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n        this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n        ]);\n        this.implementation = args.implementation;\n        this.stateSize = this.units;\n        this.dropoutMask = null;\n        this.recurrentDropoutMask = null;\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const inputDim = inputShape[inputShape.length - 1];\n        this.kernel = this.addWeight('kernel', [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        // Porting Notes: Unlike the PyKeras implementation, we perform slicing\n        //   of the weights and bias in the call() method, at execution time.\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = inputs;\n            if (inputs.length !== 2) {\n                throw new ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ` +\n                    `${inputs.length}.`);\n            }\n            const training = kwargs['training'] == null ? false : kwargs['training'];\n            let hTMinus1 = inputs[1]; // Previous memory state.\n            inputs = inputs[0];\n            // Note: For superior performance, TensorFlow.js always uses\n            // implementation 2, regardless of the actual value of\n            // config.implementation.\n            if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n                this.dropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(inputs),\n                    rate: this.dropout,\n                    training,\n                    count: 3\n                });\n            }\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n                this.recurrentDropoutMask == null) {\n                this.recurrentDropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(hTMinus1),\n                    rate: this.recurrentDropout,\n                    training,\n                    count: 3\n                });\n            }\n            const dpMask = this.dropoutMask;\n            const recDpMask = this.recurrentDropoutMask;\n            let z;\n            let r;\n            let hh;\n            if (0 < this.dropout && this.dropout < 1) {\n                inputs = tfc.mul(inputs, dpMask[0]);\n            }\n            let matrixX = K.dot(inputs, this.kernel.read());\n            if (this.useBias) {\n                matrixX = K.biasAdd(matrixX, this.bias.read());\n            }\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1) {\n                hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n            }\n            const recurrentKernelValue = this.recurrentKernel.read();\n            const [rk1, rk2] = tfc.split(recurrentKernelValue, [2 * this.units, this.units], recurrentKernelValue.rank - 1);\n            const matrixInner = K.dot(hTMinus1, rk1);\n            const [xZ, xR, xH] = tfc.split(matrixX, 3, matrixX.rank - 1);\n            const [recurrentZ, recurrentR] = tfc.split(matrixInner, 2, matrixInner.rank - 1);\n            z = this.recurrentActivation.apply(tfc.add(xZ, recurrentZ));\n            r = this.recurrentActivation.apply(tfc.add(xR, recurrentR));\n            const recurrentH = K.dot(tfc.mul(r, hTMinus1), rk2);\n            hh = this.activation.apply(tfc.add(xH, recurrentH));\n            const h = tfc.add(tfc.mul(z, hTMinus1), tfc.mul(tfc.add(1, tfc.neg(z)), hh));\n            // TODO(cais): Add use_learning_phase flag properly.\n            return [h, h];\n        });\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            recurrentActivation: serializeActivation(this.recurrentActivation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n            resetAfter: false\n        };\n        return Object.assign({}, baseConfig, config);\n    }\n}\n/** @nocollapse */\nGRUCell.className = 'GRUCell';\nserialization.registerClass(GRUCell);\nexport class GRU extends RNN {\n    constructor(args) {\n        if (args.implementation === 0) {\n            console.warn('`implementation=0` has been deprecated, and now defaults to ' +\n                '`implementation=1`. Please update your layer call.');\n        }\n        args.cell = new GRUCell(args);\n        super(args);\n        // TODO(cais): Add activityRegularizer.\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            if (this.cell.dropoutMask != null) {\n                tfc.dispose(this.cell.dropoutMask);\n                this.cell.dropoutMask = null;\n            }\n            if (this.cell.recurrentDropoutMask != null) {\n                tfc.dispose(this.cell.recurrentDropoutMask);\n                this.cell.recurrentDropoutMask = null;\n            }\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            const initialState = kwargs == null ? null : kwargs['initialState'];\n            return super.call(inputs, { mask, training, initialState });\n        });\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        if (config['implmentation'] === 0) {\n            config['implementation'] = 1;\n        }\n        return new cls(config);\n    }\n}\n/** @nocollapse */\nGRU.className = 'GRU';\nserialization.registerClass(GRU);\nexport class LSTMCell extends RNNCell {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_ACTIVATION = 'tanh';\n        this.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        this.units = args.units;\n        assertPositiveInteger(this.units, 'units');\n        this.activation = getActivation(args.activation === undefined ? this.DEFAULT_ACTIVATION :\n            args.activation);\n        this.recurrentActivation = getActivation(args.recurrentActivation === undefined ?\n            this.DEFAULT_RECURRENT_ACTIVATION :\n            args.recurrentActivation);\n        this.useBias = args.useBias == null ? true : args.useBias;\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.unitForgetBias = args.unitForgetBias;\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.dropout = math_utils.min([1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n        this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n        ]);\n        this.implementation = args.implementation;\n        this.stateSize = [this.units, this.units];\n        this.dropoutMask = null;\n        this.recurrentDropoutMask = null;\n    }\n    build(inputShape) {\n        var _a;\n        inputShape = getExactlyOneShape(inputShape);\n        const inputDim = inputShape[inputShape.length - 1];\n        this.kernel = this.addWeight('kernel', [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        let biasInitializer;\n        if (this.useBias) {\n            if (this.unitForgetBias) {\n                const capturedBiasInit = this.biasInitializer;\n                const capturedUnits = this.units;\n                biasInitializer = new (_a = class CustomInit extends Initializer {\n                        apply(shape, dtype) {\n                            // TODO(cais): More informative variable names?\n                            const bI = capturedBiasInit.apply([capturedUnits]);\n                            const bF = (new Ones()).apply([capturedUnits]);\n                            const bCAndH = capturedBiasInit.apply([capturedUnits * 2]);\n                            return K.concatAlongFirstAxis(K.concatAlongFirstAxis(bI, bF), bCAndH);\n                        }\n                    },\n                    /** @nocollapse */\n                    _a.className = 'CustomInit',\n                    _a)();\n            }\n            else {\n                biasInitializer = this.biasInitializer;\n            }\n            this.bias = this.addWeight('bias', [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        // Porting Notes: Unlike the PyKeras implementation, we perform slicing\n        //   of the weights and bias in the call() method, at execution time.\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            const training = kwargs['training'] == null ? false : kwargs['training'];\n            inputs = inputs;\n            if (inputs.length !== 3) {\n                throw new ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ` +\n                    `${inputs.length}.`);\n            }\n            let hTMinus1 = inputs[1]; // Previous memory state.\n            const cTMinus1 = inputs[2]; // Previous carry state.\n            inputs = inputs[0];\n            if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n                this.dropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(inputs),\n                    rate: this.dropout,\n                    training,\n                    count: 4\n                });\n            }\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n                this.recurrentDropoutMask == null) {\n                this.recurrentDropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(hTMinus1),\n                    rate: this.recurrentDropout,\n                    training,\n                    count: 4\n                });\n            }\n            const dpMask = this.dropoutMask;\n            const recDpMask = this.recurrentDropoutMask;\n            // Note: For superior performance, TensorFlow.js always uses\n            // implementation 2 regardless of the actual value of\n            // config.implementation.\n            let i;\n            let f;\n            let c;\n            let o;\n            if (0 < this.dropout && this.dropout < 1) {\n                inputs = tfc.mul(inputs, dpMask[0]);\n            }\n            let z = K.dot(inputs, this.kernel.read());\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1) {\n                hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n            }\n            z = tfc.add(z, K.dot(hTMinus1, this.recurrentKernel.read()));\n            if (this.useBias) {\n                z = K.biasAdd(z, this.bias.read());\n            }\n            const [z0, z1, z2, z3] = tfc.split(z, 4, z.rank - 1);\n            i = this.recurrentActivation.apply(z0);\n            f = this.recurrentActivation.apply(z1);\n            c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(z2)));\n            o = this.recurrentActivation.apply(z3);\n            const h = tfc.mul(o, this.activation.apply(c));\n            // TODO(cais): Add use_learning_phase flag properly.\n            return [h, h, c];\n        });\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            recurrentActivation: serializeActivation(this.recurrentActivation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            unitForgetBias: this.unitForgetBias,\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n        };\n        return Object.assign({}, baseConfig, config);\n    }\n}\n/** @nocollapse */\nLSTMCell.className = 'LSTMCell';\nserialization.registerClass(LSTMCell);\nexport class LSTM extends RNN {\n    constructor(args) {\n        if (args.implementation === 0) {\n            console.warn('`implementation=0` has been deprecated, and now defaults to ' +\n                '`implementation=1`. Please update your layer call.');\n        }\n        args.cell = new LSTMCell(args);\n        super(args);\n        // TODO(cais): Add activityRegularizer.\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            if (this.cell.dropoutMask != null) {\n                tfc.dispose(this.cell.dropoutMask);\n                this.cell.dropoutMask = null;\n            }\n            if (this.cell.recurrentDropoutMask != null) {\n                tfc.dispose(this.cell.recurrentDropoutMask);\n                this.cell.recurrentDropoutMask = null;\n            }\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            const initialState = kwargs == null ? null : kwargs['initialState'];\n            return super.call(inputs, { mask, training, initialState });\n        });\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        if (config['implmentation'] === 0) {\n            config['implementation'] = 1;\n        }\n        return new cls(config);\n    }\n}\n/** @nocollapse */\nLSTM.className = 'LSTM';\nserialization.registerClass(LSTM);\nexport class StackedRNNCells extends RNNCell {\n    constructor(args) {\n        super(args);\n        this.cells = args.cells;\n    }\n    get stateSize() {\n        // States are a flat list in reverse order of the cell stack.\n        // This allows perserving the requirement `stack.statesize[0] ===\n        // outputDim`. E.g., states of a 2-layer LSTM would be `[h2, c2, h1, c1]`,\n        // assuming one LSTM has states `[h, c]`.\n        const stateSize = [];\n        for (const cell of this.cells.slice().reverse()) {\n            if (Array.isArray(cell.stateSize)) {\n                stateSize.push(...cell.stateSize);\n            }\n            else {\n                stateSize.push(cell.stateSize);\n            }\n        }\n        return stateSize;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = inputs;\n            let states = inputs.slice(1);\n            // Recover per-cell states.\n            const nestedStates = [];\n            for (const cell of this.cells.slice().reverse()) {\n                if (Array.isArray(cell.stateSize)) {\n                    nestedStates.push(states.splice(0, cell.stateSize.length));\n                }\n                else {\n                    nestedStates.push(states.splice(0, 1));\n                }\n            }\n            nestedStates.reverse();\n            // Call the cells in order and store the returned states.\n            const newNestedStates = [];\n            let callInputs;\n            for (let i = 0; i < this.cells.length; ++i) {\n                const cell = this.cells[i];\n                states = nestedStates[i];\n                // TODO(cais): Take care of constants.\n                if (i === 0) {\n                    callInputs = [inputs[0]].concat(states);\n                }\n                else {\n                    callInputs = [callInputs[0]].concat(states);\n                }\n                callInputs = cell.call(callInputs, kwargs);\n                newNestedStates.push(callInputs.slice(1));\n            }\n            // Format the new states as a flat list in reverse cell order.\n            states = [];\n            for (const cellStates of newNestedStates.slice().reverse()) {\n                states.push(...cellStates);\n            }\n            return [callInputs[0]].concat(states);\n        });\n    }\n    build(inputShape) {\n        if (isArrayOfShapes(inputShape)) {\n            // TODO(cais): Take care of input constants.\n            // const constantShape = inputShape.slice(1);\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        let outputDim;\n        this.cells.forEach((cell, i) => {\n            nameScope(`RNNCell_${i}`, () => {\n                // TODO(cais): Take care of input constants.\n                cell.build(inputShape);\n                if (Array.isArray(cell.stateSize)) {\n                    outputDim = cell.stateSize[0];\n                }\n                else {\n                    outputDim = cell.stateSize;\n                }\n                inputShape = [inputShape[0], outputDim];\n            });\n        });\n        this.built = true;\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const getCellConfig = (cell) => {\n            return {\n                'className': cell.getClassName(),\n                'config': cell.getConfig(),\n            };\n        };\n        const cellConfigs = this.cells.map(getCellConfig);\n        const config = { 'cells': cellConfigs };\n        return Object.assign({}, baseConfig, config);\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config, customObjects = {}) {\n        const cells = [];\n        for (const cellConfig of config['cells']) {\n            cells.push(deserialize(cellConfig, customObjects));\n        }\n        return new cls({ cells });\n    }\n    get trainableWeights() {\n        if (!this.trainable) {\n            return [];\n        }\n        const weights = [];\n        for (const cell of this.cells) {\n            weights.push(...cell.trainableWeights);\n        }\n        return weights;\n    }\n    get nonTrainableWeights() {\n        const weights = [];\n        for (const cell of this.cells) {\n            weights.push(...cell.nonTrainableWeights);\n        }\n        if (!this.trainable) {\n            const trainableWeights = [];\n            for (const cell of this.cells) {\n                trainableWeights.push(...cell.trainableWeights);\n            }\n            return trainableWeights.concat(weights);\n        }\n        return weights;\n    }\n    /**\n     * Retrieve the weights of a the model.\n     *\n     * @returns A flat `Array` of `tf.Tensor`s.\n     */\n    getWeights() {\n        const weights = [];\n        for (const cell of this.cells) {\n            weights.push(...cell.weights);\n        }\n        return batchGetValue(weights);\n    }\n    /**\n     * Set the weights of the model.\n     *\n     * @param weights An `Array` of `tf.Tensor`s with shapes and types matching\n     *     the output of `getWeights()`.\n     */\n    setWeights(weights) {\n        const tuples = [];\n        for (const cell of this.cells) {\n            const numParams = cell.weights.length;\n            const inputWeights = weights.splice(numParams);\n            for (let i = 0; i < cell.weights.length; ++i) {\n                tuples.push([cell.weights[i], inputWeights[i]]);\n            }\n        }\n        batchSetValue(tuples);\n    }\n}\n/** @nocollapse */\nStackedRNNCells.className = 'StackedRNNCells';\nserialization.registerClass(StackedRNNCells);\nexport function generateDropoutMask(args) {\n    const { ones, rate, training = false, count = 1 } = args;\n    const droppedInputs = () => K.dropout(ones(), rate);\n    const createMask = () => K.inTrainPhase(droppedInputs, ones, training);\n    // just in case count is provided with null or undefined\n    if (!count || count <= 1) {\n        return tfc.keep(createMask().clone());\n    }\n    const masks = Array(count).fill(undefined).map(createMask);\n    return masks.map(m => tfc.keep(m.clone()));\n}\n//# sourceMappingURL=recurrent.js.map"]},"metadata":{},"sourceType":"module"}