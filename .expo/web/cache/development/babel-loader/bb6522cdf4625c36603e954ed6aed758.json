{"ast":null,"code":"import _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport _assertThisInitialized from \"@babel/runtime/helpers/assertThisInitialized\";\nimport _inherits from \"@babel/runtime/helpers/inherits\";\nimport _possibleConstructorReturn from \"@babel/runtime/helpers/possibleConstructorReturn\";\nimport _getPrototypeOf from \"@babel/runtime/helpers/getPrototypeOf\";\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { serialization } from '@tensorflow/tfjs-core';\nimport { getUid } from \"../backend/state\";\nimport { ValueError } from \"../errors\";\nimport { Layer, Node, SymbolicTensor } from \"./topology\";\nexport var InputLayer = function (_Layer) {\n  _inherits(InputLayer, _Layer);\n\n  var _super = _createSuper(InputLayer);\n\n  function InputLayer(args) {\n    var _this;\n\n    _classCallCheck(this, InputLayer);\n\n    _this = _super.call(this, {\n      dtype: args.dtype,\n      name: args.name != null ? args.name : getUid('input').toString()\n    });\n\n    if (args.batchSize == null) {\n      args.batchSize = null;\n    }\n\n    if (args.sparse == null) {\n      args.sparse = false;\n    }\n\n    _this.trainable = false;\n    _this.built = true;\n    _this.sparse = args.sparse;\n\n    if (args.inputShape != null && args.batchInputShape != null) {\n      throw new ValueError('Only provide the inputShape OR ' + 'batchInputShape argument to inputLayer, not both at the same time.');\n    }\n\n    var batchInputShape = args.batchInputShape;\n\n    if (batchInputShape == null) {\n      if (args.inputShape == null) {\n        throw new ValueError('An InputLayer should be passed either a ' + '`batchInputShape` or an `inputShape`.');\n      } else {\n        batchInputShape = [args.batchSize].concat(args.inputShape);\n      }\n    } else {\n      if (args.batchSize != null) {\n        throw new ValueError('Cannot specify batchSize if batchInputShape is ' + 'specified when creating an InputLayer.');\n      }\n    }\n\n    var dtype = args.dtype || 'float32';\n    _this.batchInputShape = batchInputShape;\n    _this.dtype = dtype;\n    _this.inputSpec = [{\n      shape: batchInputShape\n    }];\n    var inputTensor = new SymbolicTensor(_this.dtype, _this.batchInputShape, _assertThisInitialized(_this), [], {}, _this.name);\n    inputTensor.nodeIndex = 0;\n    inputTensor.tensorIndex = 0;\n    new Node({\n      outboundLayer: _assertThisInitialized(_this),\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: [inputTensor],\n      outputTensors: [inputTensor],\n      inputMasks: [null],\n      outputMasks: [null],\n      inputShapes: [batchInputShape],\n      outputShapes: [batchInputShape]\n    });\n    return _this;\n  }\n\n  _createClass(InputLayer, [{\n    key: \"apply\",\n    value: function apply(inputs, kwargs) {\n      throw new ValueError('Cannot pass any input to an ' + (\"InputLayer's apply() method. InputLayer name: \" + this.name));\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      return {\n        refCountAfterDispose: this._refCount,\n        numDisposedVariables: 0\n      };\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        batchInputShape: this.batchInputShape,\n        dtype: this.dtype,\n        sparse: this.sparse,\n        name: this.name\n      };\n    }\n  }]);\n\n  return InputLayer;\n}(Layer);\nInputLayer.className = 'InputLayer';\nserialization.registerClass(InputLayer);\nexport function Input(config) {\n  if (config.batchShape == null && config.shape == null) {\n    throw new Error('Please provide to Input either a `shape`' + ' or a `batchShape` argument. Note that ' + '`shape` does not include the batch ' + 'dimension.');\n  }\n\n  if (config.batchShape != null && config.shape != null) {\n    throw new ValueError('Please provide either a `shape` or `batchShape` ' + 'argument to Input, but not both.');\n  }\n\n  var batchShape = config.batchShape;\n\n  if (config.shape != null && batchShape == null) {\n    batchShape = [null].concat(config.shape);\n  }\n\n  var dtype = config.dtype;\n\n  if (dtype == null) {\n    dtype = 'float32';\n  }\n\n  var inputLayer = new InputLayer({\n    batchInputShape: batchShape,\n    name: config.name,\n    dtype: dtype,\n    sparse: config.sparse\n  });\n  var outputs = inputLayer.inboundNodes[0].outputTensors;\n  return outputs[0];\n}","map":{"version":3,"sources":["../../src/engine/input_layer.ts"],"names":[],"mappings":";;;;;;;;;;;AAAA;;;;;;;;AAQG;AAEH,SAAkB,aAAlB,QAA8C,uBAA9C;AAEA,SAAQ,MAAR;AACA,SAAQ,UAAR;AAIA,SAAuB,KAAvB,EAA8B,IAA9B,EAAoC,cAApC;AA2BA,WAAa,UAAb;EAAA;;EAAA;;EAIE,oBAAY,IAAZ,EAAgC;IAAA;;IAAA;;IAC9B,0BAAM;MACJ,KAAK,EAAE,IAAI,CAAC,KADR;MAEJ,IAAI,EAAE,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,IAAI,CAAC,IAAzB,GAAgC,MAAM,CAAC,OAAD,CAAN,CAAgB,QAAhB;IAFlC,CAAN;;IAKA,IAAI,IAAI,CAAC,SAAL,IAAkB,IAAtB,EAA4B;MAC1B,IAAI,CAAC,SAAL,GAAiB,IAAjB;IACD;;IACD,IAAI,IAAI,CAAC,MAAL,IAAe,IAAnB,EAAyB;MACvB,IAAI,CAAC,MAAL,GAAc,KAAd;IACD;;IAED,MAAK,SAAL,GAAiB,KAAjB;IACA,MAAK,KAAL,GAAa,IAAb;IACA,MAAK,MAAL,GAAc,IAAI,CAAC,MAAnB;;IAEA,IAAI,IAAI,CAAC,UAAL,IAAmB,IAAnB,IAA2B,IAAI,CAAC,eAAL,IAAwB,IAAvD,EAA6D;MAC3D,MAAM,IAAI,UAAJ,CACF,oCACA,oEAFE,CAAN;IAGD;;IACD,IAAI,eAAe,GAAG,IAAI,CAAC,eAA3B;;IACA,IAAI,eAAe,IAAI,IAAvB,EAA6B;MAC3B,IAAI,IAAI,CAAC,UAAL,IAAmB,IAAvB,EAA6B;QAC3B,MAAM,IAAI,UAAJ,CACF,6CACA,uCAFE,CAAN;MAGD,CAJD,MAIO;QACL,eAAe,GAAG,CAAC,IAAI,CAAC,SAAN,EAAiB,MAAjB,CAAwB,IAAI,CAAC,UAA7B,CAAlB;MACD;IACF,CARD,MAQO;MAEL,IAAI,IAAI,CAAC,SAAL,IAAkB,IAAtB,EAA4B;QAC1B,MAAM,IAAI,UAAJ,CACF,oDACA,wCAFE,CAAN;MAGD;IACF;;IAED,IAAM,KAAK,GAAG,IAAI,CAAC,KAAL,IAAc,SAA5B;IAEA,MAAK,eAAL,GAAuB,eAAvB;IACA,MAAK,KAAL,GAAa,KAAb;IAEA,MAAK,SAAL,GAAiB,CAAC;MAAC,KAAK,EAAE;IAAR,CAAD,CAAjB;IAEA,IAAM,WAAW,GAAG,IAAI,cAAJ,CAChB,MAAK,KADW,EACJ,MAAK,eADD,iCACwB,EADxB,EAC4B,EAD5B,EACgC,MAAK,IADrC,CAApB;IAEA,WAAW,CAAC,SAAZ,GAAwB,CAAxB;IACA,WAAW,CAAC,WAAZ,GAA0B,CAA1B;IAKA,IAAI,IAAJ,CAAS;MACP,aAAa,+BADN;MAEP,aAAa,EAAE,EAFR;MAGP,WAAW,EAAE,EAHN;MAIP,aAAa,EAAE,EAJR;MAKP,YAAY,EAAE,CAAC,WAAD,CALP;MAMP,aAAa,EAAE,CAAC,WAAD,CANR;MAOP,UAAU,EAAE,CAAC,IAAD,CAPL;MAQP,WAAW,EAAE,CAAC,IAAD,CARN;MASP,WAAW,EAAE,CAAC,eAAD,CATN;MAUP,YAAY,EAAE,CAAC,eAAD;IAVP,CAAT;IAvD8B;EAmE/B;;EAvEH;IAAA;IAAA,OAyEE,eACI,MADJ,EAEI,MAFJ,EAEmB;MACjB,MAAM,IAAI,UAAJ,CACF,qFACiD,KAAK,IADtD,CADE,CAAN;IAGD;EA/EH;IAAA;IAAA,OAiFE,mBAAO;MAEL,OAAO;QAAC,oBAAoB,EAAE,KAAK,SAA5B;QAAuC,oBAAoB,EAAE;MAA7D,CAAP;IACD;EApFH;IAAA;IAAA,OAsFE,qBAAS;MACP,OAAO;QACL,eAAe,EAAE,KAAK,eADjB;QAEL,KAAK,EAAE,KAAK,KAFP;QAGL,MAAM,EAAE,KAAK,MAHR;QAIL,IAAI,EAAE,KAAK;MAJN,CAAP;IAMD;EA7FH;;EAAA;AAAA,EAAgC,KAAhC;AAEkB,UAAA,CAAA,SAAA,GAAY,YAAZ;AA6FlB,aAAa,CAAC,aAAd,CAA4B,UAA5B;AAmCA,OAAM,SAAU,KAAV,CAAgB,MAAhB,EAAmC;EACvC,IAAI,MAAM,CAAC,UAAP,IAAqB,IAArB,IAA6B,MAAM,CAAC,KAAP,IAAgB,IAAjD,EAAuD;IACrD,MAAM,IAAI,KAAJ,CACF,6CACA,yCADA,GAEA,qCAFA,GAGA,YAJE,CAAN;EAKD;;EACD,IAAI,MAAM,CAAC,UAAP,IAAqB,IAArB,IAA6B,MAAM,CAAC,KAAP,IAAgB,IAAjD,EAAuD;IAErD,MAAM,IAAI,UAAJ,CACF,qDACA,kCAFE,CAAN;EAGD;;EACD,IAAI,UAAU,GAAG,MAAM,CAAC,UAAxB;;EACA,IAAI,MAAM,CAAC,KAAP,IAAgB,IAAhB,IAAwB,UAAU,IAAI,IAA1C,EAAgD;IAC9C,UAAU,GAAG,CAAC,IAAD,EAAO,MAAP,CAAc,MAAM,CAAC,KAArB,CAAb;EACD;;EAED,IAAI,KAAK,GAAG,MAAM,CAAC,KAAnB;;EACA,IAAI,KAAK,IAAI,IAAb,EAAmB;IACjB,KAAK,GAAG,SAAR;EACD;;EAED,IAAM,UAAU,GAAG,IAAI,UAAJ,CAAe;IAChC,eAAe,EAAE,UADe;IAEhC,IAAI,EAAE,MAAM,CAAC,IAFmB;IAGhC,KAAK,EAAL,KAHgC;IAIhC,MAAM,EAAE,MAAM,CAAC;EAJiB,CAAf,CAAnB;EAOA,IAAM,OAAO,GAAG,UAAU,CAAC,YAAX,CAAwB,CAAxB,EAA2B,aAA3C;EACA,OAAO,OAAO,CAAC,CAAD,CAAd;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { serialization } from '@tensorflow/tfjs-core';\nimport { getUid } from '../backend/state';\nimport { ValueError } from '../errors';\nimport { Layer, Node, SymbolicTensor } from './topology';\nexport class InputLayer extends Layer {\n    constructor(args) {\n        super({\n            dtype: args.dtype,\n            name: args.name != null ? args.name : getUid('input').toString()\n        });\n        // Normalize config.batchSize and config.sparse\n        if (args.batchSize == null) {\n            args.batchSize = null;\n        }\n        if (args.sparse == null) {\n            args.sparse = false;\n        }\n        this.trainable = false;\n        this.built = true;\n        this.sparse = args.sparse;\n        if (args.inputShape != null && args.batchInputShape != null) {\n            throw new ValueError('Only provide the inputShape OR ' +\n                'batchInputShape argument to inputLayer, not both at the same time.');\n        }\n        let batchInputShape = args.batchInputShape;\n        if (batchInputShape == null) {\n            if (args.inputShape == null) {\n                throw new ValueError('An InputLayer should be passed either a ' +\n                    '`batchInputShape` or an `inputShape`.');\n            }\n            else {\n                batchInputShape = [args.batchSize].concat(args.inputShape);\n            }\n        }\n        else {\n            // TODO(michaelterry): Backport to PyKeras\n            if (args.batchSize != null) {\n                throw new ValueError('Cannot specify batchSize if batchInputShape is ' +\n                    'specified when creating an InputLayer.');\n            }\n        }\n        const dtype = args.dtype || 'float32';\n        this.batchInputShape = batchInputShape;\n        this.dtype = dtype;\n        // TODO(michaelterry): Backport this to PyKeras?\n        this.inputSpec = [{ shape: batchInputShape }];\n        const inputTensor = new SymbolicTensor(this.dtype, this.batchInputShape, this, [], {}, this.name);\n        inputTensor.nodeIndex = 0;\n        inputTensor.tensorIndex = 0;\n        // Create an input node to add to this.outboundNode.\n        // (This call has side effects.)\n        // tslint:disable-next-line:no-unused-expression\n        new Node({\n            outboundLayer: this,\n            inboundLayers: [],\n            nodeIndices: [],\n            tensorIndices: [],\n            inputTensors: [inputTensor],\n            outputTensors: [inputTensor],\n            inputMasks: [null],\n            outputMasks: [null],\n            inputShapes: [batchInputShape],\n            outputShapes: [batchInputShape]\n        });\n    }\n    apply(inputs, kwargs) {\n        throw new ValueError('Cannot pass any input to an ' +\n            `InputLayer's apply() method. InputLayer name: ${this.name}`);\n    }\n    dispose() {\n        // dispose() for InputLayer is overridden as no-op.\n        return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };\n    }\n    getConfig() {\n        return {\n            batchInputShape: this.batchInputShape,\n            dtype: this.dtype,\n            sparse: this.sparse,\n            name: this.name\n        };\n    }\n}\n/** @nocollapse */\nInputLayer.className = 'InputLayer';\nserialization.registerClass(InputLayer);\nexport function Input(config) {\n    if (config.batchShape == null && config.shape == null) {\n        throw new Error('Please provide to Input either a `shape`' +\n            ' or a `batchShape` argument. Note that ' +\n            '`shape` does not include the batch ' +\n            'dimension.');\n    }\n    if (config.batchShape != null && config.shape != null) {\n        // TODO(michaelterry): Backport to PyKeras.\n        throw new ValueError('Please provide either a `shape` or `batchShape` ' +\n            'argument to Input, but not both.');\n    }\n    let batchShape = config.batchShape;\n    if (config.shape != null && batchShape == null) {\n        batchShape = [null].concat(config.shape);\n    }\n    let dtype = config.dtype;\n    if (dtype == null) {\n        dtype = 'float32';\n    }\n    const inputLayer = new InputLayer({\n        batchInputShape: batchShape,\n        name: config.name,\n        dtype,\n        sparse: config.sparse\n    });\n    const outputs = inputLayer.inboundNodes[0].outputTensors;\n    return outputs[0];\n}\n//# sourceMappingURL=input_layer.js.map"]},"metadata":{},"sourceType":"module"}