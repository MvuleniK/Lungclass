{"ast":null,"code":"import _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, sumOutType, util } from '@tensorflow/tfjs-core';\nimport { reduce } from \"../kernel_utils/reduce\";\nimport { reshape } from \"./Reshape\";\nimport { transposeImpl } from \"./Transpose_impl\";\nexport function sumImpl(x, axis, keepDims, backend) {\n  var reductionIndices = axis;\n  var xRank = x.shape.length;\n  var origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  var axes = origAxes;\n  var permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  var sumInputIsTransposed = permutedAxes != null;\n  var sumInput = x;\n\n  if (sumInputIsTransposed) {\n    sumInput = transposeImpl(x, permutedAxes, backend);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n\n  var _backend_util$compute = backend_util.computeOutAndReduceShapes(sumInput.shape, axes),\n      _backend_util$compute2 = _slicedToArray(_backend_util$compute, 2),\n      sumOutShape = _backend_util$compute2[0],\n      reduceShape = _backend_util$compute2[1];\n\n  var outShape = sumOutShape;\n\n  if (keepDims) {\n    outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n  }\n\n  var inSize = util.sizeFromShape(reduceShape);\n  var xSize = util.sizeFromShape(x.shape);\n  var batchSize = xSize / inSize;\n  var reshapedInput = reshape({\n    inputs: {\n      x: sumInput\n    },\n    attrs: {\n      shape: [batchSize, inSize]\n    },\n    backend: backend\n  });\n  var outType = sumOutType(x.dtype);\n  var reduced = reduce(reshapedInput, outType, 'sum', backend);\n  var out = reshape({\n    inputs: {\n      x: reduced\n    },\n    attrs: {\n      shape: outShape\n    },\n    backend: backend\n  });\n  backend.disposeIntermediateTensorInfo(reshapedInput);\n  backend.disposeIntermediateTensorInfo(reduced);\n\n  if (sumInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(sumInput);\n  }\n\n  return out;\n}","map":{"version":3,"sources":["../../src/kernels/Sum_impl.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,EAAsB,UAAtB,EAA8C,IAA9C,QAAyD,uBAAzD;AAGA,SAAQ,MAAR;AACA,SAAQ,OAAR;AAEA,SAAQ,aAAR;AAEA,OAAM,SAAU,OAAV,CACF,CADE,EACa,IADb,EACoC,QADpC,EAEF,OAFE,EAEuB;EAC3B,IAAM,gBAAgB,GAAG,IAAzB;EAEA,IAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EAEA,IAAM,QAAQ,GAAG,IAAI,CAAC,cAAL,CAAoB,gBAApB,EAAsC,CAAC,CAAC,KAAxC,CAAjB;EACA,IAAI,IAAI,GAAG,QAAX;EACA,IAAM,YAAY,GAAG,YAAY,CAAC,kBAAb,CAAgC,IAAhC,EAAsC,KAAtC,CAArB;EACA,IAAM,oBAAoB,GAAG,YAAY,IAAI,IAA7C;EAEA,IAAI,QAAQ,GAAG,CAAf;;EACA,IAAI,oBAAJ,EAA0B;IACxB,QAAQ,GAAG,aAAa,CAAC,CAAD,EAAI,YAAJ,EAAkB,OAAlB,CAAxB;IAEA,IAAI,GAAG,YAAY,CAAC,gBAAb,CAA8B,IAAI,CAAC,MAAnC,EAA2C,KAA3C,CAAP;EACD;;EAED,YAAY,CAAC,0BAAb,CAAwC,KAAxC,EAA+C,IAA/C,EAAqD,KAArD;;EACA,4BACI,YAAY,CAAC,yBAAb,CAAuC,QAAQ,CAAC,KAAhD,EAAuD,IAAvD,CADJ;EAAA;EAAA,IAAO,WAAP;EAAA,IAAoB,WAApB;;EAGA,IAAI,QAAQ,GAAG,WAAf;;EACA,IAAI,QAAJ,EAAc;IAEZ,QAAQ,GAAG,YAAY,CAAC,oBAAb,CAAkC,WAAlC,EAA+C,QAA/C,CAAX;EACD;;EAED,IAAM,MAAM,GAAG,IAAI,CAAC,aAAL,CAAmB,WAAnB,CAAf;EACA,IAAM,KAAK,GAAG,IAAI,CAAC,aAAL,CAAmB,CAAC,CAAC,KAArB,CAAd;EACA,IAAM,SAAS,GAAG,KAAK,GAAG,MAA1B;EACA,IAAM,aAAa,GAAG,OAAO,CACzB;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAJ,CAAT;IAAwB,KAAK,EAAE;MAAC,KAAK,EAAE,CAAC,SAAD,EAAY,MAAZ;IAAR,CAA/B;IAA6D,OAAO,EAAP;EAA7D,CADyB,CAA7B;EAGA,IAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,KAAH,CAA1B;EAEA,IAAM,OAAO,GAAG,MAAM,CAAC,aAAD,EAAgB,OAAhB,EAAyB,KAAzB,EAAgC,OAAhC,CAAtB;EACA,IAAM,GAAG,GACL,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAJ,CAAT;IAAuB,KAAK,EAAE;MAAC,KAAK,EAAE;IAAR,CAA9B;IAAiD,OAAO,EAAP;EAAjD,CAAD,CADX;EAGA,OAAO,CAAC,6BAAR,CAAsC,aAAtC;EACA,OAAO,CAAC,6BAAR,CAAsC,OAAtC;;EACA,IAAI,oBAAJ,EAA0B;IACxB,OAAO,CAAC,6BAAR,CAAsC,QAAtC;EACD;;EAED,OAAO,GAAP;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, sumOutType, util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from './Reshape';\nimport { transposeImpl } from './Transpose_impl';\nexport function sumImpl(x, axis, keepDims, backend) {\n    const reductionIndices = axis;\n    const xRank = x.shape.length;\n    const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    const sumInputIsTransposed = permutedAxes != null;\n    let sumInput = x;\n    if (sumInputIsTransposed) {\n        sumInput = transposeImpl(x, permutedAxes, backend);\n        axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    }\n    backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n    const [sumOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(sumInput.shape, axes);\n    let outShape = sumOutShape;\n    if (keepDims) {\n        // rather than reshape at the end, set the target shape here.\n        outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n    }\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(x.shape);\n    const batchSize = xSize / inSize;\n    const reshapedInput = reshape({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend });\n    const outType = sumOutType(x.dtype);\n    const reduced = reduce(reshapedInput, outType, 'sum', backend);\n    const out = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(reshapedInput);\n    backend.disposeIntermediateTensorInfo(reduced);\n    if (sumInputIsTransposed) {\n        backend.disposeIntermediateTensorInfo(sumInput);\n    }\n    return out;\n}\n//# sourceMappingURL=Sum_impl.js.map"]},"metadata":{},"sourceType":"module"}