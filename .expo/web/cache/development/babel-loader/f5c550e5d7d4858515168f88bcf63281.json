{"ast":null,"code":"import _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nimport _extends from \"@babel/runtime/helpers/extends\";\nimport _toConsumableArray from \"@babel/runtime/helpers/toConsumableArray\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from \"../operations/executors/utils\";\nimport { executeOp } from \"../operations/operation_executor\";\nimport { ExecutionContext } from \"./execution_context\";\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from \"./model_analysis\";\nexport var GraphExecutor = function () {\n  function GraphExecutor(graph, parent) {\n    var _this = this;\n\n    _classCallCheck(this, GraphExecutor);\n\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(function (name) {\n        _this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], _this);\n      });\n    }\n  }\n\n  _createClass(GraphExecutor, [{\n    key: \"weightIds\",\n    get: function get() {\n      return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n  }, {\n    key: \"functionExecutorMap\",\n    get: function get() {\n      return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n    }\n  }, {\n    key: \"weightMap\",\n    get: function get() {\n      return this.parent ? this.parent.weightMap : this._weightMap;\n    },\n    set: function set(weightMap) {\n      var _ref;\n\n      var weightIds = Object.keys(weightMap).map(function (key) {\n        return weightMap[key].map(function (tensor) {\n          return tensor.id;\n        });\n      });\n      this._weightIds = (_ref = []).concat.apply(_ref, _toConsumableArray(weightIds));\n      this._weightMap = weightMap;\n    }\n  }, {\n    key: \"resourceManager\",\n    set: function set(resourceManager) {\n      this._resourceManager = resourceManager;\n    }\n  }, {\n    key: \"inputs\",\n    get: function get() {\n      return this._inputs.map(function (node) {\n        return {\n          name: node.name,\n          shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n          dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n        };\n      });\n    }\n  }, {\n    key: \"outputs\",\n    get: function get() {\n      return this._outputs.map(function (node) {\n        return {\n          name: node.name,\n          shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n          dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n        };\n      });\n    }\n  }, {\n    key: \"inputNodes\",\n    get: function get() {\n      return this._inputs.map(function (node) {\n        return node.signatureKey || node.name;\n      });\n    }\n  }, {\n    key: \"outputNodes\",\n    get: function get() {\n      return this._outputs.map(function (node) {\n        var name = node.signatureKey || node.name;\n        return node.defaultOutput ? name + \":\" + node.defaultOutput : name;\n      });\n    }\n  }, {\n    key: \"functions\",\n    get: function get() {\n      var _this2 = this;\n\n      return Object.keys(this._functions).reduce(function (map, key) {\n        map[key] = _this2._functions[key].signature;\n        return map;\n      }, {});\n    }\n  }, {\n    key: \"getCompilationKey\",\n    value: function getCompilationKey(inputs, outputs) {\n      var sortedInputs = inputs.map(function (node) {\n        return node.name;\n      }).sort();\n      var sortedOutputs = outputs.map(function (node) {\n        return node.name;\n      }).sort();\n      return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n    }\n  }, {\n    key: \"compile\",\n    value: function compile(inputs, outputs) {\n      var executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n      var missingInputs = executionInfo.missingInputs,\n          dynamicNode = executionInfo.dynamicNode,\n          syncInputs = executionInfo.syncInputs;\n\n      if (dynamicNode != null) {\n        throw new Error(\"This execution contains the node '\" + dynamicNode.name + \"', which has \" + (\"the dynamic op '\" + dynamicNode.op + \"'. Please use \") + \"model.executeAsync() instead. Alternatively, to avoid the \" + (\"dynamic ops, specify the inputs [\" + syncInputs + \"]\"));\n      }\n\n      if (missingInputs.length > 0) {\n        var outNames = outputs.map(function (n) {\n          return n.name;\n        });\n        var inNames = Object.keys(inputs);\n        throw new Error(\"Cannot compute the outputs [\" + outNames + \"] from the provided inputs \" + (\"[\" + inNames + \"]. Missing the following inputs: [\" + missingInputs + \"]\"));\n      }\n\n      return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n  }, {\n    key: \"execute\",\n    value: function execute(inputs, outputs) {\n      var _this3 = this;\n\n      inputs = this.mapInputs(inputs);\n      var names = Object.keys(inputs).sort();\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n      var inputNodes = names.map(function (name) {\n        return _this3.graph.nodes[parseNodeName(name)[0]];\n      });\n      var outputNodeNames = outputs.map(function (name) {\n        return parseNodeName(name)[0];\n      });\n      var outputNodes = outputNodeNames.map(function (name) {\n        return _this3.graph.nodes[name];\n      });\n\n      if (outputNodes.length === 0) {\n        outputNodes = this._outputs;\n      }\n\n      var compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n      var orderedNodes = this.compiledMap.get(compilationKey);\n\n      if (orderedNodes == null) {\n        orderedNodes = this.compile(inputs, outputNodes);\n        this.compiledMap.set(compilationKey, orderedNodes);\n      }\n\n      var tensorArrayMap = {};\n      var tensorListMap = {};\n      return tidy(function () {\n        var context = new ExecutionContext(_this3.weightMap, tensorArrayMap, tensorListMap, _this3.functionExecutorMap);\n\n        var tensorsMap = _extends({}, _this3.weightMap);\n\n        Object.keys(inputs).forEach(function (name) {\n          var _parseNodeName = parseNodeName(name),\n              _parseNodeName2 = _slicedToArray(_parseNodeName, 2),\n              nodeName = _parseNodeName2[0],\n              index = _parseNodeName2[1];\n\n          var tensors = [];\n          tensors[index] = inputs[name];\n          tensorsMap[nodeName] = tensors;\n        });\n\n        var tensorsToKeep = _this3.getFrozenTensorIds(tensorsMap);\n\n        var intermediateTensorConsumerCount = {};\n\n        for (var i = 0; i < orderedNodes.length; i++) {\n          var node = orderedNodes[i];\n\n          if (!tensorsMap[node.name]) {\n            var tensors = executeOp(node, tensorsMap, context, _this3._resourceManager);\n\n            if (util.isPromise(tensors)) {\n              throw new Error(\"The execution of the op '\" + node.op + \"' returned a promise. \" + \"Please use model.executeAsync() instead.\");\n            }\n\n            tensorsMap[node.name] = tensors;\n\n            _this3.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n          }\n        }\n\n        if (_this3.parent == null) {\n          context.dispose(tensorsToKeep);\n        }\n\n        return outputs.map(function (name) {\n          return getTensor(name, tensorsMap, context);\n        });\n      });\n    }\n  }, {\n    key: \"getFrozenTensorIds\",\n    value: function getFrozenTensorIds(tensorMap) {\n      var ids = [].concat.apply([], Object.keys(tensorMap).map(function (key) {\n        return tensorMap[key];\n      }).map(function (tensors) {\n        return tensors.map(function (tensor) {\n          return tensor.id;\n        });\n      }));\n      return new Set(ids);\n    }\n  }, {\n    key: \"checkTensorForDisposal\",\n    value: function checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n      if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n        return;\n      }\n\n      tensorMap[nodeName].forEach(function (tensor) {\n        if (tensor != null) {\n          intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n        }\n      });\n      node.inputs.forEach(function (input) {\n        if (input.category !== 'control') {\n          var tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n\n          if (tensors != null) {\n            tensors.forEach(function (tensor) {\n              if (tensor && !tensorsToKeep.has(tensor.id)) {\n                var count = intermediateTensorConsumerCount[tensor.id];\n\n                if (count === 1) {\n                  tensor.dispose();\n                  delete intermediateTensorConsumerCount[tensor.id];\n                } else if (count != null) {\n                  intermediateTensorConsumerCount[tensor.id]--;\n                }\n              }\n            });\n          }\n        }\n      });\n    }\n  }, {\n    key: \"executeAsync\",\n    value: function executeAsync(inputs, outputs) {\n      return _regeneratorRuntime.async(function executeAsync$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              return _context.abrupt(\"return\", this._executeAsync(inputs, outputs));\n\n            case 1:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"_executeAsync\",\n    value: function _executeAsync(inputs, outputs) {\n      var isFunctionExecution,\n          tensorArrayMap,\n          tensorListMap,\n          context,\n          tensorMap,\n          results,\n          outputIds,\n          inputIds,\n          keepIds,\n          _args2 = arguments;\n      return _regeneratorRuntime.async(function _executeAsync$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              isFunctionExecution = _args2.length > 2 && _args2[2] !== undefined ? _args2[2] : false;\n              tensorArrayMap = _args2.length > 3 && _args2[3] !== undefined ? _args2[3] : {};\n              tensorListMap = _args2.length > 4 && _args2[4] !== undefined ? _args2[4] : {};\n\n              if (!isFunctionExecution) {\n                inputs = this.mapInputs(inputs);\n                this.checkInputs(inputs);\n                this.checkInputShapeAndType(inputs);\n                outputs = this.mapOutputs(outputs);\n                this.checkOutputs(outputs);\n              }\n\n              context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n              _context2.next = 7;\n              return _regeneratorRuntime.awrap(this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution));\n\n            case 7:\n              tensorMap = _context2.sent;\n              results = outputs.map(function (name) {\n                return getTensor(name, tensorMap, context);\n              });\n              outputIds = results.map(function (t) {\n                return t.id;\n              });\n              inputIds = Object.keys(inputs).map(function (name) {\n                return inputs[name].id;\n              });\n              keepIds = new Set([].concat(_toConsumableArray(outputIds), _toConsumableArray(inputIds), _toConsumableArray(this.weightIds)));\n              Object.keys(tensorMap).forEach(function (key) {\n                var tensorArray = tensorMap[key];\n                tensorArray.forEach(function (tensor) {\n                  if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n                    tensor.dispose();\n                  }\n                });\n              });\n\n              if (this.parent == null) {\n                context.dispose(keepIds);\n              }\n\n              return _context2.abrupt(\"return\", results);\n\n            case 15:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"executeFunctionAsync\",\n    value: function executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n      var _this4 = this;\n\n      var mappedInputs;\n      return _regeneratorRuntime.async(function executeFunctionAsync$(_context3) {\n        while (1) {\n          switch (_context3.prev = _context3.next) {\n            case 0:\n              mappedInputs = inputs.reduce(function (map, tensor, index) {\n                map[_this4.inputs[index].name] = tensor;\n                return map;\n              }, {});\n              return _context3.abrupt(\"return\", this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap));\n\n            case 2:\n            case \"end\":\n              return _context3.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"executeWithControlFlow\",\n    value: function executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n      var _this5 = this;\n\n      var names, inputNodes, outputNodeNames, outputNodes, _getExecutionSubgraph, usedNodes, missingInputs, dynamicNode, syncInputs, stack, tensorsMap, intermediateTensorConsumerCount, tensorsToKeep, added, promises, missingOutputs, alternativeMsg;\n\n      return _regeneratorRuntime.async(function executeWithControlFlow$(_context4) {\n        while (1) {\n          switch (_context4.prev = _context4.next) {\n            case 0:\n              names = Object.keys(inputs);\n              inputNodes = names.map(function (name) {\n                return _this5.graph.nodes[parseNodeName(name)[0]];\n              });\n              outputNodeNames = outputNames.map(function (name) {\n                return parseNodeName(name)[0];\n              });\n              outputNodes = outputNodeNames.map(function (name) {\n                return _this5.graph.nodes[name];\n              });\n\n              if (outputNodes.length === 0) {\n                outputNodes = this._outputs;\n              }\n\n              _getExecutionSubgraph = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes), usedNodes = _getExecutionSubgraph.usedNodes, missingInputs = _getExecutionSubgraph.missingInputs, dynamicNode = _getExecutionSubgraph.dynamicNode, syncInputs = _getExecutionSubgraph.syncInputs;\n              stack = [].concat(_toConsumableArray(inputNodes), _toConsumableArray(this.graph.weights), _toConsumableArray(this._initNodes || [])).map(function (node) {\n                return {\n                  node: node,\n                  contexts: context.currentContext\n                };\n              });\n              tensorsMap = _extends({}, this.weightMap);\n              Object.keys(inputs).forEach(function (name) {\n                var _parseNodeName3 = parseNodeName(name),\n                    _parseNodeName4 = _slicedToArray(_parseNodeName3, 2),\n                    nodeName = _parseNodeName4[0],\n                    index = _parseNodeName4[1];\n\n                var tensors = [];\n                tensors[index] = inputs[name];\n                tensorsMap[nodeName] = tensors;\n              });\n              intermediateTensorConsumerCount = {};\n              tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n              added = {};\n\n            case 12:\n              if (!(stack.length > 0)) {\n                _context4.next = 18;\n                break;\n              }\n\n              promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n              _context4.next = 16;\n              return _regeneratorRuntime.awrap(Promise.all(promises));\n\n            case 16:\n              _context4.next = 12;\n              break;\n\n            case 18:\n              if (dynamicNode == null && !isFunctionExecution) {\n                console.warn(\"This model execution did not contain any nodes with control flow \" + \"or dynamic output shapes. You can use model.execute() instead.\");\n              }\n\n              missingOutputs = outputNodes.filter(function (node) {\n                return !isControlFlow(node) && !getTensor(node.name, tensorsMap, context);\n              }).map(function (node) {\n                return node.name;\n              });\n\n              if (!(missingOutputs.length > 0)) {\n                _context4.next = 24;\n                break;\n              }\n\n              alternativeMsg = '';\n\n              if (dynamicNode != null) {\n                alternativeMsg = \"Alternatively, to avoid the dynamic ops, use model.execute() \" + (\"and specify the inputs [\" + syncInputs + \"]\");\n              }\n\n              throw new Error(\"Cannot compute the outputs [\" + missingOutputs + \"] from the provided \" + (\"inputs [\" + names + \"]. Consider providing the following inputs: \") + (\"[\" + missingInputs + \"]. \" + alternativeMsg));\n\n            case 24:\n              return _context4.abrupt(\"return\", tensorsMap);\n\n            case 25:\n            case \"end\":\n              return _context4.stop();\n          }\n        }\n      }, null, this, null, Promise);\n    }\n  }, {\n    key: \"processStack\",\n    value: function processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n      var _this6 = this;\n\n      var promises = [];\n\n      var _loop = function _loop() {\n        var item = stack.pop();\n        context.currentContext = item.contexts;\n        var nodeName = '';\n\n        if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n          var _getNodeNameAndIndex = getNodeNameAndIndex(item.node.name, context);\n\n          var _getNodeNameAndIndex2 = _slicedToArray(_getNodeNameAndIndex, 1);\n\n          nodeName = _getNodeNameAndIndex2[0];\n        }\n\n        if (tensorMap[item.node.name] == null) {\n          var tensors = executeOp(item.node, tensorMap, context, _this6._resourceManager);\n\n          if (!nodeName) {\n            var _getNodeNameAndIndex3 = getNodeNameAndIndex(item.node.name, context);\n\n            var _getNodeNameAndIndex4 = _slicedToArray(_getNodeNameAndIndex3, 1);\n\n            nodeName = _getNodeNameAndIndex4[0];\n          }\n\n          var currentContext = context.currentContext;\n\n          if (util.isPromise(tensors)) {\n            promises.push(tensors.then(function (t) {\n              tensorMap[nodeName] = t;\n              context.currentContext = currentContext;\n\n              _this6.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n\n              _this6.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n\n              return t;\n            }));\n          } else {\n            tensorMap[nodeName] = tensors;\n\n            _this6.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n\n            _this6.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n          }\n        } else {\n          _this6.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      };\n\n      while (stack.length > 0) {\n        _loop();\n      }\n\n      return promises;\n    }\n  }, {\n    key: \"processChildNodes\",\n    value: function processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n      node.children.forEach(function (childNode) {\n        var _getNodeNameAndIndex5 = getNodeNameAndIndex(childNode.name, context),\n            _getNodeNameAndIndex6 = _slicedToArray(_getNodeNameAndIndex5, 1),\n            nodeName = _getNodeNameAndIndex6[0];\n\n        if (added[nodeName] || !usedNodes.has(childNode.name)) {\n          return;\n        }\n\n        if (childNode.op === 'Merge') {\n          if (childNode.inputNames.some(function (name) {\n            return !!getTensor(name, tensorMap, context);\n          })) {\n            added[nodeName] = true;\n            stack.push({\n              contexts: context.currentContext,\n              node: childNode\n            });\n          }\n        } else if (childNode.inputNames.every(function (name) {\n            return !!getTensor(name, tensorMap, context);\n          })) {\n            added[nodeName] = true;\n            stack.push({\n              contexts: context.currentContext,\n              node: childNode\n            });\n          }\n      });\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var _this7 = this;\n\n      Object.keys(this.weightMap).forEach(function (key) {\n        return _this7.weightMap[key].forEach(function (tensor) {\n          return tensor.dispose();\n        });\n      });\n    }\n  }, {\n    key: \"checkInputShapeAndType\",\n    value: function checkInputShapeAndType(inputs) {\n      var _this8 = this;\n\n      Object.keys(inputs).forEach(function (name) {\n        var input = inputs[name];\n\n        var _parseNodeName5 = parseNodeName(name),\n            _parseNodeName6 = _slicedToArray(_parseNodeName5, 1),\n            nodeName = _parseNodeName6[0];\n\n        var node = _this8.graph.nodes[nodeName];\n\n        if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n          var shape = node.attrParams['shape'].value;\n          var match = shape.length === input.shape.length && input.shape.every(function (dim, index) {\n            return shape[index] === -1 || shape[index] === dim;\n          });\n          util.assert(match, function () {\n            return \"The shape of dict['\" + node.name + \"'] provided in \" + (\"model.execute(dict) must be [\" + shape + \"], but was \") + (\"[\" + input.shape + \"]\");\n          });\n        }\n\n        if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n          util.assert(input.dtype === node.attrParams['dtype'].value, function () {\n            return \"The dtype of dict['\" + node.name + \"'] provided in \" + \"model.execute(dict) must be \" + (node.attrParams['dtype'].value + \", but was \" + input.dtype);\n          });\n        }\n      });\n    }\n  }, {\n    key: \"mapInputs\",\n    value: function mapInputs(inputs) {\n      var result = {};\n\n      for (var inputName in inputs) {\n        if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n          var tensor = this._signature.inputs[inputName];\n          result[tensor.name] = inputs[inputName];\n        } else {\n          result[inputName] = inputs[inputName];\n        }\n      }\n\n      return result;\n    }\n  }, {\n    key: \"checkInputs\",\n    value: function checkInputs(inputs) {\n      var _this9 = this;\n\n      var notInGraph = Object.keys(inputs).filter(function (name) {\n        var _parseNodeName7 = parseNodeName(name),\n            _parseNodeName8 = _slicedToArray(_parseNodeName7, 1),\n            nodeName = _parseNodeName8[0];\n\n        return _this9.graph.nodes[nodeName] == null;\n      });\n\n      if (notInGraph.length > 0) {\n        throw new Error(\"The dict provided in model.execute(dict) has \" + (\"keys: [\" + notInGraph + \"] that are not part of graph\"));\n      }\n    }\n  }, {\n    key: \"mapOutputs\",\n    value: function mapOutputs(outputs) {\n      var _this10 = this;\n\n      return outputs.map(function (name) {\n        if (_this10._signature != null && _this10._signature.outputs != null && _this10._signature.outputs[name] != null) {\n          var tensor = _this10._signature.outputs[name];\n          return tensor.name;\n        }\n\n        return name;\n      }, {});\n    }\n  }, {\n    key: \"checkOutputs\",\n    value: function checkOutputs(outputs) {\n      var _this11 = this;\n\n      outputs.forEach(function (name) {\n        var _parseNodeName9 = parseNodeName(name),\n            _parseNodeName10 = _slicedToArray(_parseNodeName9, 1),\n            normalizedName = _parseNodeName10[0];\n\n        if (!_this11.graph.nodes[normalizedName]) {\n          throw new Error(\"The output '\" + name + \"' is not found in the graph\");\n        }\n      });\n    }\n  }]);\n\n  return GraphExecutor;\n}();","map":{"version":3,"sources":["../../src/executor/graph_executor.ts"],"names":[],"mappings":";;;;;;;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAA0C,IAA1C,EAAgD,IAAhD,QAA2D,uBAA3D;AAIA,SAAQ,mBAAR,EAA6B,aAA7B,EAA4C,SAA5C,EAAuD,4BAAvD,EAAqF,aAArF;AACA,SAAQ,SAAR;AAGA,SAAQ,gBAAR;AACA,SAAQ,oBAAR,EAA8B,0BAA9B,EAA0D,aAA1D;AASA,WAAa,aAAb;EA+FE,uBAAoB,KAApB,EAA0C,MAA1C,EAAgE;IAAA;;IAAA;;IAA5C,KAAA,KAAA,GAAA,KAAA;IAAsB,KAAA,MAAA,GAAA,MAAA;IA9FlC,KAAA,WAAA,GAAmC,IAAI,GAAJ,EAAnC;IACA,KAAA,UAAA,GAA8B,EAA9B;IAMA,KAAA,SAAA,GAAY,GAAZ;IACA,KAAA,UAAA,GAAqC,EAArC;IACA,KAAA,oBAAA,GAA0D,EAA1D;IAsFN,KAAK,QAAL,GAAgB,KAAK,CAAC,OAAtB;IACA,KAAK,OAAL,GAAe,KAAK,CAAC,MAArB;IACA,KAAK,UAAL,GAAkB,KAAK,CAAC,SAAxB;IACA,KAAK,UAAL,GAAkB,KAAK,CAAC,SAAxB;IACA,KAAK,UAAL,GAAkB,KAAK,CAAC,SAAxB;;IAEA,IAAI,KAAK,CAAC,SAAN,IAAmB,IAAvB,EAA6B;MAC3B,MAAM,CAAC,IAAP,CAAY,KAAK,CAAC,SAAlB,EAA6B,OAA7B,CAAqC,UAAA,IAAI,EAAG;QAC1C,KAAI,CAAC,oBAAL,CAA0B,IAA1B,IACI,IAAI,aAAJ,CAAkB,KAAK,CAAC,SAAN,CAAgB,IAAhB,CAAlB,EAAyC,KAAzC,CADJ;MAED,CAHD;IAID;EACF;;EA5GH;IAAA;IAAA,KAaE,eAAa;MACX,OAAO,KAAK,MAAL,GAAc,KAAK,MAAL,CAAY,SAA1B,GAAsC,KAAK,UAAlD;IACD;EAfH;IAAA;IAAA,KAiBE,eAAuB;MACrB,OAAO,KAAK,MAAL,GAAc,KAAK,MAAL,CAAY,mBAA1B,GACc,KAAK,oBAD1B;IAED;EApBH;IAAA;IAAA,KAsBE,eAAa;MACX,OAAO,KAAK,MAAL,GAAc,KAAK,MAAL,CAAY,SAA1B,GAAsC,KAAK,UAAlD;IACD,CAxBH;IAAA,KA0BE,aAAc,SAAd,EAAwC;MAAA;;MACtC,IAAM,SAAS,GAAG,MAAM,CAAC,IAAP,CAAY,SAAZ,EAAuB,GAAvB,CACd,UAAA,GAAG;QAAA,OAAI,SAAS,CAAC,GAAD,CAAT,CAAe,GAAf,CAAmB,UAAA,MAAM;UAAA,OAAI,MAAM,CAAC,EAAX;QAAA,CAAzB,CAAJ;MAAA,CADW,CAAlB;MAEA,KAAK,UAAL,GAAkB,YAAG,MAAH,gCAAa,SAAb,EAAlB;MACA,KAAK,UAAL,GAAkB,SAAlB;IACD;EA/BH;IAAA;IAAA,KAqCE,aAAoB,eAApB,EAAoD;MAClD,KAAK,gBAAL,GAAwB,eAAxB;IACD;EAvCH;IAAA;IAAA,KAyCE,eAAU;MACR,OAAO,KAAK,OAAL,CAAa,GAAb,CAAiB,UAAA,IAAI,EAAG;QAC7B,OAAO;UACL,IAAI,EAAE,IAAI,CAAC,IADN;UAEL,KAAK,EAAE,IAAI,CAAC,UAAL,CAAgB,OAAhB,IACH,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KADtB,GAEH,SAJC;UAKL,KAAK,EAAE,IAAI,CAAC,UAAL,CAAgB,OAAhB,IACH,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KADtB,GAEH;QAPC,CAAP;MASD,CAVM,CAAP;IAWD;EArDH;IAAA;IAAA,KAuDE,eAAW;MACT,OAAO,KAAK,QAAL,CAAc,GAAd,CAAkB,UAAA,IAAI,EAAG;QAC9B,OAAO;UACL,IAAI,EAAE,IAAI,CAAC,IADN;UAEL,KAAK,EAAE,IAAI,CAAC,UAAL,CAAgB,OAAhB,IACH,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KADtB,GAEH,SAJC;UAKL,KAAK,EAAE,IAAI,CAAC,UAAL,CAAgB,OAAhB,IACH,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KADtB,GAEH;QAPC,CAAP;MASD,CAVM,CAAP;IAWD;EAnEH;IAAA;IAAA,KAqEE,eAAc;MACZ,OAAO,KAAK,OAAL,CAAa,GAAb,CAAiB,UAAA,IAAI;QAAA,OAAI,IAAI,CAAC,YAAL,IAAqB,IAAI,CAAC,IAA9B;MAAA,CAArB,CAAP;IACD;EAvEH;IAAA;IAAA,KAyEE,eAAe;MACb,OAAO,KAAK,QAAL,CAAc,GAAd,CAAkB,UAAC,IAAD,EAAS;QAChC,IAAM,IAAI,GAAG,IAAI,CAAC,YAAL,IAAqB,IAAI,CAAC,IAAvC;QACA,OAAO,IAAI,CAAC,aAAL,GAAyB,IAAzB,SAAiC,IAAI,CAAC,aAAtC,GAAyD,IAAhE;MACD,CAHM,CAAP;IAID;EA9EH;IAAA;IAAA,KAgFE,eAAa;MAAA;;MACX,OAAO,MAAM,CAAC,IAAP,CAAY,KAAK,UAAjB,EAA6B,MAA7B,CAAoC,UAAC,GAAD,EAAM,GAAN,EAAa;QACtD,GAAG,CAAC,GAAD,CAAH,GAAW,MAAI,CAAC,UAAL,CAAgB,GAAhB,EAAqB,SAAhC;QACA,OAAO,GAAP;MACD,CAHM,EAGJ,EAHI,CAAP;IAID;EArFH;IAAA;IAAA,OA8GU,2BAAkB,MAAlB,EAAkC,OAAlC,EAAiD;MACvD,IAAM,YAAY,GAAG,MAAM,CAAC,GAAP,CAAW,UAAA,IAAI;QAAA,OAAI,IAAI,CAAC,IAAT;MAAA,CAAf,EAA8B,IAA9B,EAArB;MACA,IAAM,aAAa,GAAG,OAAO,CAAC,GAAR,CAAY,UAAA,IAAI;QAAA,OAAI,IAAI,CAAC,IAAT;MAAA,CAAhB,EAA+B,IAA/B,EAAtB;MACA,OAAO,YAAY,CAAC,IAAb,CAAkB,KAAK,SAAvB,IAAoC,IAApC,GACH,aAAa,CAAC,IAAd,CAAmB,KAAK,SAAxB,CADJ;IAED;EAnHH;IAAA;IAAA,OAyHU,iBAAQ,MAAR,EAAgC,OAAhC,EAA+C;MACrD,IAAM,aAAa,GACf,oBAAoB,CAAC,MAAD,EAAS,OAAT,EAAkB,KAAK,SAAvB,EAAkC,KAAK,UAAvC,CADxB;MAEA,IAAO,aAAP,GAAiD,aAAjD,CAAO,aAAP;MAAA,IAAsB,WAAtB,GAAiD,aAAjD,CAAsB,WAAtB;MAAA,IAAmC,UAAnC,GAAiD,aAAjD,CAAmC,UAAnC;;MACA,IAAI,WAAW,IAAI,IAAnB,EAAyB;QACvB,MAAM,IAAI,KAAJ,CACF,uCAAqC,WAAW,CAAC,IAAjD,2CACmB,WAAW,CAAC,EAD/B,6HAGoC,UAHpC,OADE,CAAN;MAKD;;MAED,IAAI,aAAa,CAAC,MAAd,GAAuB,CAA3B,EAA8B;QAC5B,IAAM,QAAQ,GAAG,OAAO,CAAC,GAAR,CAAY,UAAA,CAAC;UAAA,OAAI,CAAC,CAAC,IAAN;QAAA,CAAb,CAAjB;QACA,IAAM,OAAO,GAAG,MAAM,CAAC,IAAP,CAAY,MAAZ,CAAhB;QACA,MAAM,IAAI,KAAJ,CACF,iCAA+B,QAA/B,0CACI,OADJ,0CACgD,aADhD,OADE,CAAN;MAGD;;MAED,OAAO,0BAA0B,CAC7B,KAAK,KADwB,EACjB,KAAK,SADY,EACD,aADC,CAAjC;IAED;EA/IH;IAAA;IAAA,OA0JE,iBAAQ,MAAR,EAAgC,OAAhC,EAAkD;MAAA;;MAChD,MAAM,GAAG,KAAK,SAAL,CAAe,MAAf,CAAT;MACA,IAAM,KAAK,GAAG,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,IAApB,EAAd;MACA,KAAK,WAAL,CAAiB,MAAjB;MACA,KAAK,sBAAL,CAA4B,MAA5B;MACA,OAAO,GAAG,KAAK,UAAL,CAAgB,OAAhB,CAAV;MACA,KAAK,YAAL,CAAkB,OAAlB;MACA,IAAM,UAAU,GACZ,KAAK,CAAC,GAAN,CAAU,UAAA,IAAI;QAAA,OAAI,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,aAAa,CAAC,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAJ;MAAA,CAAd,CADJ;MAEA,IAAM,eAAe,GAAG,OAAO,CAAC,GAAR,CAAY,UAAA,IAAI;QAAA,OAAI,aAAa,CAAC,IAAD,CAAb,CAAoB,CAApB,CAAJ;MAAA,CAAhB,CAAxB;MACA,IAAI,WAAW,GAAG,eAAe,CAAC,GAAhB,CAAoB,UAAA,IAAI;QAAA,OAAI,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,IAAjB,CAAJ;MAAA,CAAxB,CAAlB;;MAGA,IAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;QAC5B,WAAW,GAAG,KAAK,QAAnB;MACD;;MAED,IAAM,cAAc,GAAG,KAAK,iBAAL,CAAuB,UAAvB,EAAmC,WAAnC,CAAvB;MAGA,IAAI,YAAY,GAAG,KAAK,WAAL,CAAiB,GAAjB,CAAqB,cAArB,CAAnB;;MACA,IAAI,YAAY,IAAI,IAApB,EAA0B;QACxB,YAAY,GAAG,KAAK,OAAL,CAAa,MAAb,EAAqB,WAArB,CAAf;QACA,KAAK,WAAL,CAAiB,GAAjB,CAAqB,cAArB,EAAqC,YAArC;MACD;;MAED,IAAM,cAAc,GAAmB,EAAvC;MACA,IAAM,aAAa,GAAkB,EAArC;MAEA,OAAO,IAAI,CAAC,YAAK;QACf,IAAM,OAAO,GAAG,IAAI,gBAAJ,CACZ,MAAI,CAAC,SADO,EACI,cADJ,EACoB,aADpB,EAEZ,MAAI,CAAC,mBAFO,CAAhB;;QAGA,IAAM,UAAU,GAAA,SAAA,EAAA,EAAwB,MAAI,CAAC,SAA7B,CAAhB;;QAEA,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,OAApB,CAA4B,UAAA,IAAI,EAAG;UACjC,qBAA0B,aAAa,CAAC,IAAD,CAAvC;UAAA;UAAA,IAAO,QAAP;UAAA,IAAiB,KAAjB;;UACA,IAAM,OAAO,GAAa,EAA1B;UACA,OAAO,CAAC,KAAD,CAAP,GAAiB,MAAM,CAAC,IAAD,CAAvB;UACA,UAAU,CAAC,QAAD,CAAV,GAAuB,OAAvB;QACD,CALD;;QAOA,IAAM,aAAa,GAAG,MAAI,CAAC,kBAAL,CAAwB,UAAxB,CAAtB;;QACA,IAAM,+BAA+B,GAA4B,EAAjE;;QACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAAY,CAAC,MAAjC,EAAyC,CAAC,EAA1C,EAA8C;UAC5C,IAAM,IAAI,GAAG,YAAY,CAAC,CAAD,CAAzB;;UACA,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAN,CAAf,EAA4B;YAC1B,IAAM,OAAO,GACT,SAAS,CAAC,IAAD,EAAO,UAAP,EAAmB,OAAnB,EAA4B,MAAI,CAAC,gBAAjC,CADb;;YAGA,IAAI,IAAI,CAAC,SAAL,CAAe,OAAf,CAAJ,EAA6B;cAC3B,MAAM,IAAI,KAAJ,CACF,8BAA4B,IAAI,CAAC,EAAjC,wEADE,CAAN;YAGD;;YACD,UAAU,CAAC,IAAI,CAAC,IAAN,CAAV,GAAwB,OAAxB;;YACA,MAAI,CAAC,sBAAL,CACI,IAAI,CAAC,IADT,EACe,IADf,EACqB,UADrB,EACiC,OADjC,EAC0C,aAD1C,EAEI,eAFJ,EAEqB,+BAFrB;UAGD;QACF;;QAED,IAAI,MAAI,CAAC,MAAL,IAAe,IAAnB,EAAyB;UACvB,OAAO,CAAC,OAAR,CAAgB,aAAhB;QACD;;QACD,OAAO,OAAO,CAAC,GAAR,CAAY,UAAA,IAAI;UAAA,OAAI,SAAS,CAAC,IAAD,EAAO,UAAP,EAAmB,OAAnB,CAAb;QAAA,CAAhB,CAAP;MACD,CArCU,CAAX;IAsCD;EA7NH;IAAA;IAAA,OA+NU,4BAAmB,SAAnB,EAA6C;MACnD,IAAM,GAAG,GAAG,GAAG,MAAH,CAAU,KAAV,CACR,EADQ,EAER,MAAM,CAAC,IAAP,CAAY,SAAZ,EACK,GADL,CACS,UAAA,GAAG;QAAA,OAAI,SAAS,CAAC,GAAD,CAAb;MAAA,CADZ,EAEK,GAFL,CAES,UAAA,OAAO;QAAA,OAAI,OAAO,CAAC,GAAR,CAAY,UAAA,MAAM;UAAA,OAAI,MAAM,CAAC,EAAX;QAAA,CAAlB,CAAJ;MAAA,CAFhB,CAFQ,CAAZ;MAKA,OAAO,IAAI,GAAJ,CAAQ,GAAR,CAAP;IACD;EAtOH;IAAA;IAAA,OAuOU,gCACJ,QADI,EACc,IADd,EAC0B,SAD1B,EAEJ,OAFI,EAEuB,aAFvB,EAGJ,WAHI,EAIJ,+BAJI,EAIoD;MAG1D,IAAI,IAAI,CAAC,QAAL,KAAkB,SAAlB,IAA+B,WAAW,CAAC,OAAZ,CAAoB,QAApB,MAAkC,CAAC,CAAtE,EAAyE;QACvE;MACD;;MAED,SAAS,CAAC,QAAD,CAAT,CAAoB,OAApB,CAA4B,UAAA,MAAM,EAAG;QACnC,IAAI,MAAM,IAAI,IAAd,EAAoB;UAClB,+BAA+B,CAAC,MAAM,CAAC,EAAR,CAA/B,GACI,CAAC,+BAA+B,CAAC,MAAM,CAAC,EAAR,CAA/B,IAA8C,CAA/C,IACA,IAAI,CAAC,QAAL,CAAc,MAFlB;QAGD;MACF,CAND;MAOA,IAAI,CAAC,MAAL,CAAY,OAAZ,CAAoB,UAAA,KAAK,EAAG;QAG1B,IAAI,KAAK,CAAC,QAAN,KAAmB,SAAvB,EAAkC;UAChC,IAAM,OAAO,GACT,4BAA4B,CAAC,KAAK,CAAC,IAAP,EAAa,SAAb,EAAwB,OAAxB,CADhC;;UAEA,IAAI,OAAO,IAAI,IAAf,EAAqB;YACnB,OAAO,CAAC,OAAR,CAAgB,UAAA,MAAM,EAAG;cACvB,IAAI,MAAM,IAAI,CAAC,aAAa,CAAC,GAAd,CAAkB,MAAM,CAAC,EAAzB,CAAf,EAA6C;gBAC3C,IAAM,KAAK,GAAG,+BAA+B,CAAC,MAAM,CAAC,EAAR,CAA7C;;gBACA,IAAI,KAAK,KAAK,CAAd,EAAiB;kBACf,MAAM,CAAC,OAAP;kBACA,OAAO,+BAA+B,CAAC,MAAM,CAAC,EAAR,CAAtC;gBACD,CAHD,MAGO,IAAI,KAAK,IAAI,IAAb,EAAmB;kBAGxB,+BAA+B,CAAC,MAAM,CAAC,EAAR,CAA/B;gBACD;cACF;YACF,CAZD;UAaD;QACF;MACF,CAtBD;IAuBD;EAhRH;IAAA;IAAA,OA2RE,sBAAmB,MAAnB,EAA2C,OAA3C;MAAA;QAAA;UAAA;YAAA;cAAA,iCAES,KAAK,aAAL,CAAmB,MAAnB,EAA2B,OAA3B,CAFT;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA3RF;IAAA;IAAA,OA8SU,uBACJ,MADI,EACoB,OADpB;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;MAAA;QAAA;UAAA;YAAA;cACwC,mBADxC,8DAC8D,KAD9D;cAEJ,cAFI,8DAE6B,EAF7B;cAGJ,aAHI,8DAG2B,EAH3B;;cAIN,IAAI,CAAC,mBAAL,EAA0B;gBACxB,MAAM,GAAG,KAAK,SAAL,CAAe,MAAf,CAAT;gBACA,KAAK,WAAL,CAAiB,MAAjB;gBACA,KAAK,sBAAL,CAA4B,MAA5B;gBACA,OAAO,GAAG,KAAK,UAAL,CAAgB,OAAhB,CAAV;gBACA,KAAK,YAAL,CAAkB,OAAlB;cACD;;cAEK,OAZA,GAYU,IAAI,gBAAJ,CACZ,KAAK,SADO,EACI,cADJ,EACoB,aADpB,EAEZ,KAAK,mBAFO,CAZV;cAAA;cAAA,iCAmBkB,KAAK,sBAAL,CACpB,MADoB,EACZ,OADY,EACH,OADG,EACM,mBADN,CAnBlB;;YAAA;cAmBA,SAnBA;cAqBA,OArBA,GAqBU,OAAO,CAAC,GAAR,CAAY,UAAA,IAAI;gBAAA,OAAI,SAAS,CAAC,IAAD,EAAO,SAAP,EAAkB,OAAlB,CAAb;cAAA,CAAhB,CArBV;cAwBA,SAxBA,GAwBY,OAAO,CAAC,GAAR,CAAY,UAAA,CAAC;gBAAA,OAAI,CAAC,CAAC,EAAN;cAAA,CAAb,CAxBZ;cAyBA,QAzBA,GAyBW,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,GAApB,CAAwB,UAAA,IAAI;gBAAA,OAAI,MAAM,CAAC,IAAD,CAAN,CAAa,EAAjB;cAAA,CAA5B,CAzBX;cA0BA,OA1BA,GA2BF,IAAI,GAAJ,8BAAoB,SAApB,sBAAkC,QAAlC,sBAA+C,KAAK,SAApD,GA3BE;cA4BN,MAAM,CAAC,IAAP,CAAY,SAAZ,EAAuB,OAAvB,CAA+B,UAAA,GAAG,EAAG;gBACnC,IAAM,WAAW,GAAG,SAAS,CAAC,GAAD,CAA7B;gBACA,WAAW,CAAC,OAAZ,CAAoB,UAAA,MAAM,EAAG;kBAC3B,IAAI,MAAM,IAAI,CAAC,MAAM,CAAC,UAAlB,IAAgC,CAAC,OAAO,CAAC,GAAR,CAAY,MAAM,CAAC,EAAnB,CAArC,EAA6D;oBAC3D,MAAM,CAAC,OAAP;kBACD;gBACF,CAJD;cAKD,CAPD;;cASA,IAAI,KAAK,MAAL,IAAe,IAAnB,EAAyB;gBACvB,OAAO,CAAC,OAAR,CAAgB,OAAhB;cACD;;cAvCK,kCAyCC,OAzCD;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA9SV;IAAA;IAAA,OA0VE,8BACI,MADJ,EACsB,cADtB,EAEI,aAFJ;MAAA;;MAAA;MAAA;QAAA;UAAA;YAAA;cAGQ,YAHR,GAGuB,MAAM,CAAC,MAAP,CAAc,UAAC,GAAD,EAAM,MAAN,EAAc,KAAd,EAAuB;gBACxD,GAAG,CAAC,MAAI,CAAC,MAAL,CAAY,KAAZ,EAAmB,IAApB,CAAH,GAA+B,MAA/B;gBACA,OAAO,GAAP;cACD,CAHoB,EAGlB,EAHkB,CAHvB;cAAA,kCAQS,KAAK,aAAL,CACH,YADG,EACW,KAAK,WADhB,EAC6B,IAD7B,EACmC,cADnC,EACmD,aADnD,CART;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EA1VF;IAAA;IAAA,OAgXU,gCACJ,MADI,EACoB,OADpB,EAC+C,WAD/C,EAEJ,mBAFI;MAAA;;MAAA;;MAAA;QAAA;UAAA;YAAA;cAGA,KAHA,GAGQ,MAAM,CAAC,IAAP,CAAY,MAAZ,CAHR;cAIA,UAJA,GAKF,KAAK,CAAC,GAAN,CAAU,UAAA,IAAI;gBAAA,OAAI,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,aAAa,CAAC,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAJ;cAAA,CAAd,CALE;cAMA,eANA,GAMkB,WAAW,CAAC,GAAZ,CAAgB,UAAA,IAAI;gBAAA,OAAI,aAAa,CAAC,IAAD,CAAb,CAAoB,CAApB,CAAJ;cAAA,CAApB,CANlB;cAOF,WAPE,GAOY,eAAe,CAAC,GAAhB,CAAoB,UAAA,IAAI;gBAAA,OAAI,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,IAAjB,CAAJ;cAAA,CAAxB,CAPZ;;cAUN,IAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;gBAC5B,WAAW,GAAG,KAAK,QAAnB;cACD;;cAZK,wBAeF,oBAAoB,CAChB,MADgB,EACR,WADQ,EACK,KAAK,SADV,EACqB,KAAK,UAD1B,CAflB,EAcC,SAdD,yBAcC,SAdD,EAcY,aAdZ,yBAcY,aAdZ,EAc2B,WAd3B,yBAc2B,WAd3B,EAcwC,UAdxC,yBAcwC,UAdxC;cAmBA,KAnBA,GAmB4B,6BAC7B,UAD6B,sBACd,KAAK,KAAL,CAAW,OADG,sBACU,KAAK,UAAL,IAAmB,EAD7B,GAEhC,GAFgC,CAE5B,UAAA,IAAI,EAAG;gBACX,OAAO;kBAAC,IAAI,EAAJ,IAAD;kBAAO,QAAQ,EAAE,OAAO,CAAC;gBAAzB,CAAP;cACD,CAJiC,CAnB5B;cAwBA,UAxBA,GAwBU,SAAA,EAAA,EAAwB,KAAK,SAA7B,CAxBV;cAyBN,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,OAApB,CAA4B,UAAA,IAAI,EAAG;gBACjC,sBAA0B,aAAa,CAAC,IAAD,CAAvC;gBAAA;gBAAA,IAAO,QAAP;gBAAA,IAAiB,KAAjB;;gBACA,IAAM,OAAO,GAAa,EAA1B;gBACA,OAAO,CAAC,KAAD,CAAP,GAAiB,MAAM,CAAC,IAAD,CAAvB;gBACA,UAAU,CAAC,QAAD,CAAV,GAAuB,OAAvB;cACD,CALD;cAMM,+BA/BA,GA+B2D,EA/B3D;cAgCA,aAhCA,GAgCgB,KAAK,kBAAL,CAAwB,UAAxB,CAhChB;cAiCA,KAjCA,GAiCkC,EAjClC;;YAAA;cAAA,MAkCC,KAAK,CAAC,MAAN,GAAe,CAlChB;gBAAA;gBAAA;cAAA;;cAmCE,QAnCF,GAmCa,KAAK,YAAL,CACb,UADa,EACD,KADC,EACM,OADN,EACe,UADf,EAC2B,KAD3B,EACkC,aADlC,EAEb,eAFa,EAEI,+BAFJ,EAEqC,SAFrC,CAnCb;cAAA;cAAA,iCAsCE,OAAO,CAAC,GAAR,CAAY,QAAZ,CAtCF;;YAAA;cAAA;cAAA;;YAAA;cAwCN,IAAI,WAAW,IAAI,IAAf,IAAuB,CAAC,mBAA5B,EAAiD;gBAC/C,OAAO,CAAC,IAAR,CACI,sIADJ;cAGD;;cACK,cA7CA,GA8CF,WAAW,CACN,MADL,CAEQ,UAAA,IAAI;gBAAA,OAAI,CAAC,aAAa,CAAC,IAAD,CAAd,IACJ,CAAC,SAAS,CAAC,IAAI,CAAC,IAAN,EAAY,UAAZ,EAAwB,OAAxB,CADV;cAAA,CAFZ,EAIK,GAJL,CAIS,UAAA,IAAI;gBAAA,OAAI,IAAI,CAAC,IAAT;cAAA,CAJb,CA9CE;;cAAA,MAmDF,cAAc,CAAC,MAAf,GAAwB,CAnDtB;gBAAA;gBAAA;cAAA;;cAoDA,cApDA,GAoDiB,EApDjB;;cAqDJ,IAAI,WAAW,IAAI,IAAnB,EAAyB;gBACvB,cAAc,GACV,gGAC2B,UAD3B,OADJ;cAGD;;cAzDG,MA0DE,IAAI,KAAJ,CACF,iCAA+B,cAA/B,0CACW,KADX,4DAEI,aAFJ,WAEuB,cAFvB,CADE,CA1DF;;YAAA;cAAA,kCA+DC,UA/DD;;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA;EAhXV;IAAA;IAAA,OAkbU,sBACJ,UADI,EACgB,KADhB,EAC2C,OAD3C,EAEJ,SAFI,EAEwB,KAFxB,EAGJ,aAHI,EAGwB,WAHxB,EAIJ,+BAJI,EAKJ,SALI,EAKkB;MAAA;;MACxB,IAAM,QAAQ,GAA6B,EAA3C;;MADwB;QAGtB,IAAM,IAAI,GAAG,KAAK,CAAC,GAAN,EAAb;QACA,OAAO,CAAC,cAAR,GAAyB,IAAI,CAAC,QAA9B;QACA,IAAI,QAAQ,GAAG,EAAf;;QAIA,IAAI,IAAI,CAAC,IAAL,CAAU,EAAV,KAAiB,OAAjB,IACA,aAAa,CAAC,YAAD,EAAe,IAAI,CAAC,IAApB,EAA0B,SAA1B,EAAqC,OAArC,CADjB,EACgE;UAAA,2BACjD,mBAAmB,CAAC,IAAI,CAAC,IAAL,CAAU,IAAX,EAAiB,OAAjB,CAD8B;;UAAA;;UAC7D,QAD6D;QAE/D;;QAID,IAAI,SAAS,CAAC,IAAI,CAAC,IAAL,CAAU,IAAX,CAAT,IAA6B,IAAjC,EAAuC;UACrC,IAAM,OAAO,GACT,SAAS,CAAC,IAAI,CAAC,IAAN,EAAY,SAAZ,EAAuB,OAAvB,EAAgC,MAAI,CAAC,gBAArC,CADb;;UAEA,IAAI,CAAC,QAAL,EAAe;YAAA,4BACA,mBAAmB,CAAC,IAAI,CAAC,IAAL,CAAU,IAAX,EAAiB,OAAjB,CADnB;;YAAA;;YACZ,QADY;UAEd;;UACD,IAAM,cAAc,GAAG,OAAO,CAAC,cAA/B;;UACA,IAAI,IAAI,CAAC,SAAL,CAAe,OAAf,CAAJ,EAA6B;YAC3B,QAAQ,CAAC,IAAT,CAAe,OAA6B,CAAC,IAA9B,CAAmC,UAAA,CAAC,EAAG;cACpD,SAAS,CAAC,QAAD,CAAT,GAAsB,CAAtB;cACA,OAAO,CAAC,cAAR,GAAyB,cAAzB;;cACA,MAAI,CAAC,sBAAL,CACI,QADJ,EACc,IAAI,CAAC,IADnB,EACyB,SADzB,EACoC,OADpC,EAC6C,aAD7C,EAEI,WAFJ,EAEiB,+BAFjB;;cAGA,MAAI,CAAC,iBAAL,CACI,IAAI,CAAC,IADT,EACe,KADf,EACsB,OADtB,EAC+B,SAD/B,EAC0C,KAD1C,EACiD,SADjD;;cAEA,OAAO,CAAP;YACD,CATc,CAAf;UAUD,CAXD,MAWO;YACL,SAAS,CAAC,QAAD,CAAT,GAAsB,OAAtB;;YACA,MAAI,CAAC,sBAAL,CACI,QADJ,EACc,IAAI,CAAC,IADnB,EACyB,SADzB,EACoC,OADpC,EAC6C,aAD7C,EAEI,WAFJ,EAEiB,+BAFjB;;YAGA,MAAI,CAAC,iBAAL,CACI,IAAI,CAAC,IADT,EACe,KADf,EACsB,OADtB,EAC+B,SAD/B,EAC0C,KAD1C,EACiD,SADjD;UAED;QACF,CA1BD,MA0BO;UACL,MAAI,CAAC,iBAAL,CACI,IAAI,CAAC,IADT,EACe,KADf,EACsB,OADtB,EAC+B,SAD/B,EAC0C,KAD1C,EACiD,SADjD;QAED;MA7CqB;;MAExB,OAAO,KAAK,CAAC,MAAN,GAAe,CAAtB,EAAyB;QAAA;MA4CxB;;MACD,OAAO,QAAP;IACD;EAveH;IAAA;IAAA,OAyeU,2BACJ,IADI,EACQ,KADR,EACmC,OADnC,EAEJ,SAFI,EAEwB,KAFxB,EAGJ,SAHI,EAGkB;MACxB,IAAI,CAAC,QAAL,CAAc,OAAd,CAAsB,UAAC,SAAD,EAAc;QAClC,4BAAqB,mBAAmB,CAAC,SAAS,CAAC,IAAX,EAAiB,OAAjB,CAAxC;QAAA;QAAA,IAAO,QAAP;;QACA,IAAI,KAAK,CAAC,QAAD,CAAL,IAAmB,CAAC,SAAS,CAAC,GAAV,CAAc,SAAS,CAAC,IAAxB,CAAxB,EAAuD;UACrD;QACD;;QAED,IAAI,SAAS,CAAC,EAAV,KAAiB,OAArB,EAA8B;UAC5B,IAAI,SAAS,CAAC,UAAV,CAAqB,IAArB,CAA0B,UAAA,IAAI,EAAG;YAC/B,OAAO,CAAC,CAAC,SAAS,CAAC,IAAD,EAAO,SAAP,EAAkB,OAAlB,CAAlB;UACD,CAFD,CAAJ,EAEQ;YACN,KAAK,CAAC,QAAD,CAAL,GAAkB,IAAlB;YACA,KAAK,CAAC,IAAN,CAAW;cAAC,QAAQ,EAAE,OAAO,CAAC,cAAnB;cAAmC,IAAI,EAAE;YAAzC,CAAX;UACD;QACF,CAPD,MAQI,IAAI,SAAS,CAAC,UAAV,CAAqB,KAArB,CAA2B,UAAA,IAAI,EAAG;YAChC,OAAO,CAAC,CAAC,SAAS,CAAC,IAAD,EAAO,SAAP,EAAkB,OAAlB,CAAlB;UACD,CAFD,CAAJ,EAEQ;YACV,KAAK,CAAC,QAAD,CAAL,GAAkB,IAAlB;YACA,KAAK,CAAC,IAAN,CAAW;cAAC,QAAQ,EAAE,OAAO,CAAC,cAAnB;cAAmC,IAAI,EAAE;YAAzC,CAAX;UACD;MACF,CApBD;IAqBD;EAlgBH;IAAA;IAAA,OAugBE,mBAAO;MAAA;;MACL,MAAM,CAAC,IAAP,CAAY,KAAK,SAAjB,EACK,OADL,CAEQ,UAAA,GAAG;QAAA,OAAI,MAAI,CAAC,SAAL,CAAe,GAAf,EAAoB,OAApB,CAA4B,UAAA,MAAM;UAAA,OAAI,MAAM,CAAC,OAAP,EAAJ;QAAA,CAAlC,CAAJ;MAAA,CAFX;IAGD;EA3gBH;IAAA;IAAA,OA6gBU,gCAAuB,MAAvB,EAA6C;MAAA;;MACnD,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,OAApB,CAA4B,UAAA,IAAI,EAAG;QACjC,IAAM,KAAK,GAAG,MAAM,CAAC,IAAD,CAApB;;QACA,sBAAqB,aAAa,CAAC,IAAD,CAAlC;QAAA;QAAA,IAAO,QAAP;;QACA,IAAM,IAAI,GAAG,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,QAAjB,CAAb;;QACA,IAAI,IAAI,CAAC,UAAL,CAAgB,OAAhB,KAA4B,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KAAzD,EAAgE;UAC9D,IAAM,KAAK,GAAG,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KAAvC;UACA,IAAM,KAAK,GAAG,KAAK,CAAC,MAAN,KAAiB,KAAK,CAAC,KAAN,CAAY,MAA7B,IACV,KAAK,CAAC,KAAN,CAAY,KAAZ,CACI,UAAC,GAAD,EAAM,KAAN;YAAA,OAAgB,KAAK,CAAC,KAAD,CAAL,KAAiB,CAAC,CAAlB,IAAuB,KAAK,CAAC,KAAD,CAAL,KAAiB,GAAxD;UAAA,CADJ,CADJ;UAGA,IAAI,CAAC,MAAL,CACI,KADJ,EAEI;YAAA,OAAM,wBAAsB,IAAI,CAAC,IAA3B,0DAC8B,KAD9B,2BAEE,KAAK,CAAC,KAFR,OAAN;UAAA,CAFJ;QAKD;;QACD,IAAI,IAAI,CAAC,UAAL,CAAgB,OAAhB,KAA4B,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KAAzD,EAAgE;UAC9D,IAAI,CAAC,MAAL,CACI,KAAK,CAAC,KAAN,KAAgB,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KAD7C,EAEI;YAAA,OAAM,wBAAsB,IAAI,CAAC,IAA3B,yDAEC,IAAI,CAAC,UAAL,CAAgB,OAAhB,EAAyB,KAF1B,kBAE4C,KAAK,CAAC,KAFlD,CAAN;UAAA,CAFJ;QAKD;MACF,CAtBD;IAuBD;EAriBH;IAAA;IAAA,OAuiBU,mBAAU,MAAV,EAAgC;MACtC,IAAM,MAAM,GAAmB,EAA/B;;MACA,KAAK,IAAM,SAAX,IAAwB,MAAxB,EAAgC;QAC9B,IAAI,KAAK,UAAL,IAAmB,IAAnB,IAA2B,KAAK,UAAL,CAAgB,MAAhB,IAA0B,IAArD,IACA,KAAK,UAAL,CAAgB,MAAhB,CAAuB,SAAvB,KAAqC,IADzC,EAC+C;UAC7C,IAAM,MAAM,GAAG,KAAK,UAAL,CAAgB,MAAhB,CAAuB,SAAvB,CAAf;UACA,MAAM,CAAC,MAAM,CAAC,IAAR,CAAN,GAAsB,MAAM,CAAC,SAAD,CAA5B;QACD,CAJD,MAIO;UACL,MAAM,CAAC,SAAD,CAAN,GAAoB,MAAM,CAAC,SAAD,CAA1B;QACD;MACF;;MACD,OAAO,MAAP;IACD;EAnjBH;IAAA;IAAA,OAqjBU,qBAAY,MAAZ,EAAkC;MAAA;;MACxC,IAAM,UAAU,GAAG,MAAM,CAAC,IAAP,CAAY,MAAZ,EAAoB,MAApB,CAA2B,UAAA,IAAI,EAAG;QACnD,sBAAmB,aAAa,CAAC,IAAD,CAAhC;QAAA;QAAA,IAAO,QAAP;;QACA,OAAO,MAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,QAAjB,KAA8B,IAArC;MACD,CAHkB,CAAnB;;MAIA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;QACzB,MAAM,IAAI,KAAJ,CACF,+DACU,UADV,kCADE,CAAN;MAGD;IACF;EA/jBH;IAAA;IAAA,OAikBU,oBAAW,OAAX,EAA4B;MAAA;;MAClC,OAAO,OAAO,CAAC,GAAR,CAAY,UAAA,IAAI,EAAG;QACxB,IAAI,OAAI,CAAC,UAAL,IAAmB,IAAnB,IAA2B,OAAI,CAAC,UAAL,CAAgB,OAAhB,IAA2B,IAAtD,IACA,OAAI,CAAC,UAAL,CAAgB,OAAhB,CAAwB,IAAxB,KAAiC,IADrC,EAC2C;UACzC,IAAM,MAAM,GAAG,OAAI,CAAC,UAAL,CAAgB,OAAhB,CAAwB,IAAxB,CAAf;UACA,OAAO,MAAM,CAAC,IAAd;QACD;;QACD,OAAO,IAAP;MACD,CAPM,EAOJ,EAPI,CAAP;IAQD;EA1kBH;IAAA;IAAA,OA4kBU,sBAAa,OAAb,EAA8B;MAAA;;MACpC,OAAO,CAAC,OAAR,CAAgB,UAAA,IAAI,EAAG;QACrB,sBAAyB,aAAa,CAAC,IAAD,CAAtC;QAAA;QAAA,IAAO,cAAP;;QACA,IAAI,CAAC,OAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,cAAjB,CAAL,EAAuC;UACrC,MAAM,IAAI,KAAJ,kBAAyB,IAAzB,iCAAN;QACD;MACF,CALD;IAMD;EAnlBH;;EAAA;AAAA","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n    /**\n     *\n     * @param graph Graph the model or function graph to be executed.\n     * @param parent When building function exector you need to set the parent\n     * executor. Since the weights and function executor maps are set at parant\n     * level, that function executor can access the function maps and weight maps\n     * through the parent.\n     */\n    constructor(graph, parent) {\n        this.graph = graph;\n        this.parent = parent;\n        this.compiledMap = new Map();\n        this._weightMap = {};\n        this.SEPERATOR = ',';\n        this._functions = {};\n        this._functionExecutorMap = {};\n        this._outputs = graph.outputs;\n        this._inputs = graph.inputs;\n        this._initNodes = graph.initNodes;\n        this._signature = graph.signature;\n        this._functions = graph.functions;\n        // create sub-graph executors\n        if (graph.functions != null) {\n            Object.keys(graph.functions).forEach(name => {\n                this._functionExecutorMap[name] =\n                    new GraphExecutor(graph.functions[name], this);\n            });\n        }\n    }\n    get weightIds() {\n        return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n    get functionExecutorMap() {\n        return this.parent ? this.parent.functionExecutorMap :\n            this._functionExecutorMap;\n    }\n    get weightMap() {\n        return this.parent ? this.parent.weightMap : this._weightMap;\n    }\n    set weightMap(weightMap) {\n        const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n        this._weightIds = [].concat(...weightIds);\n        this._weightMap = weightMap;\n    }\n    /**\n     * Set `ResourceManager` shared by executors of a model.\n     * @param resourceManager: `ResourceManager` of the `GraphModel`.\n     */\n    set resourceManager(resourceManager) {\n        this._resourceManager = resourceManager;\n    }\n    get inputs() {\n        return this._inputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get outputs() {\n        return this._outputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get inputNodes() {\n        return this._inputs.map(node => node.signatureKey || node.name);\n    }\n    get outputNodes() {\n        return this._outputs.map((node) => {\n            const name = node.signatureKey || node.name;\n            return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n        });\n    }\n    get functions() {\n        return Object.keys(this._functions).reduce((map, key) => {\n            map[key] = this._functions[key].signature;\n            return map;\n        }, {});\n    }\n    getCompilationKey(inputs, outputs) {\n        const sortedInputs = inputs.map(node => node.name).sort();\n        const sortedOutputs = outputs.map(node => node.name).sort();\n        return sortedInputs.join(this.SEPERATOR) + '--' +\n            sortedOutputs.join(this.SEPERATOR);\n    }\n    /**\n     * Compiles the inference graph and returns the minimal set of nodes that are\n     * required for execution, in the correct execution order.\n     */\n    compile(inputs, outputs) {\n        const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n        const { missingInputs, dynamicNode, syncInputs } = executionInfo;\n        if (dynamicNode != null) {\n            throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` +\n                `the dynamic op '${dynamicNode.op}'. Please use ` +\n                `model.executeAsync() instead. Alternatively, to avoid the ` +\n                `dynamic ops, specify the inputs [${syncInputs}]`);\n        }\n        if (missingInputs.length > 0) {\n            const outNames = outputs.map(n => n.name);\n            const inNames = Object.keys(inputs);\n            throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` +\n                `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n        }\n        return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n    /**\n     * Executes the inference for given input tensors.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model, if\n     * no outputs are specified, the default outputs of the model would be used.\n     * You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     */\n    execute(inputs, outputs) {\n        inputs = this.mapInputs(inputs);\n        const names = Object.keys(inputs).sort();\n        this.checkInputs(inputs);\n        this.checkInputShapeAndType(inputs);\n        outputs = this.mapOutputs(outputs);\n        this.checkOutputs(outputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n        // Do nothing if the compiled graph cache contains the input.\n        let orderedNodes = this.compiledMap.get(compilationKey);\n        if (orderedNodes == null) {\n            orderedNodes = this.compile(inputs, outputNodes);\n            this.compiledMap.set(compilationKey, orderedNodes);\n        }\n        const tensorArrayMap = {};\n        const tensorListMap = {};\n        return tidy(() => {\n            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n            const tensorsMap = Object.assign({}, this.weightMap);\n            Object.keys(inputs).forEach(name => {\n                const [nodeName, index] = parseNodeName(name);\n                const tensors = [];\n                tensors[index] = inputs[name];\n                tensorsMap[nodeName] = tensors;\n            });\n            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n            const intermediateTensorConsumerCount = {};\n            for (let i = 0; i < orderedNodes.length; i++) {\n                const node = orderedNodes[i];\n                if (!tensorsMap[node.name]) {\n                    const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n                    if (util.isPromise(tensors)) {\n                        throw new Error(`The execution of the op '${node.op}' returned a promise. ` +\n                            `Please use model.executeAsync() instead.`);\n                    }\n                    tensorsMap[node.name] = tensors;\n                    this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n                }\n            }\n            // dispose the context for the root executor\n            if (this.parent == null) {\n                context.dispose(tensorsToKeep);\n            }\n            return outputs.map(name => getTensor(name, tensorsMap, context));\n        });\n    }\n    getFrozenTensorIds(tensorMap) {\n        const ids = [].concat.apply([], Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n        return new Set(ids);\n    }\n    checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n        // Skip output nodes and any control flow nodes, since its dependency is\n        // tricky to track correctly.\n        if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n            return;\n        }\n        tensorMap[nodeName].forEach(tensor => {\n            if (tensor != null) {\n                intermediateTensorConsumerCount[tensor.id] =\n                    (intermediateTensorConsumerCount[tensor.id] || 0) +\n                        node.children.length;\n            }\n        });\n        node.inputs.forEach(input => {\n            // Skip any control flow nodes, since its dependency is tricky to track\n            // correctly.\n            if (input.category !== 'control') {\n                const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n                if (tensors != null) {\n                    tensors.forEach(tensor => {\n                        if (tensor && !tensorsToKeep.has(tensor.id)) {\n                            const count = intermediateTensorConsumerCount[tensor.id];\n                            if (count === 1) {\n                                tensor.dispose();\n                                delete intermediateTensorConsumerCount[tensor.id];\n                            }\n                            else if (count != null) {\n                                // only intermediate nodes has count set, inputs and weights are\n                                // not.\n                                intermediateTensorConsumerCount[tensor.id]--;\n                            }\n                        }\n                    });\n                }\n            }\n        });\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs output node name from the Tensorflow model, if no outputs\n     * are specified, the default outputs of the model would be used. You can\n     * inspect intermediate nodes of the model by adding them to the outputs\n     * array.\n     */\n    async executeAsync(inputs, outputs) {\n        return this._executeAsync(inputs, outputs);\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Optional. Flag for executing a function.\n     * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n     * function execution.\n     * @param tensorArrayMap Optinal global TensorList map by id. Used for\n     * function execution.\n     */\n    async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n        if (!isFunctionExecution) {\n            inputs = this.mapInputs(inputs);\n            this.checkInputs(inputs);\n            this.checkInputShapeAndType(inputs);\n            outputs = this.mapOutputs(outputs);\n            this.checkOutputs(outputs);\n        }\n        const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n        // Graph with control flow op requires runtime evaluation of the execution\n        // order, while without control flow the execution order is pre-determined\n        // in the compile method.\n        const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n        const results = outputs.map(name => getTensor(name, tensorMap, context));\n        // dispose all the intermediate tensors\n        const outputIds = results.map(t => t.id);\n        const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n        const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);\n        Object.keys(tensorMap).forEach(key => {\n            const tensorArray = tensorMap[key];\n            tensorArray.forEach(tensor => {\n                if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n                    tensor.dispose();\n                }\n            });\n        });\n        // dispose the context for the root executor\n        if (this.parent == null) {\n            context.dispose(keepIds);\n        }\n        return results;\n    }\n    async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n        const mappedInputs = inputs.reduce((map, tensor, index) => {\n            map[this.inputs[index].name] = tensor;\n            return map;\n        }, {});\n        return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n    }\n    /**\n     * When there are control flow nodes in the graph, the graph execution use\n     * ExecutionContext to keep track of the frames and loop iterators.\n     * @param inputs placeholder tensors for the graph.\n     * @param context the execution context object for current execution.\n     * @param outputNames Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Flag for executing a function.\n     */\n    async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n        const names = Object.keys(inputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n        // First nodes to execute include inputNodes, weights, and initNodes.\n        const stack = [\n            ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n        ].map(node => {\n            return { node, contexts: context.currentContext };\n        });\n        const tensorsMap = Object.assign({}, this.weightMap);\n        Object.keys(inputs).forEach(name => {\n            const [nodeName, index] = parseNodeName(name);\n            const tensors = [];\n            tensors[index] = inputs[name];\n            tensorsMap[nodeName] = tensors;\n        });\n        const intermediateTensorConsumerCount = {};\n        const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n        const added = {};\n        while (stack.length > 0) {\n            const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n            await Promise.all(promises);\n        }\n        if (dynamicNode == null && !isFunctionExecution) {\n            console.warn(`This model execution did not contain any nodes with control flow ` +\n                `or dynamic output shapes. You can use model.execute() instead.`);\n        }\n        const missingOutputs = outputNodes\n            .filter(node => !isControlFlow(node) &&\n            !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n        if (missingOutputs.length > 0) {\n            let alternativeMsg = '';\n            if (dynamicNode != null) {\n                alternativeMsg =\n                    `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n                        `and specify the inputs [${syncInputs}]`;\n            }\n            throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` +\n                `inputs [${names}]. Consider providing the following inputs: ` +\n                `[${missingInputs}]. ${alternativeMsg}`);\n        }\n        return tensorsMap;\n    }\n    processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n        const promises = [];\n        while (stack.length > 0) {\n            const item = stack.pop();\n            context.currentContext = item.contexts;\n            let nodeName = '';\n            // The tensor of the Enter op with isConstant set should be set\n            // in the parent scope, so it will be available as constant for the\n            // whole loop.\n            if (item.node.op === 'Enter' &&\n                getParamValue('isConstant', item.node, tensorMap, context)) {\n                [nodeName] = getNodeNameAndIndex(item.node.name, context);\n            }\n            // only process nodes that are not in the tensorMap yet, this include\n            // inputNodes and internal initNodes.\n            if (tensorMap[item.node.name] == null) {\n                const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n                if (!nodeName) {\n                    [nodeName] = getNodeNameAndIndex(item.node.name, context);\n                }\n                const currentContext = context.currentContext;\n                if (util.isPromise(tensors)) {\n                    promises.push(tensors.then(t => {\n                        tensorMap[nodeName] = t;\n                        context.currentContext = currentContext;\n                        this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                        return t;\n                    }));\n                }\n                else {\n                    tensorMap[nodeName] = tensors;\n                    this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                    this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                }\n            }\n            else {\n                this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            }\n        }\n        return promises;\n    }\n    processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n        node.children.forEach((childNode) => {\n            const [nodeName,] = getNodeNameAndIndex(childNode.name, context);\n            if (added[nodeName] || !usedNodes.has(childNode.name)) {\n                return;\n            }\n            // Merge op can be pushed if any of its inputs has value.\n            if (childNode.op === 'Merge') {\n                if (childNode.inputNames.some(name => {\n                    return !!getTensor(name, tensorMap, context);\n                })) {\n                    added[nodeName] = true;\n                    stack.push({ contexts: context.currentContext, node: childNode });\n                }\n            }\n            else // Otherwise all inputs must to have value.\n             if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n            })) {\n                added[nodeName] = true;\n                stack.push({ contexts: context.currentContext, node: childNode });\n            }\n        });\n    }\n    /**\n     * Releases the memory used by the weight tensors.\n     */\n    dispose() {\n        Object.keys(this.weightMap)\n            .forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n    }\n    checkInputShapeAndType(inputs) {\n        Object.keys(inputs).forEach(name => {\n            const input = inputs[name];\n            const [nodeName,] = parseNodeName(name);\n            const node = this.graph.nodes[nodeName];\n            if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n                const shape = node.attrParams['shape'].value;\n                const match = shape.length === input.shape.length &&\n                    input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n                util.assert(match, () => `The shape of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be [${shape}], but was ` +\n                    `[${input.shape}]`);\n            }\n            if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n                util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be ` +\n                    `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n            }\n        });\n    }\n    mapInputs(inputs) {\n        const result = {};\n        for (const inputName in inputs) {\n            if (this._signature != null && this._signature.inputs != null &&\n                this._signature.inputs[inputName] != null) {\n                const tensor = this._signature.inputs[inputName];\n                result[tensor.name] = inputs[inputName];\n            }\n            else {\n                result[inputName] = inputs[inputName];\n            }\n        }\n        return result;\n    }\n    checkInputs(inputs) {\n        const notInGraph = Object.keys(inputs).filter(name => {\n            const [nodeName] = parseNodeName(name);\n            return this.graph.nodes[nodeName] == null;\n        });\n        if (notInGraph.length > 0) {\n            throw new Error(`The dict provided in model.execute(dict) has ` +\n                `keys: [${notInGraph}] that are not part of graph`);\n        }\n    }\n    mapOutputs(outputs) {\n        return outputs.map(name => {\n            if (this._signature != null && this._signature.outputs != null &&\n                this._signature.outputs[name] != null) {\n                const tensor = this._signature.outputs[name];\n                return tensor.name;\n            }\n            return name;\n        }, {});\n    }\n    checkOutputs(outputs) {\n        outputs.forEach(name => {\n            const [normalizedName] = parseNodeName(name);\n            if (!this.graph.nodes[normalizedName]) {\n                throw new Error(`The output '${name}' is not found in the graph`);\n            }\n        });\n    }\n}\n//# sourceMappingURL=graph_executor.js.map"]},"metadata":{},"sourceType":"module"}